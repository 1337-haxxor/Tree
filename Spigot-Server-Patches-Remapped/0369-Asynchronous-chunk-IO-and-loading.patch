From 0000000000000000000000000000000000000000 Mon Sep 17 00:00:00 2001
From: Spottedleaf <Spottedleaf@users.noreply.github.com>
Date: Sat, 13 Jul 2019 09:23:10 -0700
Subject: [PATCH] Asynchronous chunk IO and loading

This patch re-adds a file IO thread as well as shoving de-serializing
chunk NBT data onto worker threads. This patch also will shove
chunk data serialization onto the same worker threads when the chunk
is unloaded - this cannot be done for regular saves since that's unsafe.

The file IO Thread

Unlike 1.13 and below, the file IO thread is prioritized - IO tasks can
be reoredered, however they are "stuck" to a world & coordinate.

Scheduling IO tasks works as follows, given a world & coordinate - location:

The IO thread has been designed to ensure that reads and writes appear to
occur synchronously for a given location, however the implementation also
has the unfortunate side-effect of making every write appear as if
they occur without failure.

The IO thread has also been designed to accomodate Mojang's decision to
store chunk data and POI data separately. It can independently schedule
tasks for each.

However threads can wait for writes to complete and check if:
 - The write was overwriten by another scheduler
 - The write failed (however it does not indicate whether it was overwritten by another scheduler)

Scheduling reads:

 - If a write task is in progress, the task is not scheduled and returns the in-progress write data
    This means that readers cannot modify the NBTTagCompound returned and must clone if it they wish to write
 - If a write task is not in progress but a read task is in progress, then the read task is simply chained
    This means that again, readers cannot modify the NBTTagCompound returned

Scheduling writes:

 - If a read task is in progress, ignore the read task and schedule the write
    We cannot complete the read task since we assume it wants old data - not current
 - If a write task is pending, overwrite the write data
    The file IO thread does correctly handle cases where the data is overwritten when it
    is writing data (before completing a task it will check if the data was overwritten and
    will retry).

When the file IO thread executes a task for a location, the it will
execute the read task first (if it exists), then it will execute the
write task. This ensures that, even when scheduling at different
priorities, that reads/writes for a location act synchronously.

The downside of the file IO thread is that write failure can only be
indicated to the scheduling thread if:

- No other thread decides to schedule another write for the location
concurrently
- The scheduling thread blocks on the write to complete (however the
current implementation can be modified to indicate success
asynchronously)

The file io thread can be modified easily to provide indications
of write failure and write overwriting if needed.

The upside of the file IO thread is that if a write failures, then
chunk data is not lost until server restart. This leaves more room
for spurious failure.

Finally, the io thread will indicate to the console when reads
or writes fail - with relevant detail.

Asynchronous chunk data serialization for unloading chunks

When chunks unload they make a call to PlayerChunkMap#saveChunk(IChunkAccess).
Even if I make the IO asynchronous for this call, the data serialization
still hits pretty hard. And given that now the chunk system will
aggressively unload chunks more often (queued immediately at
ticket level 45 or higher), unloads occur more often, and
combined with our changes to the unload queue to make it
significantly more aggresive - chunk unloads can hit pretty hard.
Especially players running around with elytras and fireworks.

For serializing chunk data off main, there are some tasks which cannot be
done asynchronously. Lighting data must be saved beforehand as well as
potentially some tick lists. These are completed before scheduling the
asynchronous save.

However serializing chunk data off of the main thread is still risky.
Even though this patch schedules the save to occur after ALL references
of the chunk are removed from the world, plugins can still technically
access entities inside the chunks. For this, if the serialization task
fails for any reason, it will be re-scheduled to be serialized on the
main thread - with the hopes that the reason it failed was due to a plugin
and not an error with the save code itself. Like vanilla code - if the
serialization fails, the chunk data is lost.

Asynchronous chunk io/loading

Mojang's current implementation for loading chunk data off disk is
to return a CompletableFuture that will be completed by scheduling a
task to be executed on the world's chunk queue (which is only drained
on the main thread). This task will read the IO off disk and it will
apply data conversions & deserialization synchronously. Obviously
all 3 of these operations are expensive however all can be completed
asynchronously instead.

The solution this patch uses is as follows:

0. If an asynchronous chunk save is in progress (see above), wait
for that task to complete. It will use the serialized NBTTagCompound
created by the task. If the task fails to complete, then we would continue
with step 1. If it does not, we skip step 1. (Note: We actually load
POI data no matter what in this case).
1. Schedule an IO task to read chunk & poi data off disk.
2. The IO task will schedule a chunk load task.
3. The chunk load task executes on the async chunk loader threads
and will apply datafixers & de-serialize the chunk into a ProtoChunk
or ProtoChunkExtension.
4. The in progress chunk is then passed on to the world's chunk queue
to complete the ComletableFuture and execute any of the synchronous
tasks required to be executed by the chunk load task (i.e lighting
and some poi tasks).

diff --git a/src/main/java/co/aikar/timings/WorldTimingsHandler.java b/src/main/java/co/aikar/timings/WorldTimingsHandler.java
index db5fe00fede07b582513741c25445d2081da8b61..0d6fbe70fc75306748e5197d5f4999decd7d1dc5 100644
--- a/src/main/java/co/aikar/timings/WorldTimingsHandler.java
+++ b/src/main/java/co/aikar/timings/WorldTimingsHandler.java
@@ -59,6 +59,17 @@ public class WorldTimingsHandler {
 
     public final Timing miscMobSpawning;
 
+    public final Timing poiUnload;
+    public final Timing chunkUnload;
+    public final Timing poiSaveDataSerialization;
+    public final Timing chunkSave;
+    public final Timing chunkSaveOverwriteCheck;
+    public final Timing chunkSaveDataSerialization;
+    public final Timing chunkSaveIOWait;
+    public final Timing chunkUnloadPrepareSave;
+    public final Timing chunkUnloadPOISerialization;
+    public final Timing chunkUnloadDataSave;
+
     public WorldTimingsHandler(World server) {
         String name = ((ServerWorldInfo) server.func_72912_H()).func_76065_j() + " - ";
 
@@ -112,6 +123,17 @@ public class WorldTimingsHandler {
 
 
         miscMobSpawning = Timings.ofSafe(name + "Mob spawning - Misc");
+
+        poiUnload = Timings.ofSafe(name + "Chunk unload - POI");
+        chunkUnload = Timings.ofSafe(name + "Chunk unload - Chunk");
+        poiSaveDataSerialization = Timings.ofSafe(name + "Chunk save - POI Data serialization");
+        chunkSave = Timings.ofSafe(name + "Chunk save - Chunk");
+        chunkSaveOverwriteCheck = Timings.ofSafe(name + "Chunk save - Chunk Overwrite Check");
+        chunkSaveDataSerialization = Timings.ofSafe(name + "Chunk save - Chunk Data serialization");
+        chunkSaveIOWait = Timings.ofSafe(name + "Chunk save - Chunk IO Wait");
+        chunkUnloadPrepareSave = Timings.ofSafe(name + "Chunk unload - Async Save Prepare");
+        chunkUnloadPOISerialization = Timings.ofSafe(name + "Chunk unload - POI Data Serialization");
+        chunkUnloadDataSave = Timings.ofSafe(name + "Chunk unload - Data Serialization");
     }
 
     public static Timing getTickList(ServerWorld worldserver, String timingsType) {
diff --git a/src/main/java/com/destroystokyo/paper/PaperCommand.java b/src/main/java/com/destroystokyo/paper/PaperCommand.java
index 59c1fbf3ee9b8e55a22a2e0056690eca0fe0f067..248380e08d683d3d615f0dec5f672bb30d5c32d8 100644
--- a/src/main/java/com/destroystokyo/paper/PaperCommand.java
+++ b/src/main/java/com/destroystokyo/paper/PaperCommand.java
@@ -1,5 +1,6 @@
 package com.destroystokyo.paper;
 
+import com.destroystokyo.paper.io.chunk.ChunkTaskManager;
 import com.google.common.base.Functions;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Lists;
@@ -35,14 +36,14 @@ public class PaperCommand extends Command {
     public PaperCommand(String name) {
         super(name);
         this.description = "Paper related commands";
-        this.usageMessage = "/paper [heap | entity | reload | version | debug | chunkinfo]";
+        this.usageMessage = "/paper [heap | entity | reload | version | debug | dumpwaiting | chunkinfo]";
         this.setPermission("bukkit.command.paper");
     }
 
     @Override
     public List<String> tabComplete(CommandSender sender, String alias, String[] args, Location location) throws IllegalArgumentException {
         if (args.length <= 1)
-            return getListMatchingLast(args, "heap", "entity", "reload", "version", "debug", "chunkinfo");
+            return getListMatchingLast(args, "heap", "entity", "reload", "version", "debug", "dumpwaiting", "chunkinfo");
 
         switch (args[0].toLowerCase(Locale.ENGLISH))
         {
@@ -134,6 +135,9 @@ public class PaperCommand extends Command {
             case "debug":
                 doDebug(sender, args);
                 break;
+            case "dumpwaiting":
+                ChunkTaskManager.dumpAllChunkLoadInfo();
+                break;
             case "chunkinfo":
                 doChunkInfo(sender, args);
                 break;
diff --git a/src/main/java/com/destroystokyo/paper/PaperConfig.java b/src/main/java/com/destroystokyo/paper/PaperConfig.java
index 346da105776a0ae0cb06ed69f1f8f9160695bb85..0fcabd12408a8209da5cb3332e217f98983aec02 100644
--- a/src/main/java/com/destroystokyo/paper/PaperConfig.java
+++ b/src/main/java/com/destroystokyo/paper/PaperConfig.java
@@ -1,5 +1,6 @@
 package com.destroystokyo.paper;
 
+import com.destroystokyo.paper.io.chunk.ChunkTaskManager;
 import com.google.common.base.Strings;
 import com.google.common.base.Throwables;
 
@@ -347,4 +348,54 @@ public class PaperConfig {
         maxBookPageSize = getInt("settings.book-size.page-max", maxBookPageSize);
         maxBookTotalSizeMultiplier = getDouble("settings.book-size.total-multiplier", maxBookTotalSizeMultiplier);
     }
+
+    public static boolean asyncChunks = false;
+    private static void asyncChunks() {
+        ConfigurationSection section;
+        if (version < 15) {
+            section = config.createSection("settings.async-chunks");
+            section.set("threads", -1);
+        } else {
+            section = config.getConfigurationSection("settings.async-chunks");
+            if (section == null) {
+                section = config.createSection("settings.async-chunks");
+            }
+        }
+        // Clean up old configs
+        if (section.contains("load-threads")) {
+            if (!section.contains("threads")) {
+                section.set("threads", section.get("load-threads"));
+            }
+            section.set("load-threads", null);
+        }
+        section.set("generation", null);
+        section.set("enabled", null);
+        section.set("thread-per-world-generation", null);
+
+        int threads = getInt("settings.async-chunks.threads", -1);
+        int cpus = Runtime.getRuntime().availableProcessors();
+        if (threads <= 0) {
+            threads = (int) Math.min(Integer.getInteger("paper.maxChunkThreads", 8), Math.max(1, cpus - 1));
+        }
+        if (cpus == 1 && !Boolean.getBoolean("Paper.allowAsyncChunksSingleCore")) {
+            asyncChunks = false;
+        } else {
+            asyncChunks = true;
+        }
+
+        // Let Shared Host set some limits
+        String sharedHostThreads = System.getenv("PAPER_ASYNC_CHUNKS_SHARED_HOST_THREADS");
+        if (sharedHostThreads != null) {
+            try {
+                threads = Math.max(1, Math.min(threads, Integer.parseInt(sharedHostThreads)));
+            } catch (NumberFormatException ignored) {}
+        }
+
+        if (!asyncChunks) {
+            log("Async Chunks: Disabled - Chunks will be managed synchronosuly, and will cause tremendous lag.");
+        } else {
+            ChunkTaskManager.initGlobalLoadThreads(threads);
+            log("Async Chunks: Enabled - Chunks will be loaded much faster, without lag.");
+        }
+    }
 }
diff --git a/src/main/java/com/destroystokyo/paper/io/IOUtil.java b/src/main/java/com/destroystokyo/paper/io/IOUtil.java
new file mode 100644
index 0000000000000000000000000000000000000000..5af0ac3d9e87c06053e65433060f15779c156c2a
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/IOUtil.java
@@ -0,0 +1,62 @@
+package com.destroystokyo.paper.io;
+
+import org.bukkit.Bukkit;
+
+public final class IOUtil {
+
+    /* Copied from concrete or concurrentutil */
+
+    public static long getCoordinateKey(final int x, final int z) {
+        return ((long)z << 32) | (x & 0xFFFFFFFFL);
+    }
+
+    public static int getCoordinateX(final long key) {
+        return (int)key;
+    }
+
+    public static int getCoordinateZ(final long key) {
+        return (int)(key >>> 32);
+    }
+
+    public static int getRegionCoordinate(final int chunkCoordinate) {
+        return chunkCoordinate >> 5;
+    }
+
+    public static int getChunkInRegion(final int chunkCoordinate) {
+        return chunkCoordinate & 31;
+    }
+
+    public static String genericToString(final Object object) {
+        return object == null ? "null" : object.getClass().getName() + ":" + object.toString();
+    }
+
+    public static <T> T notNull(final T obj) {
+        if (obj == null) {
+            throw new NullPointerException();
+        }
+        return obj;
+    }
+
+    public static <T> T notNull(final T obj, final String msgIfNull) {
+        if (obj == null) {
+            throw new NullPointerException(msgIfNull);
+        }
+        return obj;
+    }
+
+    public static void arrayBounds(final int off, final int len, final int arrayLength, final String msgPrefix) {
+        if (off < 0 || len < 0 || (arrayLength - off) < len) {
+            throw new ArrayIndexOutOfBoundsException(msgPrefix + ": off: " + off + ", len: " + len + ", array length: " + arrayLength);
+        }
+    }
+
+    public static int getPriorityForCurrentThread() {
+        return Bukkit.isPrimaryThread() ? PrioritizedTaskQueue.HIGHEST_PRIORITY : PrioritizedTaskQueue.NORMAL_PRIORITY;
+    }
+
+    @SuppressWarnings("unchecked")
+    public static <T extends Throwable> void rethrow(final Throwable throwable) throws T {
+        throw (T)throwable;
+    }
+
+}
diff --git a/src/main/java/com/destroystokyo/paper/io/PaperFileIOThread.java b/src/main/java/com/destroystokyo/paper/io/PaperFileIOThread.java
new file mode 100644
index 0000000000000000000000000000000000000000..0edefd6322b57efa2efca28d5009f5d89c6f0e40
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/PaperFileIOThread.java
@@ -0,0 +1,606 @@
+package com.destroystokyo.paper.io;
+
+import net.minecraft.nbt.CompoundNBT;
+import net.minecraft.server.MinecraftServer;
+import net.minecraft.util.math.ChunkPos;
+import net.minecraft.world.chunk.storage.RegionFile;
+import net.minecraft.world.server.ServerWorld;
+import org.apache.logging.log4j.Logger;
+import com.destroystokyo.paper.io.PaperFileIOThread.GeneralTask;
+import java.io.IOException;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.function.Consumer;
+import java.util.function.Function;
+
+/**
+ * Prioritized singleton thread responsible for all chunk IO that occurs in a minecraft server.
+ *
+ * <p>
+ *    Singleton access: {@link Holder#INSTANCE}
+ * </p>
+ *
+ * <p>
+ *     All functions provided are MT-Safe, however certain ordering constraints are (but not enforced):
+ *     <li>
+ *         Chunk saves may not occur for unloaded chunks.
+ *     </li>
+ *     <li>
+ *         Tasks must be scheduled on the main thread.
+ *     </li>
+ * </p>
+ *
+ * @see Holder#INSTANCE
+ * @see #scheduleSave(ServerWorld, int, int, CompoundNBT, CompoundNBT, int)
+ * @see #loadChunkDataAsync(ServerWorld, int, int, int, Consumer, boolean, boolean, boolean)
+ */
+public final class PaperFileIOThread extends QueueExecutorThread {
+
+    public static final Logger LOGGER = MinecraftServer.field_147145_h;
+    public static final CompoundNBT FAILURE_VALUE = new CompoundNBT();
+
+    public static final class Holder {
+
+        public static final PaperFileIOThread INSTANCE = new PaperFileIOThread();
+
+        static {
+            INSTANCE.start();
+        }
+    }
+
+    private final AtomicLong writeCounter = new AtomicLong();
+
+    private PaperFileIOThread() {
+        super(new PrioritizedTaskQueue<>(), (int)(1.0e6)); // 1.0ms spinwait time
+        this.setName("Paper RegionFile IO Thread");
+        this.setPriority(Thread.NORM_PRIORITY - 1); // we keep priority close to normal because threads can wait on us
+        this.setUncaughtExceptionHandler((final Thread unused, final Throwable thr) -> {
+            LOGGER.fatal("Uncaught exception thrown from IO thread, report this!", thr);
+        });
+    }
+
+    /* run() is implemented by superclass */
+
+    /*
+     *
+     * IO thread will perform reads before writes
+     *
+     * How reads/writes are scheduled:
+     *
+     * If read in progress while scheduling write, ignore read and schedule write
+     * If read in progress while scheduling read (no write in progress), chain the read task
+     *
+     *
+     * If write in progress while scheduling read, use the pending write data and ret immediately
+     * If write in progress while scheduling write (ignore read in progress), overwrite the write in progress data
+     *
+     * This allows the reads and writes to act as if they occur synchronously to the thread scheduling them, however
+     * it fails to properly propagate write failures. When writes fail the data is kept so future reads will actually
+     * read the failed write data. This should hopefully act as a way to prevent data loss for spurious fails for writing data.
+     *
+     */
+
+    /**
+     * Attempts to bump the priority of all IO tasks for the given chunk coordinates. This has no effect if no tasks are queued.
+     * @param world Chunk's world
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     * @param priority Priority level to try to bump to
+     */
+    public void bumpPriority(final ServerWorld world, final int chunkX, final int chunkZ, final int priority) {
+        if (!PrioritizedTaskQueue.validPriority(priority)) {
+            throw new IllegalArgumentException("Invalid priority: " + priority);
+        }
+
+        final Long key = Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ));
+
+        final ChunkDataTask poiTask = world.poiDataController.tasks.get(key);
+        final ChunkDataTask chunkTask = world.chunkDataController.tasks.get(key);
+
+        if (poiTask != null) {
+            poiTask.raisePriority(priority);
+        }
+        if (chunkTask != null) {
+            chunkTask.raisePriority(priority);
+        }
+    }
+
+    public CompoundNBT getPendingWrite(final ServerWorld world, final int chunkX, final int chunkZ, final boolean poiData) {
+        final ChunkDataController taskController = poiData ? world.poiDataController : world.chunkDataController;
+
+        final ChunkDataTask dataTask = taskController.tasks.get(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)));
+
+        if (dataTask == null) {
+            return null;
+        }
+
+        final ChunkDataController.InProgressWrite write = dataTask.inProgressWrite;
+
+        if (write == null) {
+            return null;
+        }
+
+        return write.data;
+    }
+
+    /**
+     * Sets the priority of all IO tasks for the given chunk coordinates. This has no effect if no tasks are queued.
+     * @param world Chunk's world
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     * @param priority Priority level to set to
+     */
+    public void setPriority(final ServerWorld world, final int chunkX, final int chunkZ, final int priority) {
+        if (!PrioritizedTaskQueue.validPriority(priority)) {
+            throw new IllegalArgumentException("Invalid priority: " + priority);
+        }
+
+        final Long key = Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ));
+
+        final ChunkDataTask poiTask = world.poiDataController.tasks.get(key);
+        final ChunkDataTask chunkTask = world.chunkDataController.tasks.get(key);
+
+        if (poiTask != null) {
+            poiTask.updatePriority(priority);
+        }
+        if (chunkTask != null) {
+            chunkTask.updatePriority(priority);
+        }
+    }
+
+    /**
+     * Schedules the chunk data to be written asynchronously.
+     * <p>
+     *     Impl notes:
+     * </p>
+     * <li>
+     *     This function presumes a chunk load for the coordinates is not called during this function (anytime after is OK). This means
+     *     saves must be scheduled before a chunk is unloaded.
+     * </li>
+     * <li>
+     *     Writes may be called concurrently, although only the "later" write will go through.
+     * </li>
+     * @param world Chunk's world
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     * @param poiData Chunk point of interest data. If {@code null}, then no poi data is saved.
+     * @param chunkData Chunk data. If {@code null}, then no chunk data is saved.
+     * @param priority Priority level for this task. See {@link PrioritizedTaskQueue}
+     * @throws IllegalArgumentException If both {@code poiData} and {@code chunkData} are {@code null}.
+     * @throws IllegalStateException If the file io thread has shutdown.
+     */
+    public void scheduleSave(final ServerWorld world, final int chunkX, final int chunkZ,
+                             final CompoundNBT poiData, final CompoundNBT chunkData,
+                             final int priority) throws IllegalArgumentException {
+        if (!PrioritizedTaskQueue.validPriority(priority)) {
+            throw new IllegalArgumentException("Invalid priority: " + priority);
+        }
+
+        final long writeCounter = this.writeCounter.getAndIncrement();
+
+        if (poiData != null) {
+            this.scheduleWrite(world.poiDataController, world, chunkX, chunkZ, poiData, priority, writeCounter);
+        }
+        if (chunkData != null) {
+            this.scheduleWrite(world.chunkDataController, world, chunkX, chunkZ, chunkData, priority, writeCounter);
+        }
+    }
+
+    private void scheduleWrite(final ChunkDataController dataController, final ServerWorld world,
+                               final int chunkX, final int chunkZ, final CompoundNBT data, final int priority, final long writeCounter) {
+        dataController.tasks.compute(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)), (final Long keyInMap, final ChunkDataTask taskRunning) -> {
+            if (taskRunning == null) {
+                // no task is scheduled
+
+                // create task
+                final ChunkDataTask newTask = new ChunkDataTask(priority, world, chunkX, chunkZ, dataController);
+                newTask.inProgressWrite = new ChunkDataController.InProgressWrite();
+                newTask.inProgressWrite.writeCounter = writeCounter;
+                newTask.inProgressWrite.data = data;
+
+                PaperFileIOThread.this.queueTask(newTask); // schedule
+                return newTask;
+            }
+
+            taskRunning.raisePriority(priority);
+
+            if (taskRunning.inProgressWrite == null) {
+                taskRunning.inProgressWrite = new ChunkDataController.InProgressWrite();
+            }
+
+            boolean reschedule = taskRunning.inProgressWrite.writeCounter == -1L;
+
+            // synchronize for readers
+            //noinspection SynchronizationOnLocalVariableOrMethodParameter
+            synchronized (taskRunning) {
+                taskRunning.inProgressWrite.data = data;
+                taskRunning.inProgressWrite.writeCounter = writeCounter;
+            }
+
+            if (reschedule) {
+                // We need to reschedule this task since the previous one is not currently scheduled since it failed
+                taskRunning.reschedule(priority);
+            }
+
+            return taskRunning;
+        });
+    }
+
+    /**
+     * Same as {@link #loadChunkDataAsync(ServerWorld, int, int, int, Consumer, boolean, boolean, boolean)}, except this function returns
+     * a {@link CompletableFuture} which is potentially completed <b>ASYNCHRONOUSLY ON THE FILE IO THREAD</b> when the load task
+     * has completed.
+     * <p>
+     *     Note that if the chunk fails to load the returned future is completed with {@code null}.
+     * </p>
+     */
+    public CompletableFuture<ChunkData> loadChunkDataAsyncFuture(final ServerWorld world, final int chunkX, final int chunkZ,
+                                                                 final int priority, final boolean readPoiData, final boolean readChunkData,
+                                                                 final boolean intendingToBlock) {
+        final CompletableFuture<ChunkData> future = new CompletableFuture<>();
+        this.loadChunkDataAsync(world, chunkX, chunkZ, priority, future::complete, readPoiData, readChunkData, intendingToBlock);
+        return future;
+    }
+
+    /**
+     * Schedules a load to be executed asynchronously.
+     * <p>
+     *     Impl notes:
+     * </p>
+     * <li>
+     *     If a chunk fails to load, the {@code onComplete} parameter is completed with {@code null}.
+     * </li>
+     * <li>
+     *     It is possible for the {@code onComplete} parameter to be given {@link ChunkData} containing data
+     *     this call did not request.
+     * </li>
+     * <li>
+     *     The {@code onComplete} parameter may be completed during the execution of this function synchronously or it may
+     *     be completed asynchronously on this file io thread. Interacting with the file IO thread in the completion of
+     *     data is undefined behaviour, and can cause deadlock.
+     * </li>
+     * @param world Chunk's world
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     * @param priority Priority level for this task. See {@link PrioritizedTaskQueue}
+     * @param onComplete Consumer to execute once this task has completed
+     * @param readPoiData Whether to read point of interest data. If {@code false}, the {@code NBTTagCompound} will be {@code null}.
+     * @param readChunkData Whether to read chunk data. If {@code false}, the {@code NBTTagCompound} will be {@code null}.
+     * @return The {@link PrioritizedTaskQueue.PrioritizedTask} associated with this task. Note that this task does not support
+     *                                                          cancellation.
+     */
+    public void loadChunkDataAsync(final ServerWorld world, final int chunkX, final int chunkZ,
+                                   final int priority, final Consumer<ChunkData> onComplete,
+                                   final boolean readPoiData, final boolean readChunkData,
+                                   final boolean intendingToBlock) {
+        if (!PrioritizedTaskQueue.validPriority(priority)) {
+            throw new IllegalArgumentException("Invalid priority: " + priority);
+        }
+
+        if (!(readPoiData | readChunkData)) {
+            throw new IllegalArgumentException("Must read chunk data or poi data");
+        }
+
+        final ChunkData complete = new ChunkData();
+        final boolean[] requireCompletion = new boolean[] { readPoiData, readChunkData };
+
+        if (readPoiData) {
+            this.scheduleRead(world.poiDataController, world, chunkX, chunkZ, (final CompoundNBT poiData) -> {
+                complete.poiData = poiData;
+
+                final boolean finished;
+
+                // avoid a race condition where the file io thread completes and we complete synchronously
+                // Note: Synchronization can be elided if both of the accesses are volatile
+                synchronized (requireCompletion) {
+                    requireCompletion[0] = false; // 0 -> poi data
+                    finished = !requireCompletion[1]; // 1 -> chunk data
+                }
+
+                if (finished) {
+                    onComplete.accept(complete);
+                }
+            }, priority, intendingToBlock);
+        }
+
+        if (readChunkData) {
+            this.scheduleRead(world.chunkDataController, world, chunkX, chunkZ, (final CompoundNBT chunkData) -> {
+                complete.chunkData = chunkData;
+
+                final boolean finished;
+
+                // avoid a race condition where the file io thread completes and we complete synchronously
+                // Note: Synchronization can be elided if both of the accesses are volatile
+                synchronized (requireCompletion) {
+                    requireCompletion[1] = false; // 1 -> chunk data
+                    finished = !requireCompletion[0]; // 0 -> poi data
+                }
+
+                if (finished) {
+                    onComplete.accept(complete);
+                }
+            }, priority, intendingToBlock);
+        }
+
+    }
+
+    // Note: the onComplete may be called asynchronously or synchronously here.
+    private void scheduleRead(final ChunkDataController dataController, final ServerWorld world,
+                              final int chunkX, final int chunkZ, final Consumer<CompoundNBT> onComplete, final int priority,
+                              final boolean intendingToBlock) {
+
+        Function<RegionFile, Boolean> tryLoadFunction = (final RegionFile file) -> {
+            if (file == null) {
+                return Boolean.TRUE;
+            }
+            return Boolean.valueOf(file.func_222667_d(new ChunkPos(chunkX, chunkZ)));
+        };
+
+        dataController.tasks.compute(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)), (final Long keyInMap, final ChunkDataTask running) -> {
+            if (running == null) {
+                // not scheduled
+
+                final Boolean shouldSchedule = intendingToBlock ? dataController.computeForRegionFile(chunkX, chunkZ, tryLoadFunction) :
+                    dataController.computeForRegionFileIfLoaded(chunkX, chunkZ, tryLoadFunction);
+
+                if (shouldSchedule == Boolean.FALSE) {
+                    // not on disk
+                    onComplete.accept(null);
+                    return null;
+                }
+
+                // set up task
+                final ChunkDataTask newTask = new ChunkDataTask(priority, world, chunkX, chunkZ, dataController);
+                newTask.inProgressRead = new ChunkDataController.InProgressRead();
+                newTask.inProgressRead.readFuture.thenAccept(onComplete);
+
+                PaperFileIOThread.this.queueTask(newTask); // schedule task
+                return newTask;
+            }
+
+            running.raisePriority(priority);
+
+            if (running.inProgressWrite == null) {
+                // chain to the read future
+                running.inProgressRead.readFuture.thenAccept(onComplete);
+                return running;
+            }
+
+            // at this stage we have to use the in progress write's data to avoid an order issue
+            // we don't synchronize since all writes to data occur in the compute() call
+            onComplete.accept(running.inProgressWrite.data);
+            return running;
+        });
+    }
+
+    /**
+     * Same as {@link #loadChunkDataAsync(ServerWorld, int, int, int, Consumer, boolean, boolean, boolean)}, except this function returns
+     * the {@link ChunkData} associated with the specified chunk when the task is complete.
+     * @return The chunk data, or {@code null} if the chunk failed to load.
+     */
+    public ChunkData loadChunkData(final ServerWorld world, final int chunkX, final int chunkZ, final int priority,
+                                   final boolean readPoiData, final boolean readChunkData) {
+        return this.loadChunkDataAsyncFuture(world, chunkX, chunkZ, priority, readPoiData, readChunkData, true).join();
+    }
+
+    /**
+     * Schedules the given task at the specified priority to be executed on the IO thread.
+     * <p>
+     *     Internal api. Do not use.
+     * </p>
+     */
+    public void runTask(final int priority, final Runnable runnable) {
+        this.queueTask(new GeneralTask(priority, runnable));
+    }
+
+    static final class GeneralTask extends PrioritizedTaskQueue.PrioritizedTask implements Runnable {
+
+        private final Runnable run;
+
+        public GeneralTask(final int priority, final Runnable run) {
+            super(priority);
+            this.run = IOUtil.notNull(run, "Task may not be null");
+        }
+
+        @Override
+        public void run() {
+            try {
+                this.run.run();
+            } catch (final Throwable throwable) {
+                if (throwable instanceof ThreadDeath) {
+                    throw (ThreadDeath)throwable;
+                }
+                LOGGER.fatal("Failed to execute general task on IO thread " + IOUtil.genericToString(this.run), throwable);
+            }
+        }
+    }
+
+    public static final class ChunkData {
+
+        public CompoundNBT poiData;
+        public CompoundNBT chunkData;
+
+        public ChunkData() {}
+
+        public ChunkData(final CompoundNBT poiData, final CompoundNBT chunkData) {
+            this.poiData = poiData;
+            this.chunkData = chunkData;
+        }
+    }
+
+    public static abstract class ChunkDataController {
+
+        // ConcurrentHashMap synchronizes per chain, so reduce the chance of task's hashes colliding.
+        public final ConcurrentHashMap<Long, ChunkDataTask> tasks = new ConcurrentHashMap<>(64, 0.5f);
+
+        public abstract void writeData(final int x, final int z, final CompoundNBT compound) throws IOException;
+        public abstract CompoundNBT readData(final int x, final int z) throws IOException;
+
+        public abstract <T> T computeForRegionFile(final int chunkX, final int chunkZ, final Function<RegionFile, T> function);
+        public abstract <T> T computeForRegionFileIfLoaded(final int chunkX, final int chunkZ, final Function<RegionFile, T> function);
+
+        public static final class InProgressWrite {
+            public long writeCounter;
+            public CompoundNBT data;
+        }
+
+        public static final class InProgressRead {
+            public final CompletableFuture<CompoundNBT> readFuture = new CompletableFuture<>();
+        }
+    }
+
+    public static final class ChunkDataTask extends PrioritizedTaskQueue.PrioritizedTask implements Runnable {
+
+        public ChunkDataController.InProgressWrite inProgressWrite;
+        public ChunkDataController.InProgressRead inProgressRead;
+
+        private final ServerWorld world;
+        private final int x;
+        private final int z;
+        private final ChunkDataController taskController;
+
+        public ChunkDataTask(final int priority, final ServerWorld world, final int x, final int z, final ChunkDataController taskController) {
+            super(priority);
+            this.world = world;
+            this.x = x;
+            this.z = z;
+            this.taskController = taskController;
+        }
+
+        @Override
+        public String toString() {
+            return "Task for world: '" + this.world.getWorld().getName() + "' at " + this.x + "," + this.z +
+                " poi: " + (this.taskController == this.world.poiDataController) + ", hash: " + this.hashCode();
+        }
+
+        /*
+         *
+         * IO thread will perform reads before writes
+         *
+         * How reads/writes are scheduled:
+         *
+         * If read in progress while scheduling write, ignore read and schedule write
+         * If read in progress while scheduling read (no write in progress), chain the read task
+         *
+         *
+         * If write in progress while scheduling read, use the pending write data and ret immediately
+         * If write in progress while scheduling write (ignore read in progress), overwrite the write in progress data
+         *
+         * This allows the reads and writes to act as if they occur synchronously to the thread scheduling them, however
+         * it fails to properly propagate write failures
+         *
+         */
+
+        void reschedule(final int priority) {
+            // priority is checked before this stage // TODO what
+            this.queue.lazySet(null);
+            this.priority.lazySet(priority);
+            PaperFileIOThread.Holder.INSTANCE.queueTask(this);
+        }
+
+        @Override
+        public void run() {
+            ChunkDataController.InProgressRead read = this.inProgressRead;
+            if (read != null) {
+                CompoundNBT compound = PaperFileIOThread.FAILURE_VALUE;
+                try {
+                    compound = this.taskController.readData(this.x, this.z);
+                } catch (final Throwable thr) {
+                    if (thr instanceof ThreadDeath) {
+                        throw (ThreadDeath)thr;
+                    }
+                    LOGGER.fatal("Failed to read chunk data for task: " + this.toString(), thr);
+                    // fall through to complete with null data
+                }
+                read.readFuture.complete(compound);
+            }
+
+            final Long chunkKey = Long.valueOf(IOUtil.getCoordinateKey(this.x, this.z));
+
+            ChunkDataController.InProgressWrite write = this.inProgressWrite;
+
+            if (write == null) {
+                // IntelliJ warns this is invalid, however it does not consider that writes to the task map & the inProgress field can occur concurrently.
+                ChunkDataTask inMap = this.taskController.tasks.compute(chunkKey, (final Long keyInMap, final ChunkDataTask valueInMap) -> {
+                    if (valueInMap == null) {
+                        throw new IllegalStateException("Write completed concurrently, expected this task: " + ChunkDataTask.this.toString() + ", report this!");
+                    }
+                    if (valueInMap != ChunkDataTask.this) {
+                        throw new IllegalStateException("Chunk task mismatch, expected this task: " + ChunkDataTask.this.toString() + ", got: " + valueInMap.toString() + ", report this!");
+                    }
+                    return valueInMap.inProgressWrite == null ? null : valueInMap;
+                });
+
+                if (inMap == null) {
+                    return; // set the task value to null, indicating we're done
+                }
+
+                // not null, which means there was a concurrent write
+                write = this.inProgressWrite;
+            }
+
+            // check if another process is writing
+            /*try { TODO: Can we restore this?
+                ((WorldServer)this.world).checkSession();
+            } catch (final Exception ex) {
+                LOGGER.fatal("Couldn't save chunk; already in use by another instance of Minecraft?", ex);
+                // we don't need to set the write counter to -1 as we know at this stage there's no point in re-scheduling
+                // writes since they'll fail anyways.
+                return;
+            }
+*/
+            for (;;) {
+                final long writeCounter;
+                final CompoundNBT data;
+
+                //noinspection SynchronizationOnLocalVariableOrMethodParameter
+                synchronized (write) {
+                    writeCounter = write.writeCounter;
+                    data = write.data;
+                }
+
+                boolean failedWrite = false;
+
+                try {
+                    this.taskController.writeData(this.x, this.z, data);
+                } catch (final Throwable thr) {
+                    if (thr instanceof ThreadDeath) {
+                        throw (ThreadDeath)thr;
+                    }
+                    LOGGER.fatal("Failed to write chunk data for task: " + this.toString(), thr);
+                    failedWrite = true;
+                }
+
+                boolean finalFailWrite = failedWrite;
+
+                ChunkDataTask inMap = this.taskController.tasks.compute(chunkKey, (final Long keyInMap, final ChunkDataTask valueInMap) -> {
+                    if (valueInMap == null) {
+                        throw new IllegalStateException("Write completed concurrently, expected this task: " + ChunkDataTask.this.toString() + ", report this!");
+                    }
+                    if (valueInMap != ChunkDataTask.this) {
+                        throw new IllegalStateException("Chunk task mismatch, expected this task: " + ChunkDataTask.this.toString() + ", got: " + valueInMap.toString() + ", report this!");
+                    }
+                    if (valueInMap.inProgressWrite.writeCounter == writeCounter) {
+                        if (finalFailWrite) {
+                            valueInMap.inProgressWrite.writeCounter = -1L;
+                        }
+
+                        return null;
+                    }
+                    return valueInMap;
+                    // Hack end
+                });
+
+                if (inMap == null) {
+                    // write counter matched, so we wrote the most up-to-date pending data, we're done here
+                    // or we failed to write and successfully set the write counter to -1
+                    return; // we're done here
+                }
+
+                // fetch & write new data
+                continue;
+            }
+        }
+    }
+}
diff --git a/src/main/java/com/destroystokyo/paper/io/PrioritizedTaskQueue.java b/src/main/java/com/destroystokyo/paper/io/PrioritizedTaskQueue.java
new file mode 100644
index 0000000000000000000000000000000000000000..97f2e433c483f1ebd7500ae142269e144ef5fda4
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/PrioritizedTaskQueue.java
@@ -0,0 +1,277 @@
+package com.destroystokyo.paper.io;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicReference;
+
+public class PrioritizedTaskQueue<T extends PrioritizedTaskQueue.PrioritizedTask> {
+
+    // lower numbers are a higher priority (except < 0)
+    // higher priorities are always executed before lower priorities
+
+    /**
+     * Priority value indicating the task has completed or is being completed.
+     */
+    public static final int COMPLETING_PRIORITY   = -1;
+
+    /**
+     * Highest priority, should only be used for main thread tasks or tasks that are blocking the main thread.
+     */
+    public static final int HIGHEST_PRIORITY      = 0;
+
+    /**
+     * Should be only used in an IO task so that chunk loads do not wait on other IO tasks.
+     * This only exists because IO tasks are scheduled before chunk load tasks to decrease IO waiting times.
+     */
+    public static final int HIGHER_PRIORITY       = 1;
+
+    /**
+     * Should be used for scheduling chunk loads/generation that would increase response times to users.
+     */
+    public static final int HIGH_PRIORITY         = 2;
+
+    /**
+     * Default priority.
+     */
+    public static final int NORMAL_PRIORITY       = 3;
+
+    /**
+     * Use for tasks not at all critical and can potentially be delayed.
+     */
+    public static final int LOW_PRIORITY          = 4;
+
+    /**
+     * Use for tasks that should "eventually" execute.
+     */
+    public static final int LOWEST_PRIORITY       = 5;
+
+    private static final int TOTAL_PRIORITIES     = 6;
+
+    final ConcurrentLinkedQueue<T>[] queues = (ConcurrentLinkedQueue<T>[])new ConcurrentLinkedQueue[TOTAL_PRIORITIES];
+
+    private final AtomicBoolean shutdown = new AtomicBoolean();
+
+    {
+        for (int i = 0; i < TOTAL_PRIORITIES; ++i) {
+            this.queues[i] = new ConcurrentLinkedQueue<>();
+        }
+    }
+
+    /**
+     * Returns whether the specified priority is valid
+     */
+    public static boolean validPriority(final int priority) {
+        return priority >= 0 && priority < TOTAL_PRIORITIES;
+    }
+
+    /**
+     * Queues a task.
+     * @throws IllegalStateException If the task has already been queued. Use {@link PrioritizedTask#raisePriority(int)} to
+     *                               raise a task's priority.
+     *                               This can also be thrown if the queue has shutdown.
+     */
+    public void add(final T task) throws IllegalStateException {
+        int priority = task.getPriority();
+        if (priority != COMPLETING_PRIORITY) {
+            task.setQueue(this);
+            this.queues[priority].add(task);
+        }
+        if (this.shutdown.get()) {
+            // note: we're not actually sure at this point if our task will go through
+            throw new IllegalStateException("Queue has shutdown, refusing to execute task " + IOUtil.genericToString(task));
+        }
+    }
+
+    /**
+     * Polls the highest priority task currently available. {@code null} if none.
+     */
+    public T poll() {
+        T task;
+        for (int i = 0; i < TOTAL_PRIORITIES; ++i) {
+            final ConcurrentLinkedQueue<T> queue = this.queues[i];
+
+            while ((task = queue.poll()) != null) {
+                final int prevPriority = task.tryComplete(i);
+                if (prevPriority != COMPLETING_PRIORITY && prevPriority <= i) {
+                    // if the prev priority was greater-than or equal to our current priority
+                    return task;
+                }
+            }
+        }
+
+        return null;
+    }
+
+    /**
+     * Returns whether this queue may have tasks queued.
+     * <p>
+     * This operation is not atomic, but is MT-Safe.
+     * </p>
+     * @return {@code true} if tasks may be queued, {@code false} otherwise
+     */
+    public boolean hasTasks() {
+        for (int i = 0; i < TOTAL_PRIORITIES; ++i) {
+            final ConcurrentLinkedQueue<T> queue = this.queues[i];
+
+            if (queue.peek() != null) {
+                return true;
+            }
+        }
+        return false;
+    }
+
+    /**
+     * Prevent further additions to this queue. Attempts to add after this call has completed (potentially during) will
+     * result in {@link IllegalStateException} being thrown.
+     * <p>
+     *     This operation is atomic with respect to other shutdown calls
+     * </p>
+     * <p>
+     *     After this call has completed, regardless of return value, this queue will be shutdown.
+     * </p>
+     * @return {@code true} if the queue was shutdown, {@code false} if it has shut down already
+     */
+    public boolean shutdown() {
+        return this.shutdown.getAndSet(false);
+    }
+
+    public abstract static class PrioritizedTask {
+
+        protected final AtomicReference<PrioritizedTaskQueue> queue = new AtomicReference<>();
+
+        protected final AtomicInteger priority;
+
+        protected PrioritizedTask() {
+            this(PrioritizedTaskQueue.NORMAL_PRIORITY);
+        }
+
+        protected PrioritizedTask(final int priority) {
+            if (!PrioritizedTaskQueue.validPriority(priority)) {
+                throw new IllegalArgumentException("Invalid priority " + priority);
+            }
+            this.priority = new AtomicInteger(priority);
+        }
+
+        /**
+         * Returns the current priority. Note that {@link PrioritizedTaskQueue#COMPLETING_PRIORITY} will be returned
+         * if this task is completing or has completed.
+         */
+        public final int getPriority() {
+            return this.priority.get();
+        }
+
+        /**
+         * Returns whether this task is scheduled to execute, or has been already executed.
+         */
+        public boolean isScheduled() {
+            return this.queue.get() != null;
+        }
+
+        final int tryComplete(final int minPriority) {
+            for (int curr = this.getPriorityVolatile();;) {
+                if (curr == COMPLETING_PRIORITY) {
+                    return COMPLETING_PRIORITY;
+                }
+                if (curr > minPriority) {
+                    // curr is lower priority
+                    return curr;
+                }
+
+                if (curr == (curr = this.compareAndExchangePriorityVolatile(curr, COMPLETING_PRIORITY))) {
+                    return curr;
+                }
+                continue;
+            }
+        }
+
+        /**
+         * Forces this task to be completed.
+         * @return {@code true} if the task was cancelled, {@code false} if the task has already completed or is being completed.
+         */
+        public boolean cancel() {
+            return this.exchangePriorityVolatile(PrioritizedTaskQueue.COMPLETING_PRIORITY) != PrioritizedTaskQueue.COMPLETING_PRIORITY;
+        }
+
+        /**
+         * Attempts to raise the priority to the priority level specified.
+         * @param priority Priority specified
+         * @return {@code true} if successful, {@code false} otherwise.
+         */
+        public boolean raisePriority(final int priority) {
+            if (!PrioritizedTaskQueue.validPriority(priority)) {
+                throw new IllegalArgumentException("Invalid priority");
+            }
+
+            for (int curr = this.getPriorityVolatile();;) {
+                if (curr == COMPLETING_PRIORITY) {
+                    return false;
+                }
+                if (priority >= curr) {
+                    return true;
+                }
+
+                if (curr == (curr = this.compareAndExchangePriorityVolatile(curr, priority))) {
+                    PrioritizedTaskQueue queue = this.queue.get();
+                    if (queue != null) {
+                        //noinspection unchecked
+                        queue.queues[priority].add(this); // silently fail on shutdown
+                    }
+                    return true;
+                }
+                continue;
+            }
+        }
+
+        /**
+         * Attempts to set this task's priority level to the level specified.
+         * @param priority Specified priority level.
+         * @return {@code true} if successful, {@code false} if this task is completing or has completed.
+         */
+        public boolean updatePriority(final int priority) {
+            if (!PrioritizedTaskQueue.validPriority(priority)) {
+                throw new IllegalArgumentException("Invalid priority");
+            }
+
+            for (int curr = this.getPriorityVolatile();;) {
+                if (curr == COMPLETING_PRIORITY) {
+                    return false;
+                }
+                if (curr == priority) {
+                    return true;
+                }
+
+                if (curr == (curr = this.compareAndExchangePriorityVolatile(curr, priority))) {
+                    PrioritizedTaskQueue queue = this.queue.get();
+                    if (queue != null) {
+                        //noinspection unchecked
+                        queue.queues[priority].add(this); // silently fail on shutdown
+                    }
+                    return true;
+                }
+                continue;
+            }
+        }
+
+        void setQueue(final PrioritizedTaskQueue queue) {
+            this.queue.set(queue);
+        }
+
+        /* priority */
+
+        protected final int getPriorityVolatile() {
+            return this.priority.get();
+        }
+
+        protected final int compareAndExchangePriorityVolatile(final int expect, final int update) {
+            if (this.priority.compareAndSet(expect, update)) {
+                return expect;
+            }
+            return this.priority.get();
+        }
+
+        protected final int exchangePriorityVolatile(final int value) {
+            return this.priority.getAndSet(value);
+        }
+    }
+}
diff --git a/src/main/java/com/destroystokyo/paper/io/QueueExecutorThread.java b/src/main/java/com/destroystokyo/paper/io/QueueExecutorThread.java
new file mode 100644
index 0000000000000000000000000000000000000000..e65940e2f5cc357c5b73ad40f34f211fed8c28b1
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/QueueExecutorThread.java
@@ -0,0 +1,241 @@
+package com.destroystokyo.paper.io;
+
+import net.minecraft.server.MinecraftServer;
+import org.apache.logging.log4j.Logger;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.locks.LockSupport;
+
+public class QueueExecutorThread<T extends PrioritizedTaskQueue.PrioritizedTask & Runnable> extends Thread {
+
+    private static final Logger LOGGER = MinecraftServer.field_147145_h;
+
+    protected final PrioritizedTaskQueue<T> queue;
+    protected final long spinWaitTime;
+
+    protected volatile boolean closed;
+
+    protected final AtomicBoolean parked = new AtomicBoolean();
+
+    protected volatile ConcurrentLinkedQueue<Thread> flushQueue = new ConcurrentLinkedQueue<>();
+    protected volatile long flushCycles;
+
+    public QueueExecutorThread(final PrioritizedTaskQueue<T> queue) {
+        this(queue, (int)(1.e6)); // 1.0ms
+    }
+
+    public QueueExecutorThread(final PrioritizedTaskQueue<T> queue, final long spinWaitTime) { // in ms
+        this.queue = queue;
+        this.spinWaitTime = spinWaitTime;
+    }
+
+    @Override
+    public void run() {
+        final long spinWaitTime = this.spinWaitTime;
+        main_loop:
+        for (;;) {
+            this.pollTasks(true);
+
+            // spinwait
+
+            final long start = System.nanoTime();
+
+            for (;;) {
+                // If we are interrpted for any reason, park() will always return immediately. Clear so that we don't needlessly use cpu in such an event.
+                Thread.interrupted();
+                LockSupport.parkNanos("Spinwaiting on tasks", 1000L); // 1us
+
+                if (this.pollTasks(true)) {
+                    // restart loop, found tasks
+                    continue main_loop;
+                }
+
+                if (this.handleClose()) {
+                    return; // we're done
+                }
+
+                if ((System.nanoTime() - start) >= spinWaitTime) {
+                    break;
+                }
+            }
+
+            if (this.handleClose()) {
+                return;
+            }
+
+            this.parked.set(true);
+
+            // We need to parse here to avoid a race condition where a thread queues a task before we set parked to true
+            // (i.e it will not notify us)
+            if (this.pollTasks(true)) {
+                this.parked.set(false);
+                continue;
+            }
+
+            if (this.handleClose()) {
+                return;
+            }
+
+            // we don't need to check parked before sleeping, but we do need to check parked in a do-while loop
+            // LockSupport.park() can fail for any reason
+            do {
+                Thread.interrupted();
+                LockSupport.park("Waiting on tasks");
+            } while (this.parked.get());
+        }
+    }
+
+    protected boolean handleClose() {
+        if (this.closed) {
+            this.pollTasks(true); // this ensures we've emptied the queue
+            this.handleFlushThreads(true);
+            return true;
+        }
+        return false;
+    }
+
+    protected boolean pollTasks(boolean flushTasks) {
+        Runnable task;
+        boolean ret = false;
+
+        while ((task = this.queue.poll()) != null) {
+            ret = true;
+            try {
+                task.run();
+            } catch (final Throwable throwable) {
+                if (throwable instanceof ThreadDeath) {
+                    throw (ThreadDeath)throwable;
+                }
+                LOGGER.fatal("Exception thrown from prioritized runnable task in thread '" + this.getName() + "': " + IOUtil.genericToString(task), throwable);
+            }
+        }
+
+        if (flushTasks) {
+            this.handleFlushThreads(false);
+        }
+
+        return ret;
+    }
+
+    protected void handleFlushThreads(final boolean shutdown) {
+        Thread parking;
+        ConcurrentLinkedQueue<Thread> flushQueue = this.flushQueue;
+        do {
+            ++flushCycles; // may be plain read opaque write
+            while ((parking = flushQueue.poll()) != null) {
+                LockSupport.unpark(parking);
+            }
+        } while (this.pollTasks(false));
+
+        if (shutdown) {
+            this.flushQueue = null;
+
+            // defend against a race condition where a flush thread double-checks right before we set to null
+            while ((parking = flushQueue.poll()) != null) {
+                LockSupport.unpark(parking);
+            }
+        }
+    }
+
+    /**
+     * Notify's this thread that a task has been added to its queue
+     * @return {@code true} if this thread was waiting for tasks, {@code false} if it is executing tasks
+     */
+    public boolean notifyTasks() {
+        if (this.parked.get() && this.parked.getAndSet(false)) {
+            LockSupport.unpark(this);
+            return true;
+        }
+        return false;
+    }
+
+    protected void queueTask(final T task) {
+        this.queue.add(task);
+        this.notifyTasks();
+    }
+
+    /**
+     * Waits until this thread's queue is empty.
+     *
+     * @throws IllegalStateException If the current thread is {@code this} thread.
+     */
+    public void flush() {
+        final Thread currentThread = Thread.currentThread();
+
+        if (currentThread == this) {
+            // avoid deadlock
+            throw new IllegalStateException("Cannot flush the queue executor thread while on the queue executor thread");
+        }
+
+        // order is important
+
+        int successes = 0;
+        long lastCycle = -1L;
+
+        do {
+            final ConcurrentLinkedQueue<Thread> flushQueue = this.flushQueue;
+            if (flushQueue == null) {
+                return;
+            }
+
+            flushQueue.add(currentThread);
+
+            // double check flush queue
+            if (this.flushQueue == null) {
+                return;
+            }
+
+            final long currentCycle = this.flushCycles; // may be opaque read
+
+            if (currentCycle == lastCycle) {
+                Thread.yield();
+                continue;
+            }
+
+            // force response
+            this.parked.set(false);
+            LockSupport.unpark(this);
+
+            LockSupport.park("flushing queue executor thread");
+
+            // returns whether there are tasks queued, does not return whether there are tasks executing
+            // this is why we cycle twice twice through flush (we know a pollTask call is made after a flush cycle)
+            // we really only need to guarantee that the tasks this thread has queued has gone through, and can leave
+            // tasks queued concurrently that are unsychronized with this thread as undefined behavior
+            if (this.queue.hasTasks()) {
+                successes = 0;
+            } else {
+                ++successes;
+            }
+
+        } while (successes != 2);
+
+    }
+
+    /**
+     * Closes this queue executor's queue and optionally waits for it to empty.
+     * <p>
+     *     If wait is {@code true}, then the queue will be empty by the time this call completes.
+     * </p>
+     * <p>
+     *     This function is MT-Safe.
+     * </p>
+     * @param wait If this call is to wait until the queue is empty
+     * @param killQueue Whether to shutdown this thread's queue
+     * @return whether this thread shut down the queue
+     */
+    public boolean close(final boolean wait, final boolean killQueue) {
+        boolean ret = !killQueue ? false : this.queue.shutdown();
+        this.closed = true;
+
+        // force thread to respond to the shutdown
+        this.parked.set(false);
+        LockSupport.unpark(this);
+
+        if (wait) {
+            this.flush();
+        }
+        return ret;
+    }
+}
diff --git a/src/main/java/com/destroystokyo/paper/io/chunk/ChunkLoadTask.java b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkLoadTask.java
new file mode 100644
index 0000000000000000000000000000000000000000..67df1804a629bfa5e882bff76fc082fcd571ef4f
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkLoadTask.java
@@ -0,0 +1,145 @@
+package com.destroystokyo.paper.io.chunk;
+
+import co.aikar.timings.Timing;
+import com.destroystokyo.paper.io.PaperFileIOThread;
+import com.destroystokyo.paper.io.IOUtil;
+import java.util.ArrayDeque;
+import java.util.function.Consumer;
+import net.minecraft.util.math.ChunkPos;
+import net.minecraft.world.chunk.storage.ChunkSerializer;
+import net.minecraft.world.server.ChunkManager;
+import net.minecraft.world.server.ServerWorld;
+
+public final class ChunkLoadTask extends ChunkTask {
+
+    public boolean cancelled;
+
+    Consumer<ChunkSerializer.InProgressChunkHolder> onComplete;
+    public PaperFileIOThread.ChunkData chunkData;
+
+    private boolean hasCompleted;
+
+    public ChunkLoadTask(final ServerWorld world, final int chunkX, final int chunkZ, final int priority,
+                         final ChunkTaskManager taskManager,
+                         final Consumer<ChunkSerializer.InProgressChunkHolder> onComplete) {
+        super(world, chunkX, chunkZ, priority, taskManager);
+        this.onComplete = onComplete;
+    }
+
+    private static final ArrayDeque<Runnable> EMPTY_QUEUE = new ArrayDeque<>();
+
+    private static ChunkSerializer.InProgressChunkHolder createEmptyHolder() {
+        return new ChunkSerializer.InProgressChunkHolder(null, EMPTY_QUEUE);
+    }
+
+    @Override
+    public void run() {
+        try {
+            this.executeTask();
+        } catch (final Throwable ex) {
+            PaperFileIOThread.LOGGER.error("Failed to execute chunk load task: " + this.toString(), ex);
+            if (!this.hasCompleted) {
+                this.complete(ChunkLoadTask.createEmptyHolder());
+            }
+        }
+    }
+
+    private boolean checkCancelled() {
+        if (this.cancelled) {
+            // IntelliJ does not understand writes may occur to cancelled concurrently.
+            return this.taskManager.chunkLoadTasks.compute(Long.valueOf(IOUtil.getCoordinateKey(this.chunkX, this.chunkZ)), (final Long keyInMap, final ChunkLoadTask valueInMap) -> {
+                if (valueInMap != ChunkLoadTask.this) {
+                    throw new IllegalStateException("Expected this task to be scheduled, but another was! Other: " + valueInMap + ", current: " + ChunkLoadTask.this);
+                }
+
+                if (valueInMap.cancelled) {
+                    return null;
+                }
+                return valueInMap;
+            }) == null;
+        }
+        return false;
+    }
+
+    public void executeTask() {
+        if (this.checkCancelled()) {
+            return;
+        }
+
+        // either executed synchronously or asynchronously
+        final PaperFileIOThread.ChunkData chunkData = this.chunkData;
+
+        if (chunkData.poiData == PaperFileIOThread.FAILURE_VALUE || chunkData.chunkData == PaperFileIOThread.FAILURE_VALUE) {
+            PaperFileIOThread.LOGGER.error("Could not load chunk for task: " + this.toString() + ", file IO thread has dumped the relevant exception above");
+            this.complete(ChunkLoadTask.createEmptyHolder());
+            return;
+        }
+
+        if (chunkData.chunkData == null) {
+            // not on disk
+            this.complete(ChunkLoadTask.createEmptyHolder());
+            return;
+        }
+
+        final ChunkPos chunkPos = new ChunkPos(this.chunkX, this.chunkZ);
+
+        final ChunkManager chunkManager = this.world.func_72863_F().field_217237_a;
+
+        try (Timing ignored = this.world.timings.chunkLoadLevelTimer.startTimingIfSync()) {
+            final ChunkSerializer.InProgressChunkHolder chunkHolder;
+
+            // apply fixes
+
+            try {
+                chunkData.chunkData = chunkManager.getChunkData(this.world.getTypeKey(),
+                    chunkManager.getWorldPersistentDataSupplier(), chunkData.chunkData, chunkPos, this.world); // clone data for safety, file IO thread does not clone
+            } catch (final Throwable ex) {
+                PaperFileIOThread.LOGGER.error("Could not apply datafixers for chunk task: " + this.toString(), ex);
+                this.complete(ChunkLoadTask.createEmptyHolder());
+            }
+
+            if (this.checkCancelled()) {
+                return;
+            }
+
+            try {
+                this.world.func_72863_F().field_217237_a.updateChunkStatusOnDisk(chunkPos, chunkData.chunkData);
+            } catch (final Throwable ex) {
+                PaperFileIOThread.LOGGER.warn("Failed to update chunk status cache for task: " + this.toString(), ex);
+                // non-fatal, continue
+            }
+
+            try {
+                chunkHolder = ChunkSerializer.loadChunk(this.world,
+                    chunkManager.field_219269_w, chunkManager.getVillagePlace(), chunkPos,
+                    chunkData.chunkData, true);
+            } catch (final Throwable ex) {
+                PaperFileIOThread.LOGGER.error("Could not de-serialize chunk data for task: " + this.toString(), ex);
+                this.complete(ChunkLoadTask.createEmptyHolder());
+                return;
+            }
+
+            this.complete(chunkHolder);
+        }
+    }
+
+    private void complete(final ChunkSerializer.InProgressChunkHolder holder) {
+        this.hasCompleted = true;
+        holder.poiData = this.chunkData == null ? null : this.chunkData.poiData;
+
+        this.taskManager.chunkLoadTasks.compute(Long.valueOf(IOUtil.getCoordinateKey(this.chunkX, this.chunkZ)), (final Long keyInMap, final ChunkLoadTask valueInMap) -> {
+            if (valueInMap != ChunkLoadTask.this) {
+                throw new IllegalStateException("Expected this task to be scheduled, but another was! Other: " + valueInMap + ", current: " + ChunkLoadTask.this);
+            }
+            if (valueInMap.cancelled) {
+                return null;
+            }
+            try {
+                ChunkLoadTask.this.onComplete.accept(holder);
+            } catch (final Throwable thr) {
+                PaperFileIOThread.LOGGER.error("Failed to complete chunk data for task: " + this.toString(), thr);
+            }
+            return null;
+        });
+    }
+}
diff --git a/src/main/java/com/destroystokyo/paper/io/chunk/ChunkSaveTask.java b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkSaveTask.java
new file mode 100644
index 0000000000000000000000000000000000000000..3f7087b808374be7bbd811aba87e9f94d6d571a1
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkSaveTask.java
@@ -0,0 +1,110 @@
+package com.destroystokyo.paper.io.chunk;
+
+import co.aikar.timings.Timing;
+import com.destroystokyo.paper.io.PaperFileIOThread;
+import com.destroystokyo.paper.io.IOUtil;
+import com.destroystokyo.paper.io.PrioritizedTaskQueue;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.atomic.AtomicInteger;
+import net.minecraft.nbt.CompoundNBT;
+import net.minecraft.world.chunk.IChunk;
+import net.minecraft.world.chunk.storage.ChunkSerializer;
+import net.minecraft.world.server.ServerWorld;
+
+public final class ChunkSaveTask extends ChunkTask {
+
+    public final ChunkSerializer.AsyncSaveData asyncSaveData;
+    public final IChunk chunk;
+    public final CompletableFuture<CompoundNBT> onComplete = new CompletableFuture<>();
+
+    private final AtomicInteger attemptedPriority;
+
+    public ChunkSaveTask(final ServerWorld world, final int chunkX, final int chunkZ, final int priority,
+                         final ChunkTaskManager taskManager, final ChunkSerializer.AsyncSaveData asyncSaveData,
+                         final IChunk chunk) {
+        super(world, chunkX, chunkZ, priority, taskManager);
+        this.chunk = chunk;
+        this.asyncSaveData = asyncSaveData;
+        this.attemptedPriority = new AtomicInteger(priority);
+    }
+
+    @Override
+    public void run() {
+        // can be executed asynchronously or synchronously
+        final CompoundNBT compound;
+
+        try (Timing ignored = this.world.timings.chunkUnloadDataSave.startTimingIfSync()) {
+            compound = ChunkSerializer.saveChunk(this.world, this.chunk, this.asyncSaveData);
+        } catch (final Throwable ex) {
+            // has a plugin modified something it should not have and made us CME?
+            PaperFileIOThread.LOGGER.error("Failed to serialize unloading chunk data for task: " + this.toString() + ", falling back to a synchronous execution", ex);
+
+            // Note: We add to the server thread queue here since this is what the server will drain tasks from
+            // when waiting for chunks
+            ChunkTaskManager.queueChunkWaitTask(() -> {
+                try (Timing ignored = this.world.timings.chunkUnloadDataSave.startTiming()) {
+                    CompoundNBT data = PaperFileIOThread.FAILURE_VALUE;
+
+                    try {
+                        data = ChunkSerializer.saveChunk(this.world, this.chunk, this.asyncSaveData);
+                        PaperFileIOThread.LOGGER.info("Successfully serialized chunk data for task: " + this.toString() + " synchronously");
+                    } catch (final Throwable ex1) {
+                        PaperFileIOThread.LOGGER.fatal("Failed to synchronously serialize unloading chunk data for task: " + this.toString() + "! Chunk data will be lost", ex1);
+                    }
+
+                    ChunkSaveTask.this.complete(data);
+                }
+            });
+
+            return; // the main thread will now complete the data
+        }
+
+        this.complete(compound);
+    }
+
+    @Override
+    public boolean raisePriority(final int priority) {
+        if (!PrioritizedTaskQueue.validPriority(priority)) {
+            throw new IllegalStateException("Invalid priority: " + priority);
+        }
+
+        // we know priority is valid here
+        for (int curr = this.attemptedPriority.get();;) {
+            if (curr <= priority) {
+                break; // curr is higher/same priority
+            }
+            if (this.attemptedPriority.compareAndSet(curr, priority)) {
+                break;
+            }
+            curr = this.attemptedPriority.get();
+        }
+
+        return super.raisePriority(priority);
+    }
+
+    @Override
+    public boolean updatePriority(final int priority) {
+        if (!PrioritizedTaskQueue.validPriority(priority)) {
+            throw new IllegalStateException("Invalid priority: " + priority);
+        }
+        this.attemptedPriority.set(priority);
+        return super.updatePriority(priority);
+    }
+
+    private void complete(final CompoundNBT compound) {
+        try {
+            this.onComplete.complete(compound);
+        } catch (final Throwable thr) {
+            PaperFileIOThread.LOGGER.error("Failed to complete chunk data for task: " + this.toString(), thr);
+        }
+        if (compound != PaperFileIOThread.FAILURE_VALUE) {
+            PaperFileIOThread.Holder.INSTANCE.scheduleSave(this.world, this.chunkX, this.chunkZ, null, compound, this.attemptedPriority.get());
+        }
+        this.taskManager.chunkSaveTasks.compute(Long.valueOf(IOUtil.getCoordinateKey(this.chunkX, this.chunkZ)), (final Long keyInMap, final ChunkSaveTask valueInMap) -> {
+            if (valueInMap != ChunkSaveTask.this) {
+                throw new IllegalStateException("Expected this task to be scheduled, but another was! Other: " + valueInMap + ", this: " + ChunkSaveTask.this);
+            }
+            return null;
+        });
+    }
+}
diff --git a/src/main/java/com/destroystokyo/paper/io/chunk/ChunkTask.java b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkTask.java
new file mode 100644
index 0000000000000000000000000000000000000000..ff0c89635f9ff385c03562a16cd894367fad57cd
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkTask.java
@@ -0,0 +1,40 @@
+package com.destroystokyo.paper.io.chunk;
+
+import com.destroystokyo.paper.io.PaperFileIOThread;
+import com.destroystokyo.paper.io.PrioritizedTaskQueue;
+import net.minecraft.world.server.ServerWorld;
+
+abstract class ChunkTask extends PrioritizedTaskQueue.PrioritizedTask implements Runnable {
+
+    public final ServerWorld world;
+    public final int chunkX;
+    public final int chunkZ;
+    public final ChunkTaskManager taskManager;
+
+    public ChunkTask(final ServerWorld world, final int chunkX, final int chunkZ, final int priority,
+                         final ChunkTaskManager taskManager) {
+        super(priority);
+        this.world = world;
+        this.chunkX = chunkX;
+        this.chunkZ = chunkZ;
+        this.taskManager = taskManager;
+    }
+
+    @Override
+    public String toString() {
+        return "Chunk task: class:" + this.getClass().getName() + ", for world '" + this.world.getWorld().getName() +
+            "', (" + this.chunkX + "," + this.chunkZ + "), hashcode:" + this.hashCode() + ", priority: " + this.getPriority();
+    }
+
+    @Override
+    public boolean raisePriority(final int priority) {
+        PaperFileIOThread.Holder.INSTANCE.bumpPriority(this.world, this.chunkX, this.chunkZ, priority);
+        return super.raisePriority(priority);
+    }
+
+    @Override
+    public boolean updatePriority(final int priority) {
+        PaperFileIOThread.Holder.INSTANCE.setPriority(this.world, this.chunkX, this.chunkZ, priority);
+        return super.updatePriority(priority);
+    }
+}
diff --git a/src/main/java/com/destroystokyo/paper/io/chunk/ChunkTaskManager.java b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkTaskManager.java
new file mode 100644
index 0000000000000000000000000000000000000000..96b1c40e7fe7edfbe743bd29397b0ea6cda4f358
--- /dev/null
+++ b/src/main/java/com/destroystokyo/paper/io/chunk/ChunkTaskManager.java
@@ -0,0 +1,511 @@
+package com.destroystokyo.paper.io.chunk;
+
+import com.destroystokyo.paper.io.PaperFileIOThread;
+import com.destroystokyo.paper.io.IOUtil;
+import com.destroystokyo.paper.io.PrioritizedTaskQueue;
+import com.destroystokyo.paper.io.QueueExecutorThread;
+import net.minecraft.nbt.CompoundNBT;
+import net.minecraft.server.MinecraftServer;
+import net.minecraft.util.concurrent.ThreadTaskExecutor;
+import net.minecraft.world.chunk.IChunk;
+import net.minecraft.world.chunk.storage.ChunkSerializer;
+import net.minecraft.world.server.ChunkHolder;
+import net.minecraft.world.server.ServerWorld;
+import org.apache.commons.lang.StringUtils;
+import org.apache.logging.log4j.Level;
+import org.bukkit.Bukkit;
+import org.spigotmc.AsyncCatcher;
+
+import java.util.ArrayDeque;
+import java.util.HashSet;
+import java.util.Set;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentLinkedQueue;
+import java.util.function.Consumer;
+
+public final class ChunkTaskManager {
+
+    private final QueueExecutorThread<ChunkTask>[] workers;
+    private final ServerWorld world;
+
+    private final PrioritizedTaskQueue<ChunkTask> queue;
+    private final boolean perWorldQueue;
+
+    final ConcurrentHashMap<Long, ChunkLoadTask> chunkLoadTasks = new ConcurrentHashMap<>(64, 0.5f);
+    final ConcurrentHashMap<Long, ChunkSaveTask> chunkSaveTasks = new ConcurrentHashMap<>(64, 0.5f);
+
+    private final PrioritizedTaskQueue<ChunkTask> chunkTasks = new PrioritizedTaskQueue<>(); // used if async chunks are disabled in config
+
+    protected static QueueExecutorThread<ChunkTask>[] globalWorkers;
+    protected static QueueExecutorThread<ChunkTask> globalUrgentWorker;
+    protected static PrioritizedTaskQueue<ChunkTask> globalQueue;
+    protected static PrioritizedTaskQueue<ChunkTask> globalUrgentQueue;
+
+    protected static final ConcurrentLinkedQueue<Runnable> CHUNK_WAIT_QUEUE = new ConcurrentLinkedQueue<>();
+
+    public static final ArrayDeque<ChunkInfo> WAITING_CHUNKS = new ArrayDeque<>(); // stack
+
+    private static final class ChunkInfo {
+
+        public final int chunkX;
+        public final int chunkZ;
+        public final ServerWorld world;
+
+        public ChunkInfo(final int chunkX, final int chunkZ, final ServerWorld world) {
+            this.chunkX = chunkX;
+            this.chunkZ = chunkZ;
+            this.world = world;
+        }
+
+        @Override
+        public String toString() {
+            return "[( " + this.chunkX + "," + this.chunkZ + ") in '" + this.world.getWorld().getName() + "']";
+        }
+    }
+
+    public static void pushChunkWait(final ServerWorld world, final int chunkX, final int chunkZ) {
+        synchronized (WAITING_CHUNKS) {
+            WAITING_CHUNKS.push(new ChunkInfo(chunkX, chunkZ, world));
+        }
+    }
+
+    public static void popChunkWait() {
+        synchronized (WAITING_CHUNKS) {
+            WAITING_CHUNKS.pop();
+        }
+    }
+
+    private static ChunkInfo[] getChunkInfos() {
+        ChunkInfo[] chunks;
+        synchronized (WAITING_CHUNKS) {
+            chunks = WAITING_CHUNKS.toArray(new ChunkInfo[0]);
+        }
+        return chunks;
+    }
+
+    public static void dumpAllChunkLoadInfo() {
+        ChunkInfo[] chunks = getChunkInfos();
+        if (chunks.length > 0) {
+            PaperFileIOThread.LOGGER.log(Level.ERROR, "Chunk wait task info below: ");
+
+            for (final ChunkInfo chunkInfo : chunks) {
+                final long key = IOUtil.getCoordinateKey(chunkInfo.chunkX, chunkInfo.chunkZ);
+                final ChunkLoadTask loadTask = chunkInfo.world.asyncChunkTaskManager.chunkLoadTasks.get(key);
+                final ChunkSaveTask saveTask = chunkInfo.world.asyncChunkTaskManager.chunkSaveTasks.get(key);
+
+                PaperFileIOThread.LOGGER.log(Level.ERROR, chunkInfo.chunkX + "," + chunkInfo.chunkZ + " in '" + chunkInfo.world.getWorld().getName() + ":");
+                PaperFileIOThread.LOGGER.log(Level.ERROR, "Load Task - " + (loadTask == null ? "none" : loadTask.toString()));
+                PaperFileIOThread.LOGGER.log(Level.ERROR, "Save Task - " + (saveTask == null ? "none" : saveTask.toString()));
+                // log current status of chunk to indicate whether we're waiting on generation or loading
+                net.minecraft.world.server.ChunkHolder chunkHolder = chunkInfo.world.func_72863_F().field_217237_a.func_219219_b(key);
+
+                dumpChunkInfo(new HashSet<>(), chunkHolder, chunkInfo.chunkX, chunkInfo.chunkZ);
+            }
+        }
+    }
+
+    static void dumpChunkInfo(Set<ChunkHolder> seenChunks, ChunkHolder chunkHolder, int x, int z) {
+        dumpChunkInfo(seenChunks, chunkHolder, x, z, 0, 1);
+    }
+
+    static void dumpChunkInfo(Set<ChunkHolder> seenChunks, ChunkHolder chunkHolder, int x, int z, int indent, int maxDepth) {
+        if (seenChunks.contains(chunkHolder)) {
+            return;
+        }
+        if (indent > maxDepth) {
+            return;
+        }
+        seenChunks.add(chunkHolder);
+        String indentStr = StringUtils.repeat("  ", indent);
+        if (chunkHolder == null) {
+            PaperFileIOThread.LOGGER.log(Level.ERROR, indentStr + "Chunk Holder - null for (" + x +"," + z +")");
+        } else {
+            IChunk chunk = chunkHolder.getAvailableChunkNow();
+            net.minecraft.world.chunk.ChunkStatus holderStatus = chunkHolder.getChunkHolderStatus();
+            PaperFileIOThread.LOGGER.log(Level.ERROR, indentStr + "Chunk Holder - non-null");
+            PaperFileIOThread.LOGGER.log(Level.ERROR, indentStr + "Chunk Status - " + ((chunk == null) ? "null chunk" : chunk.func_201589_g().toString()));
+            PaperFileIOThread.LOGGER.log(Level.ERROR, indentStr + "Chunk Ticket Status - "  + ChunkHolder.func_219278_b(chunkHolder.func_219299_i()));
+            PaperFileIOThread.LOGGER.log(Level.ERROR, indentStr + "Chunk Holder Status - " + ((holderStatus == null) ? "null" : holderStatus.toString()));
+        }
+    }
+
+    public static void initGlobalLoadThreads(int threads) {
+        if (threads <= 0 || globalWorkers != null) {
+            return;
+        }
+
+        globalWorkers = new QueueExecutorThread[threads];
+        globalQueue = new PrioritizedTaskQueue<>();
+        globalUrgentQueue = new PrioritizedTaskQueue<>();
+
+        for (int i = 0; i < threads; ++i) {
+            globalWorkers[i] = new QueueExecutorThread<>(globalQueue, (long)0.10e6); //0.1ms
+            globalWorkers[i].setName("Paper Async Chunk Task Thread #" + i);
+            globalWorkers[i].setPriority(Thread.NORM_PRIORITY - 1);
+            globalWorkers[i].setUncaughtExceptionHandler((final Thread thread, final Throwable throwable) -> {
+                PaperFileIOThread.LOGGER.fatal("Thread '" + thread.getName() + "' threw an uncaught exception!", throwable);
+            });
+
+            globalWorkers[i].start();
+        }
+
+        globalUrgentWorker = new QueueExecutorThread<>(globalUrgentQueue, (long)0.10e6); //0.1ms
+        globalUrgentWorker.setName("Paper Async Chunk Urgent Task Thread");
+        globalUrgentWorker.setPriority(Thread.NORM_PRIORITY+1);
+        globalUrgentWorker.setUncaughtExceptionHandler((final Thread thread, final Throwable throwable) -> {
+            PaperFileIOThread.LOGGER.fatal("Thread '" + thread.getName() + "' threw an uncaught exception!", throwable);
+        });
+
+        globalUrgentWorker.start();
+    }
+
+    /**
+     * Creates this chunk task manager to operate off the specified number of threads. If the specified number of threads is
+     * less-than or equal to 0, then this chunk task manager will operate off of the world's chunk task queue.
+     * @param world Specified world.
+     * @param threads Specified number of threads.
+     * @see net.minecraft.world.server.ServerChunkProvider#field_217243_i
+     */
+    public ChunkTaskManager(final ServerWorld world, final int threads) {
+        this.world = world;
+        this.workers = threads <= 0 ? null : new QueueExecutorThread[threads];
+        this.queue = new PrioritizedTaskQueue<>();
+        this.perWorldQueue = true;
+
+        for (int i = 0; i < threads; ++i) {
+            this.workers[i] = new QueueExecutorThread<>(this.queue, (long)0.10e6); //0.1ms
+            this.workers[i].setName("Async chunk loader thread #" + i +  " for world: " + world.getWorld().getName());
+            this.workers[i].setPriority(Thread.NORM_PRIORITY - 1);
+            this.workers[i].setUncaughtExceptionHandler((final Thread thread, final Throwable throwable) -> {
+                PaperFileIOThread.LOGGER.fatal("Thread '" + thread.getName() + "' threw an uncaught exception!", throwable);
+            });
+
+            this.workers[i].start();
+        }
+    }
+
+    /**
+     * Creates the chunk task manager to work from the global workers. When {@link #close(boolean)} is invoked,
+     * the global queue is not shutdown. If the global workers is configured to be disabled or use 0 threads, then
+     * this chunk task manager will operate off of the world's chunk task queue.
+     * @param world The world that this task manager is responsible for
+     * @see net.minecraft.world.server.ServerChunkProvider#field_217243_i
+     */
+    public ChunkTaskManager(final ServerWorld world) {
+        this.world = world;
+        this.workers = globalWorkers;
+        this.queue = globalQueue;
+        this.perWorldQueue = false;
+    }
+
+    public boolean pollNextChunkTask() {
+        final ChunkTask task = this.chunkTasks.poll();
+
+        if (task != null) {
+            task.run();
+            return true;
+        }
+        return false;
+    }
+
+    /**
+     * Polls and runs the next available chunk wait queue task. This is to be used when the server is waiting on a chunk queue.
+     * (per-world can cause issues if all the worker threads are blocked waiting for a response from the main thread)
+     */
+    public static boolean pollChunkWaitQueue() {
+        final Runnable run = CHUNK_WAIT_QUEUE.poll();
+        if (run != null) {
+            run.run();
+            return true;
+        }
+        return false;
+    }
+
+    /**
+     * Queues a chunk wait task. Note that this will execute out of order with respect to tasks scheduled on a world's
+     * chunk task queue, since this is the global chunk wait queue.
+     */
+    public static void queueChunkWaitTask(final Runnable runnable) {
+        CHUNK_WAIT_QUEUE.add(runnable);
+    }
+
+    private static void drainChunkWaitQueue() {
+        Runnable run;
+        while ((run = CHUNK_WAIT_QUEUE.poll()) != null) {
+            run.run();
+        }
+    }
+
+    /**
+     * The exact same as {@link #scheduleChunkLoad(int, int, int, Consumer, boolean)}, except that the chunk data is provided as
+     * the {@code data} parameter.
+     */
+    public ChunkLoadTask scheduleChunkLoad(final int chunkX, final int chunkZ, final int priority,
+                                           final Consumer<ChunkSerializer.InProgressChunkHolder> onComplete,
+                                           final boolean intendingToBlock, final CompletableFuture<CompoundNBT> dataFuture) {
+        final ServerWorld world = this.world;
+
+        return this.chunkLoadTasks.compute(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)), (final Long keyInMap, final ChunkLoadTask valueInMap) -> {
+            if (valueInMap != null) {
+                if (!valueInMap.cancelled) {
+                    throw new IllegalStateException("Double scheduling chunk load for task: " + valueInMap.toString());
+                }
+                valueInMap.cancelled = false;
+                valueInMap.onComplete = onComplete;
+                return valueInMap;
+            }
+
+            final ChunkLoadTask ret = new ChunkLoadTask(world, chunkX, chunkZ, priority, ChunkTaskManager.this, onComplete);
+
+            dataFuture.thenAccept((final CompoundNBT data) -> {
+                final boolean failed = data == PaperFileIOThread.FAILURE_VALUE;
+                PaperFileIOThread.Holder.INSTANCE.loadChunkDataAsync(world, chunkX, chunkZ, priority, (final PaperFileIOThread.ChunkData chunkData) -> {
+                    ret.chunkData = chunkData;
+                    if (!failed) {
+                        chunkData.chunkData = data;
+                    }
+                    ChunkTaskManager.this.internalSchedule(ret); // only schedule to the worker threads here
+                }, true, failed, intendingToBlock); // read data off disk if the future fails
+            });
+
+            return ret;
+        });
+    }
+
+    public void cancelChunkLoad(final int chunkX, final int chunkZ) {
+        this.chunkLoadTasks.compute(IOUtil.getCoordinateKey(chunkX, chunkZ), (final Long keyInMap, final ChunkLoadTask valueInMap) -> {
+            if (valueInMap == null) {
+                return null;
+            }
+
+            if (valueInMap.cancelled) {
+                PaperFileIOThread.LOGGER.warn("Task " + valueInMap.toString() + " is already cancelled!");
+            }
+            valueInMap.cancelled = true;
+            if (valueInMap.cancel()) {
+                return null;
+            }
+
+            return valueInMap;
+        });
+    }
+
+    /**
+     * Schedules an asynchronous chunk load for the specified coordinates. The onComplete parameter may be invoked asynchronously
+     * on a worker thread or on the world's chunk executor queue. As such the code that is executed for the parameter should be
+     * carefully chosen.
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     * @param priority Priority for this task
+     * @param onComplete The consumer to invoke with the {@link net.minecraft.world.chunk.storage.ChunkSerializer.InProgressChunkHolder} object once this task is complete
+     * @param intendingToBlock Whether the caller is intending to block on this task completing (this is a performance tune, and has no adverse side-effects)
+     * @return The {@link ChunkLoadTask} associated with
+     */
+    public ChunkLoadTask scheduleChunkLoad(final int chunkX, final int chunkZ, final int priority,
+                                           final Consumer<ChunkSerializer.InProgressChunkHolder> onComplete,
+                                           final boolean intendingToBlock) {
+        final ServerWorld world = this.world;
+
+        return this.chunkLoadTasks.compute(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)), (final Long keyInMap, final ChunkLoadTask valueInMap) -> {
+            if (valueInMap != null) {
+                if (!valueInMap.cancelled) {
+                    throw new IllegalStateException("Double scheduling chunk load for task: " + valueInMap.toString());
+                }
+                valueInMap.cancelled = false;
+                valueInMap.onComplete = onComplete;
+                return valueInMap;
+            }
+
+            final ChunkLoadTask ret = new ChunkLoadTask(world, chunkX, chunkZ, priority, ChunkTaskManager.this, onComplete);
+
+            PaperFileIOThread.Holder.INSTANCE.loadChunkDataAsync(world, chunkX, chunkZ, priority, (final PaperFileIOThread.ChunkData chunkData) -> {
+                ret.chunkData = chunkData;
+                ChunkTaskManager.this.internalSchedule(ret); // only schedule to the worker threads here
+            }, true, true, intendingToBlock);
+
+            return ret;
+        });
+    }
+
+    /**
+     * Schedules an async save for the specified chunk. The chunk, at the beginning of this call, must be completely unloaded
+     * from the world.
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     * @param priority Priority for this task
+     * @param asyncSaveData Async save data. See {@link ChunkSerializer#getAsyncSaveData(ServerWorld, IChunk)}
+     * @param chunk Chunk to save
+     * @return The {@link ChunkSaveTask} associated with the save task.
+     */
+    public ChunkSaveTask scheduleChunkSave(final int chunkX, final int chunkZ, final int priority,
+                                           final ChunkSerializer.AsyncSaveData asyncSaveData,
+                                           final IChunk chunk) {
+        AsyncCatcher.catchOp("chunk save schedule");
+
+        final ServerWorld world = this.world;
+
+        return this.chunkSaveTasks.compute(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)), (final Long keyInMap, final ChunkSaveTask valueInMap) -> {
+            if (valueInMap != null) {
+                throw new IllegalStateException("Double scheduling chunk save for task: " + valueInMap.toString());
+            }
+
+            final ChunkSaveTask ret = new ChunkSaveTask(world, chunkX, chunkZ, priority, ChunkTaskManager.this, asyncSaveData, chunk);
+
+            ChunkTaskManager.this.internalSchedule(ret);
+
+            return ret;
+        });
+    }
+
+    /**
+     * Returns a completable future which will be completed with the <b>un-copied</b> chunk data for an in progress async save.
+     * Returns {@code null} if no save is in progress.
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     */
+    public CompletableFuture<CompoundNBT> getChunkSaveFuture(final int chunkX, final int chunkZ) {
+        final ChunkSaveTask chunkSaveTask = this.chunkSaveTasks.get(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)));
+        if (chunkSaveTask == null) {
+            return null;
+        }
+        return chunkSaveTask.onComplete;
+    }
+
+    /**
+     * Returns the chunk object being used to serialize data async for an unloaded chunk. Note that modifying this chunk
+     * is not safe to do as another thread is handling its save. The chunk is also not loaded into the world.
+     * @param chunkX Chunk's x coordinate
+     * @param chunkZ Chunk's z coordinate
+     * @return Chunk object for an in-progress async save, or {@code null} if no save is in progress
+     */
+    public IChunk getChunkInSaveProgress(final int chunkX, final int chunkZ) {
+        final ChunkSaveTask chunkSaveTask = this.chunkSaveTasks.get(Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ)));
+        if (chunkSaveTask == null) {
+            return null;
+        }
+        return chunkSaveTask.chunk;
+    }
+
+    public void flush() {
+        // flush here since we schedule tasks on the IO thread that can schedule tasks here
+        drainChunkWaitQueue();
+        PaperFileIOThread.Holder.INSTANCE.flush();
+        drainChunkWaitQueue();
+
+        if (this.workers == null) {
+            if (Bukkit.isPrimaryThread() || MinecraftServer.getServer().hasStopped()) {
+                ((ThreadTaskExecutor<Runnable>)this.world.func_72863_F().field_217243_i).func_213160_bf();
+            } else {
+                CompletableFuture<Void> wait = new CompletableFuture<>();
+                MinecraftServer.getServer().scheduleOnMain(() -> {
+                    ((ThreadTaskExecutor<Runnable>)this.world.func_72863_F().field_217243_i).func_213160_bf();
+                });
+                wait.join();
+            }
+        } else {
+            for (final QueueExecutorThread<ChunkTask> worker : this.workers) {
+                worker.flush();
+            }
+        }
+        if (globalUrgentWorker != null) globalUrgentWorker.flush();
+
+        // flush again since tasks we execute async saves
+        drainChunkWaitQueue();
+        PaperFileIOThread.Holder.INSTANCE.flush();
+    }
+
+    public void close(final boolean wait) {
+        // flush here since we schedule tasks on the IO thread that can schedule tasks to this task manager
+        // we do this regardless of the wait param since after we invoke close no tasks can be queued
+        PaperFileIOThread.Holder.INSTANCE.flush();
+
+        if (this.workers == null) {
+            if (wait) {
+                this.flush();
+            }
+            return;
+        }
+
+        if (this.workers != globalWorkers) {
+            for (final QueueExecutorThread<ChunkTask> worker : this.workers) {
+                worker.close(false, this.perWorldQueue);
+            }
+        }
+
+        if (wait) {
+            this.flush();
+        }
+    }
+
+    public void raisePriority(final int chunkX, final int chunkZ, final int priority) {
+        final Long chunkKey = Long.valueOf(IOUtil.getCoordinateKey(chunkX, chunkZ));
+
+        ChunkTask chunkSaveTask = this.chunkSaveTasks.get(chunkKey);
+        if (chunkSaveTask != null) {
+            // don't bump save into urgent queue
+            raiseTaskPriority(chunkSaveTask, priority != PrioritizedTaskQueue.HIGHEST_PRIORITY ? priority : PrioritizedTaskQueue.HIGH_PRIORITY);
+        }
+
+        ChunkLoadTask chunkLoadTask = this.chunkLoadTasks.get(chunkKey);
+        if (chunkLoadTask != null) {
+            raiseTaskPriority(chunkLoadTask, priority);
+        }
+    }
+
+    private void raiseTaskPriority(ChunkTask task, int priority) {
+        final boolean raised = task.raisePriority(priority);
+        if (task.isScheduled() && raised && this.workers != null) {
+            // only notify if we're in queue to be executed
+            if (priority == PrioritizedTaskQueue.HIGHEST_PRIORITY) {
+                // was in another queue but became urgent later, add to urgent queue and the previous
+                // queue will just have to ignore this task if it has already been started.
+                // Ultimately, we now have 2 potential queues that can pull it out whoever gets it first
+                // but the urgent queue has dedicated thread(s) so it's likely to win....
+                globalUrgentQueue.add(task);
+                this.internalScheduleNotifyUrgent();
+            } else {
+                this.internalScheduleNotify();
+            }
+        }
+    }
+
+    protected void internalSchedule(final ChunkTask task) {
+        if (this.workers == null) {
+            this.chunkTasks.add(task);
+            return;
+        }
+
+        // It's important we order the task to be executed before notifying. Avoid a race condition where the worker thread
+        // wakes up and goes to sleep before we actually schedule (or it's just about to sleep)
+        if (task.getPriority() == PrioritizedTaskQueue.HIGHEST_PRIORITY) {
+            globalUrgentQueue.add(task);
+            this.internalScheduleNotifyUrgent();
+        } else {
+            this.queue.add(task);
+            this.internalScheduleNotify();
+        }
+
+    }
+
+    protected void internalScheduleNotify() {
+        if (this.workers == null) {
+            return;
+        }
+        for (final QueueExecutorThread<ChunkTask> worker : this.workers) {
+            if (worker.notifyTasks()) {
+                // break here since we only want to wake up one worker for scheduling one task
+                break;
+            }
+        }
+    }
+
+
+    protected void internalScheduleNotifyUrgent() {
+        if (globalUrgentWorker == null) {
+            return;
+        }
+        globalUrgentWorker.notifyTasks();
+    }
+
+}
diff --git a/src/main/java/net/minecraft/network/play/ServerPlayNetHandler.java b/src/main/java/net/minecraft/network/play/ServerPlayNetHandler.java
index c8e74e8ecd638122848137e547c0d5f41c275fef..bc79e4b83237f284d8c4d5dd74fcf3139b17c19d 100644
--- a/src/main/java/net/minecraft/network/play/ServerPlayNetHandler.java
+++ b/src/main/java/net/minecraft/network/play/ServerPlayNetHandler.java
@@ -726,6 +726,13 @@ public class ServerPlayNetHandler implements IServerPlayNetHandler {
             field_147367_d.scheduleOnMain(() -> this.func_194028_b(new TranslationTextComponent("disconnect.spam", new Object[0]))); // Paper
             return;
         }
+        // Paper start
+        String str = p_195518_1_.func_197707_b(); int index = -1;
+        if (str.length() > 64 && ((index = str.indexOf(' ')) == -1 || index >= 64)) {
+            field_147367_d.scheduleOnMain(() -> this.func_194028_b(new TranslationTextComponent("disconnect.spam", new Object[0]))); // Paper
+            return;
+        }
+        // Paper end
         // CraftBukkit end
         StringReader stringreader = new StringReader(p_195518_1_.func_197707_b());
 
diff --git a/src/main/java/net/minecraft/network/play/client/CTabCompletePacket.java b/src/main/java/net/minecraft/network/play/client/CTabCompletePacket.java
index 128b1b934b7d9bc09d4bf916fc2da4970dc7af3b..1a6b31938dddcd23682df0969d51dc35eba3aeb5 100644
--- a/src/main/java/net/minecraft/network/play/client/CTabCompletePacket.java
+++ b/src/main/java/net/minecraft/network/play/client/CTabCompletePacket.java
@@ -15,7 +15,7 @@ public class CTabCompletePacket implements IPacket<IServerPlayNetHandler> {
     @Override
     public void func_148837_a(PacketBuffer p_148837_1_) throws IOException {
         this.field_197710_a = p_148837_1_.func_150792_a();
-        this.field_197711_b = p_148837_1_.func_150789_c(32500);
+        this.field_197711_b = p_148837_1_.func_150789_c(2048);
     }
 
     @Override
diff --git a/src/main/java/net/minecraft/server/MCUtil.java b/src/main/java/net/minecraft/server/MCUtil.java
index ef8c783c7740504b68bea14d44d42b33f6ede5c2..c2aa07dc7be1c105bb84720a58b2ec3b8e0780e6 100644
--- a/src/main/java/net/minecraft/server/MCUtil.java
+++ b/src/main/java/net/minecraft/server/MCUtil.java
@@ -714,4 +714,9 @@ public final class MCUtil {
             out.print(fileData);
         }
     }
+
+    public static int getTicketLevelFor(ChunkStatus status) {
+        // TODO make sure the constant `33` is correct on future updates. See getChunkAt(int, int, ChunkStatus, boolean)
+        return 33 + ChunkStatus.getTicketLevelOffset(status);
+    }
 }
diff --git a/src/main/java/net/minecraft/server/Main.java b/src/main/java/net/minecraft/server/Main.java
index 07ff0b06d27c45b5d564d88af86daaddf573ddff..915bbe72e29c1c1fb53b3a709e740167e463d9e4 100644
--- a/src/main/java/net/minecraft/server/Main.java
+++ b/src/main/java/net/minecraft/server/Main.java
@@ -196,6 +196,7 @@ public class Main {
 
             convertable_conversionsession.a((IRegistryCustom) iregistrycustom_dimension, (SaveData) object);
             */
+            Class.forName("net.minecraft.server.VillagerTrades");// Paper - load this sync so it won't fail later async
             final DedicatedServer dedicatedserver = (DedicatedServer) MinecraftServer.func_240784_a_((thread) -> {
                 DedicatedServer dedicatedserver1 = new DedicatedServer(optionset, datapackconfiguration1, thread, iregistrycustom_dimension, convertable_conversionsession, resourcepackrepository, datapackresources, null, dedicatedserversettings, DataFixesManager.func_210901_a(), minecraftsessionservice, gameprofilerepository, usercache, LoggingChunkStatusListener::new);
 
diff --git a/src/main/java/net/minecraft/server/MinecraftServer.java b/src/main/java/net/minecraft/server/MinecraftServer.java
index e05e713ad26b6ab754ee0c9fb1ac9ccc412ba64a..bee380ff9538d1106ceae99621770947b4e9cab0 100644
--- a/src/main/java/net/minecraft/server/MinecraftServer.java
+++ b/src/main/java/net/minecraft/server/MinecraftServer.java
@@ -913,7 +913,7 @@ public abstract class MinecraftServer extends RecursiveEventLoop<TickDelayedTask
             this.func_152358_ax().b(false); // Paper
         }
         // Spigot end
-
+        com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE.close(true, true); // Paper
     }
 
     public String func_71211_k() {
diff --git a/src/main/java/net/minecraft/util/concurrent/ThreadTaskExecutor.java b/src/main/java/net/minecraft/util/concurrent/ThreadTaskExecutor.java
index dd2d0edb10b8aeeb92f4021a7411e877ae59a2ec..0259de933d22117dbadd907bb40fc68567d9ae47 100644
--- a/src/main/java/net/minecraft/util/concurrent/ThreadTaskExecutor.java
+++ b/src/main/java/net/minecraft/util/concurrent/ThreadTaskExecutor.java
@@ -91,7 +91,7 @@ public abstract class ThreadTaskExecutor<R extends Runnable> implements ITaskExe
 
     }
 
-    protected void func_213160_bf() {
+    public void func_213160_bf() { // Paper - protected -> public
         while (this.func_213168_p()) {
             ;
         }
diff --git a/src/main/java/net/minecraft/village/PointOfInterestManager.java b/src/main/java/net/minecraft/village/PointOfInterestManager.java
index 92167658bd26296e97e84d9724ce8101c634fcc3..0c7479240031e264edc3a0fb82a069fcb38744a6 100644
--- a/src/main/java/net/minecraft/village/PointOfInterestManager.java
+++ b/src/main/java/net/minecraft/village/PointOfInterestManager.java
@@ -20,6 +20,7 @@ import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 import java.util.stream.Stream;
 import net.minecraft.block.BlockState;
+import net.minecraft.nbt.CompoundNBT;
 import net.minecraft.util.SectionDistanceGraph;
 import net.minecraft.util.Util;
 import net.minecraft.util.datafix.DefaultTypeReferences;
@@ -30,14 +31,23 @@ import net.minecraft.world.IWorldReader;
 import net.minecraft.world.chunk.ChunkSection;
 import net.minecraft.world.chunk.ChunkStatus;
 import net.minecraft.world.chunk.storage.RegionSectionCache;
+import net.minecraft.world.server.ServerWorld;
 
 public class PointOfInterestManager extends RegionSectionCache<PointOfInterestData> {
 
     private final PointOfInterestManager.DistanceGraph field_219164_a = new PointOfInterestManager.DistanceGraph();
     private final LongSet field_226345_b_ = new LongOpenHashSet();
 
+    private final ServerWorld world; // Paper
+
     public PointOfInterestManager(File p_i231554_1_, DataFixer p_i231554_2_, boolean p_i231554_3_) {
-        super(p_i231554_1_, PointOfInterestData::func_234158_a_, PointOfInterestData::new, p_i231554_2_, DefaultTypeReferences.POI_CHUNK, p_i231554_3_);
+        // Paper start - add world parameter
+        this(p_i231554_1_, p_i231554_2_, p_i231554_3_, null);
+    }
+    public PointOfInterestManager(File file, DataFixer datafixer, boolean flag, ServerWorld world) {
+        super(file, PointOfInterestData::func_234158_a_, PointOfInterestData::new, datafixer, DefaultTypeReferences.POI_CHUNK, flag);
+        this.world = world;
+        // Paper end - add world parameter
     }
 
     public void func_219135_a(BlockPos p_219135_1_, PointOfInterestType p_219135_2_) {
@@ -155,7 +165,23 @@ public class PointOfInterestManager extends RegionSectionCache<PointOfInterestDa
 
     @Override
     public void func_219115_a(BooleanSupplier p_219115_1_) {
-        super.func_219115_a(p_219115_1_);
+        // Paper start - async chunk io
+        if (this.world == null) {
+            super.func_219115_a(p_219115_1_);
+        } else {
+            //super.a(booleansupplier); // re-implement below
+            while (!((RegionSectionCache)this).field_219122_d.isEmpty() && p_219115_1_.getAsBoolean()) {
+                ChunkPos chunkcoordintpair = SectionPos.func_218170_a(((RegionSectionCache)this).field_219122_d.firstLong()).func_218155_u();
+
+                CompoundNBT data;
+                try (co.aikar.timings.Timing ignored1 = this.world.timings.poiSaveDataSerialization.startTiming()) {
+                    data = this.getData(chunkcoordintpair);
+                }
+                com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE.scheduleSave(this.world,
+                    chunkcoordintpair.field_77276_a, chunkcoordintpair.field_77275_b, data, null, com.destroystokyo.paper.io.PrioritizedTaskQueue.LOW_PRIORITY);
+            }
+        }
+        // Paper end
         this.field_219164_a.func_215563_a();
     }
 
@@ -255,6 +281,35 @@ public class PointOfInterestManager extends RegionSectionCache<PointOfInterestDa
         }
     }
 
+    // Paper start - Asynchronous chunk io
+    @javax.annotation.Nullable
+    @Override
+    public CompoundNBT func_219099_e(ChunkPos p_219099_1_) throws java.io.IOException {
+        if (this.world != null && Thread.currentThread() != com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE) {
+            CompoundNBT ret = com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE
+                .loadChunkDataAsyncFuture(this.world, p_219099_1_.field_77276_a, p_219099_1_.field_77275_b, com.destroystokyo.paper.io.IOUtil.getPriorityForCurrentThread(),
+                    true, false, true).join().poiData;
+
+            if (ret == com.destroystokyo.paper.io.PaperFileIOThread.FAILURE_VALUE) {
+                throw new java.io.IOException("See logs for further detail");
+            }
+            return ret;
+        }
+        return super.func_219099_e(p_219099_1_);
+    }
+
+    @Override
+    public void func_219100_a(ChunkPos p_219100_1_, CompoundNBT p_219100_2_) throws java.io.IOException {
+        if (this.world != null && Thread.currentThread() != com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE) {
+            com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE.scheduleSave(
+                this.world, p_219100_1_.field_77276_a, p_219100_1_.field_77275_b, p_219100_2_, null,
+                com.destroystokyo.paper.io.IOUtil.getPriorityForCurrentThread());
+            return;
+        }
+        super.func_219100_a(p_219100_1_, p_219100_2_);
+    }
+    // Paper end
+
     public static enum Status {
 
         HAS_SPACE(PointOfInterest::func_218265_d), IS_OCCUPIED(PointOfInterest::func_218263_e), ANY((villageplacerecord) -> {
diff --git a/src/main/java/net/minecraft/world/NextTickListEntry.java b/src/main/java/net/minecraft/world/NextTickListEntry.java
index 01a151e15b4f44c2f2e677d24fb29b85369fd5b5..c08c72c9fb8bb3a1ce1b8fd732ea335ae4f66104 100644
--- a/src/main/java/net/minecraft/world/NextTickListEntry.java
+++ b/src/main/java/net/minecraft/world/NextTickListEntry.java
@@ -5,7 +5,7 @@ import net.minecraft.util.math.BlockPos;
 
 public class NextTickListEntry<T> {
 
-    private static long field_77177_f;
+    private static final java.util.concurrent.atomic.AtomicLong COUNTER = new java.util.concurrent.atomic.AtomicLong(); // Paper - async chunk loading
     private final T field_151352_g;
     public final BlockPos field_180282_a;
     public final long field_235017_b_;
@@ -17,7 +17,7 @@ public class NextTickListEntry<T> {
     }
 
     public NextTickListEntry(BlockPos blockposition, T t0, long i, TickPriority ticklistpriority) {
-        this.field_77178_g = (long) (NextTickListEntry.field_77177_f++);
+        this.field_77178_g = (long) (NextTickListEntry.COUNTER.getAndIncrement()); // Paper - async chunk loading
         this.field_180282_a = blockposition.func_185334_h();
         this.field_151352_g = t0;
         this.field_235017_b_ = i;
diff --git a/src/main/java/net/minecraft/world/chunk/ChunkStatus.java b/src/main/java/net/minecraft/world/chunk/ChunkStatus.java
index e3e5c65760d41c0970af69ab216b7181eecc86da..8890c3eef82d6387387e1e81271d7b02c10a610f 100644
--- a/src/main/java/net/minecraft/world/chunk/ChunkStatus.java
+++ b/src/main/java/net/minecraft/world/chunk/ChunkStatus.java
@@ -171,6 +171,7 @@ public class ChunkStatus {
         return ChunkStatus.field_222620_p.size();
     }
 
+    public static int getTicketLevelOffset(ChunkStatus status) { return ChunkStatus.func_222599_a(status); } // Paper - OBFHELPER
     public static int func_222599_a(ChunkStatus p_222599_0_) {
         return ChunkStatus.field_222621_q.getInt(p_222599_0_.func_222584_c());
     }
@@ -186,6 +187,7 @@ public class ChunkStatus {
         this.field_222623_s = chunkstatus == null ? 0 : chunkstatus.func_222584_c() + 1;
     }
 
+    public final int getStatusIndex() { return func_222584_c(); } // Paper - OBFHELPER
     public int func_222584_c() {
         return this.field_222623_s;
     }
@@ -194,7 +196,7 @@ public class ChunkStatus {
         return this.field_202130_j;
     }
 
-    public ChunkStatus getPreviousStatus() { return this.func_222593_e(); } // Paper - OBFHELPER
+    public final ChunkStatus getPreviousStatus() { return this.func_222593_e(); } // Paper - OBFHELPER
     public ChunkStatus func_222593_e() {
         return this.field_222624_t;
     }
@@ -207,6 +209,7 @@ public class ChunkStatus {
         return this.field_225500_w.doWork(this, p_223201_1_, p_223201_2_, p_223201_3_, p_223201_4_, p_223201_5_);
     }
 
+    public final int getNeighborRadius() { return this.func_202128_c(); } // Paper - OBFHELPER
     public int func_202128_c() {
         return this.field_202133_m;
     }
@@ -234,6 +237,7 @@ public class ChunkStatus {
         return this.field_222625_x;
     }
 
+    public final boolean isAtLeastStatus(ChunkStatus chunkstatus) { return func_209003_a(chunkstatus); } // Paper - OBFHELPER
     public boolean func_209003_a(ChunkStatus p_209003_1_) {
         return this.func_222584_c() >= p_209003_1_.func_222584_c();
     }
diff --git a/src/main/java/net/minecraft/world/chunk/NibbleArray.java b/src/main/java/net/minecraft/world/chunk/NibbleArray.java
index 42b211e498def6f69c83915bbe4786e6517efb7e..09d31e4f044dbc00f0eb0beac3779679dad9700c 100644
--- a/src/main/java/net/minecraft/world/chunk/NibbleArray.java
+++ b/src/main/java/net/minecraft/world/chunk/NibbleArray.java
@@ -72,6 +72,7 @@ public class NibbleArray {
         return this.field_76585_a;
     }
 
+    public NibbleArray copy() { return this.func_215654_b(); } // Paper - OBFHELPER
     public NibbleArray func_215654_b() {
         return this.field_76585_a == null ? new NibbleArray() : new NibbleArray((byte[]) this.field_76585_a.clone());
     }
diff --git a/src/main/java/net/minecraft/world/chunk/storage/ChunkLoader.java b/src/main/java/net/minecraft/world/chunk/storage/ChunkLoader.java
index 4a5533854492cc0d877d9f7fe0f1c4e8a6b3ff49..241dbdab436dc08a1acecd1ab7de30edf5e1876e 100644
--- a/src/main/java/net/minecraft/world/chunk/storage/ChunkLoader.java
+++ b/src/main/java/net/minecraft/world/chunk/storage/ChunkLoader.java
@@ -3,6 +3,10 @@ package net.minecraft.world.chunk.storage;
 import com.mojang.datafixers.DataFixer;
 import java.io.File;
 import java.io.IOException;
+// Paper start
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.CompletionException;
+// Paper end
 import java.util.function.Supplier;
 import javax.annotation.Nullable;
 import net.minecraft.nbt.CompoundNBT;
@@ -21,32 +25,41 @@ import net.minecraft.world.storage.DimensionSavedDataManager;
 
 public class ChunkLoader implements AutoCloseable {
 
-    private final IOWorker field_227077_a_; public IOWorker getIOWorker() { return field_227077_a_; } // Paper - OBFHELPER
+    // Paper - OBFHELPER - nuke IOWorker
     protected final DataFixer field_219168_b;
     @Nullable
-    private LegacyStructureDataUtil field_219167_a;
+    private volatile LegacyStructureDataUtil field_219167_a; // Paper - async chunk loading
+
+    private final Object persistentDataLock = new Object(); // Paper
+    protected final RegionFileCache regionFileCache;
 
     public ChunkLoader(File p_i231889_1_, DataFixer p_i231889_2_, boolean p_i231889_3_) {
+        this.regionFileCache = new RegionFileCache(p_i231889_1_, p_i231889_3_); // Paper - nuke IOWorker
         this.field_219168_b = p_i231889_2_;
-        this.field_227077_a_ = new IOWorker(p_i231889_1_, p_i231889_3_, "chunk");
+        // Paper - nuke IOWorker
     }
 
     // CraftBukkit start
     private boolean check(ServerChunkProvider cps, int x, int z) throws IOException {
         ChunkPos pos = new ChunkPos(x, z);
         if (cps != null) {
-            com.google.common.base.Preconditions.checkState(org.bukkit.Bukkit.isPrimaryThread(), "primary thread");
-            if (cps.func_73149_a(x, z)) {
+            //com.google.common.base.Preconditions.checkState(org.bukkit.Bukkit.isPrimaryThread(), "primary thread"); // Paper - this function is now MT-Safe
+            if (cps.getChunkAtIfCachedImmediately(x, z) != null) { // Paper - isLoaded is a ticket level check, not a chunk loaded check!
                 return true;
             }
         }
 
-        CompoundNBT nbt = func_227078_e_(pos);
-        if (nbt != null) {
-            CompoundNBT level = nbt.func_74775_l("Level");
-            if (level.func_74767_n("TerrainPopulated")) {
-                return true;
-            }
+
+            // Paper start - prioritize
+            CompoundNBT nbt = cps == null ? func_227078_e_(pos) :
+                com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE.loadChunkData((ServerWorld)cps.func_212864_k_(), x, z,
+                    com.destroystokyo.paper.io.PrioritizedTaskQueue.HIGHER_PRIORITY, false, true).chunkData;
+            // Paper end
+            if (nbt != null) {
+                CompoundNBT level = nbt.func_74775_l("Level");
+                if (level.func_74767_n("TerrainPopulated")) {
+                    return true;
+                }
 
             ChunkStatus status = ChunkStatus.func_222591_a(level.func_74779_i("Status"));
             if (status != null && status.func_209003_a(ChunkStatus.field_222613_i)) {
@@ -77,11 +90,13 @@ public class ChunkLoader implements AutoCloseable {
         if (i < 1493) {
             nbttagcompound = NBTUtil.func_210821_a(this.field_219168_b, DefaultTypeReferences.CHUNK, nbttagcompound, i, 1493);
             if (nbttagcompound.func_74775_l("Level").func_74767_n("hasLegacyStructureData")) {
+                synchronized (this.persistentDataLock) { // Paper - Async chunk loading
                 if (this.field_219167_a == null) {
                     this.field_219167_a = LegacyStructureDataUtil.func_236992_a_(resourcekey, (DimensionSavedDataManager) supplier.get());
                 }
 
                 nbttagcompound = this.field_219167_a.func_212181_a(nbttagcompound);
+                } // Paper - Async chunk loading
             }
         }
 
@@ -99,22 +114,20 @@ public class ChunkLoader implements AutoCloseable {
 
     @Nullable
     public CompoundNBT func_227078_e_(ChunkPos p_227078_1_) throws IOException {
-        return this.field_227077_a_.func_227090_a_(p_227078_1_);
+        return this.regionFileCache.func_219099_e(p_227078_1_);
     }
 
-    public void func_219100_a(ChunkPos p_219100_1_, CompoundNBT p_219100_2_) {
-        this.field_227077_a_.func_227093_a_(p_219100_1_, p_219100_2_);
+    public void func_219100_a(ChunkPos p_219100_1_, CompoundNBT p_219100_2_) throws IOException { write(p_219100_1_, p_219100_2_); } // Paper OBFHELPER
+    public void write(ChunkPos chunkcoordintpair, CompoundNBT nbttagcompound) throws IOException { // Paper - OBFHELPER - (Switched around for safety)
+        this.regionFileCache.func_219100_a(chunkcoordintpair, nbttagcompound);
         if (this.field_219167_a != null) {
-            this.field_219167_a.func_208216_a(p_219100_1_.func_201841_a());
+            synchronized (this.persistentDataLock) { // Paper - Async chunk loading
+            this.field_219167_a.func_208216_a(chunkcoordintpair.func_201841_a());
+            } // Paper - Async chunk loading}
         }
-
-    }
-
-    public void func_227079_i_() {
-        this.field_227077_a_.func_227088_a_().join();
     }
 
     public void close() throws IOException {
-        this.field_227077_a_.close();
+        this.regionFileCache.close();
     }
 }
diff --git a/src/main/java/net/minecraft/world/chunk/storage/ChunkSerializer.java b/src/main/java/net/minecraft/world/chunk/storage/ChunkSerializer.java
index 8e434de3ea8b0943a6e5e04b7d0cbb2d7b6fb842..bcebae34d3bfd81df2c66ba6a6e2f636036c36eb 100644
--- a/src/main/java/net/minecraft/world/chunk/storage/ChunkSerializer.java
+++ b/src/main/java/net/minecraft/world/chunk/storage/ChunkSerializer.java
@@ -6,6 +6,7 @@ import it.unimi.dsi.fastutil.longs.LongOpenHashSet;
 import it.unimi.dsi.fastutil.longs.LongSet;
 import it.unimi.dsi.fastutil.shorts.ShortList;
 import it.unimi.dsi.fastutil.shorts.ShortListIterator;
+import java.util.ArrayDeque; // Paper
 import java.util.Arrays;
 import java.util.BitSet;
 import java.util.EnumSet;
@@ -67,34 +68,58 @@ public class ChunkSerializer {
 
     private static final Logger field_222658_a = LogManager.getLogger();
 
+    // Paper start
+    public static final class InProgressChunkHolder {
+
+        public final ChunkPrimer protoChunk;
+        public final ArrayDeque<Runnable> tasks;
+
+        public CompoundNBT poiData;
+
+        public InProgressChunkHolder(final ChunkPrimer protoChunk, final ArrayDeque<Runnable> tasks) {
+            this.protoChunk = protoChunk;
+            this.tasks = tasks;
+        }
+    }
+
     public static ChunkPrimer func_222656_a(ServerWorld p_222656_0_, TemplateManager p_222656_1_, PointOfInterestManager p_222656_2_, ChunkPos p_222656_3_, CompoundNBT p_222656_4_) {
-        ChunkGenerator chunkgenerator = p_222656_0_.func_72863_F().func_201711_g();
+        net.minecraft.world.chunk.storage.ChunkSerializer.InProgressChunkHolder holder = loadChunk(p_222656_0_, p_222656_1_, p_222656_2_, p_222656_3_, p_222656_4_, true);
+        holder.tasks.forEach(Runnable::run);
+        return holder.protoChunk;
+    }
+
+    public static net.minecraft.world.chunk.storage.ChunkSerializer.InProgressChunkHolder loadChunk(ServerWorld worldserver, TemplateManager definedstructuremanager, PointOfInterestManager villageplace, ChunkPos chunkcoordintpair, CompoundNBT nbttagcompound, boolean distinguish) {
+        ArrayDeque<Runnable> tasksToExecuteOnMain = new ArrayDeque<>();
+        // Paper end
+        ChunkGenerator chunkgenerator = worldserver.func_72863_F().func_201711_g();
         BiomeProvider worldchunkmanager = chunkgenerator.func_202090_b();
-        CompoundNBT nbttagcompound1 = p_222656_4_.func_74775_l("Level");
+        CompoundNBT nbttagcompound1 = nbttagcompound.func_74775_l("Level");
         ChunkPos chunkcoordintpair1 = new ChunkPos(nbttagcompound1.func_74762_e("xPos"), nbttagcompound1.func_74762_e("zPos"));
 
-        if (!Objects.equals(p_222656_3_, chunkcoordintpair1)) {
-            ChunkSerializer.field_222658_a.error("Chunk file at {} is in the wrong location; relocating. (Expected {}, got {})", p_222656_3_, p_222656_3_, chunkcoordintpair1);
+        if (!Objects.equals(chunkcoordintpair, chunkcoordintpair1)) {
+            ChunkSerializer.field_222658_a.error("Chunk file at {} is in the wrong location; relocating. (Expected {}, got {})", chunkcoordintpair, chunkcoordintpair, chunkcoordintpair1);
         }
 
-        BiomeContainer biomestorage = new BiomeContainer(p_222656_0_.func_241828_r().func_243612_b(Registry.field_239720_u_), p_222656_3_, worldchunkmanager, nbttagcompound1.func_150297_b("Biomes", 11) ? nbttagcompound1.func_74759_k("Biomes") : null);
+        BiomeContainer biomestorage = new BiomeContainer(worldserver.func_241828_r().func_243612_b(Registry.field_239720_u_), chunkcoordintpair, worldchunkmanager, nbttagcompound1.func_150297_b("Biomes", 11) ? nbttagcompound1.func_74759_k("Biomes") : null);
         UpgradeData chunkconverter = nbttagcompound1.func_150297_b("UpgradeData", 10) ? new UpgradeData(nbttagcompound1.func_74775_l("UpgradeData")) : UpgradeData.field_196994_a;
         ChunkPrimerTickList<Block> protochunkticklist = new ChunkPrimerTickList<>((block) -> {
             return block == null || block.func_176223_P().func_196958_f();
-        }, p_222656_3_, nbttagcompound1.func_150295_c("ToBeTicked", 9));
+        }, chunkcoordintpair, nbttagcompound1.func_150295_c("ToBeTicked", 9));
         ChunkPrimerTickList<Fluid> protochunkticklist1 = new ChunkPrimerTickList<>((fluidtype) -> {
             return fluidtype == null || fluidtype == Fluids.field_204541_a;
-        }, p_222656_3_, nbttagcompound1.func_150295_c("LiquidsToBeTicked", 9));
+        }, chunkcoordintpair, nbttagcompound1.func_150295_c("LiquidsToBeTicked", 9));
         boolean flag = nbttagcompound1.func_74767_n("isLightOn");
         ListNBT nbttaglist = nbttagcompound1.func_150295_c("Sections", 10);
         boolean flag1 = true;
         ChunkSection[] achunksection = new ChunkSection[16];
-        boolean flag2 = p_222656_0_.func_230315_m_().func_218272_d();
-        ServerChunkProvider chunkproviderserver = p_222656_0_.func_72863_F();
+        boolean flag2 = worldserver.func_230315_m_().func_218272_d();
+        ServerChunkProvider chunkproviderserver = worldserver.func_72863_F();
         WorldLightManager lightengine = chunkproviderserver.func_212863_j_();
 
         if (flag) {
-            lightengine.func_223115_b(p_222656_3_, true);
+            tasksToExecuteOnMain.add(() -> { // Paper - delay this task since we're executing off-main
+                lightengine.func_223115_b(chunkcoordintpair, true);
+            }); // Paper - delay this task since we're executing off-main
         }
 
         for (int i = 0; i < nbttaglist.size(); ++i) {
@@ -102,7 +127,7 @@ public class ChunkSerializer {
             byte b0 = nbttagcompound2.func_74771_c("Y");
 
             if (nbttagcompound2.func_150297_b("Palette", 9) && nbttagcompound2.func_150297_b("BlockStates", 12)) {
-                ChunkSection chunksection = new ChunkSection(b0 << 4, null, p_222656_0_, false); // Paper - Anti-Xray - Add parameters
+                ChunkSection chunksection = new ChunkSection(b0 << 4, null, worldserver, false); // Paper - Anti-Xray - Add parameters
 
                 chunksection.func_186049_g().func_222642_a(nbttagcompound2.func_150295_c("Palette", 10), nbttagcompound2.func_197645_o("BlockStates"));
                 chunksection.func_76672_e();
@@ -110,22 +135,34 @@ public class ChunkSerializer {
                     achunksection[b0] = chunksection;
                 }
 
-                p_222656_2_.func_219139_a(p_222656_3_, chunksection);
+                tasksToExecuteOnMain.add(() -> { // Paper - delay this task since we're executing off-main
+                    villageplace.func_219139_a(chunkcoordintpair, chunksection);
+                }); // Paper - delay this task since we're executing off-main
             }
 
             if (flag) {
                 if (nbttagcompound2.func_150297_b("BlockLight", 7)) {
-                    lightengine.func_215574_a(LightType.BLOCK, SectionPos.func_218156_a(p_222656_3_, b0), new NibbleArray(nbttagcompound2.func_74770_j("BlockLight")), true);
+                    // Paper start - delay this task since we're executing off-main
+                    NibbleArray blockLight = new NibbleArray(nbttagcompound2.func_74770_j("BlockLight"));
+                    tasksToExecuteOnMain.add(() -> {
+                        lightengine.func_215574_a(LightType.BLOCK, SectionPos.func_218156_a(chunkcoordintpair, b0), blockLight, true);
+                    });
+                    // Paper end - delay this task since we're executing off-main
                 }
 
                 if (flag2 && nbttagcompound2.func_150297_b("SkyLight", 7)) {
-                    lightengine.func_215574_a(LightType.SKY, SectionPos.func_218156_a(p_222656_3_, b0), new NibbleArray(nbttagcompound2.func_74770_j("SkyLight")), true);
+                    // Paper start - delay this task since we're executing off-main
+                    NibbleArray skyLight = new NibbleArray(nbttagcompound2.func_74770_j("SkyLight"));
+                    tasksToExecuteOnMain.add(() -> {
+                        lightengine.func_215574_a(LightType.SKY, SectionPos.func_218156_a(chunkcoordintpair, b0), skyLight, true);
+                    });
+                    // Paper end - delay this task since we're executing off-main
                 }
             }
         }
 
         long j = nbttagcompound1.func_74763_f("InhabitedTime");
-        ChunkStatus.Type chunkstatus_type = func_222651_a(p_222656_4_);
+        ChunkStatus.Type chunkstatus_type = func_222651_a(nbttagcompound);
         Object object;
 
         if (chunkstatus_type == ChunkStatus.Type.LEVELCHUNK) {
@@ -156,7 +193,7 @@ public class ChunkSerializer {
                 object2 = protochunkticklist1;
             }
 
-            object = new Chunk(p_222656_0_.func_201672_e(), p_222656_3_, biomestorage, chunkconverter, (ITickList) object1, (ITickList) object2, j, achunksection, (chunk) -> {
+            object = new Chunk(worldserver.func_201672_e(), chunkcoordintpair, biomestorage, chunkconverter, (ITickList) object1, (ITickList) object2, j, achunksection, (chunk) -> {
                 func_222650_a(nbttagcompound1, chunk);
                 // CraftBukkit start - load chunk persistent data from nbt
                 INBT persistentBase = nbttagcompound1.func_74781_a("ChunkBukkitValues");
@@ -166,7 +203,7 @@ public class ChunkSerializer {
                 // CraftBukkit end
             });
         } else {
-            ChunkPrimer protochunk = new ChunkPrimer(p_222656_3_, chunkconverter, achunksection, protochunkticklist, protochunkticklist1, p_222656_0_); // Paper - Anti-Xray - Add parameter
+            ChunkPrimer protochunk = new ChunkPrimer(chunkcoordintpair, chunkconverter, achunksection, protochunkticklist, protochunkticklist1, worldserver); // Paper - Anti-Xray - Add parameter
 
             protochunk.func_225548_a_(biomestorage);
             object = protochunk;
@@ -177,7 +214,7 @@ public class ChunkSerializer {
             }
 
             if (!flag && protochunk.func_201589_g().func_209003_a(ChunkStatus.field_222614_j)) {
-                Iterator iterator = BlockPos.func_191531_b(p_222656_3_.func_180334_c(), 0, p_222656_3_.func_180333_d(), p_222656_3_.func_180332_e(), 255, p_222656_3_.func_180330_f()).iterator();
+                Iterator iterator = BlockPos.func_191531_b(chunkcoordintpair.func_180334_c(), 0, chunkcoordintpair.func_180333_d(), chunkcoordintpair.func_180332_e(), 255, chunkcoordintpair.func_180330_f()).iterator();
 
                 while (iterator.hasNext()) {
                     BlockPos blockposition = (BlockPos) iterator.next();
@@ -208,8 +245,8 @@ public class ChunkSerializer {
         Heightmap.func_222690_a((IChunk) object, enumset);
         CompoundNBT nbttagcompound4 = nbttagcompound1.func_74775_l("Structures");
 
-        ((IChunk) object).func_201612_a(func_235967_a_(p_222656_1_, nbttagcompound4, p_222656_0_.func_72905_C()));
-        ((IChunk) object).func_201606_b(func_227075_a_(p_222656_3_, nbttagcompound4));
+        ((IChunk) object).func_201612_a(func_235967_a_(definedstructuremanager, nbttagcompound4, worldserver.func_72905_C()));
+        ((IChunk) object).func_201606_b(func_227075_a_(chunkcoordintpair, nbttagcompound4));
         if (nbttagcompound1.func_74767_n("shouldSave")) {
             ((IChunk) object).func_177427_f(true);
         }
@@ -228,7 +265,7 @@ public class ChunkSerializer {
         }
 
         if (chunkstatus_type == ChunkStatus.Type.LEVELCHUNK) {
-            return new ChunkPrimerWrapper((Chunk) object);
+            return new net.minecraft.world.chunk.storage.ChunkSerializer.InProgressChunkHolder(new ChunkPrimerWrapper((Chunk) object), tasksToExecuteOnMain); // Paper - Async chunk loading
         } else {
             ChunkPrimer protochunk1 = (ChunkPrimer) object;
 
@@ -267,12 +304,84 @@ public class ChunkSerializer {
                 protochunk1.func_205767_a(worldgenstage_features, BitSet.valueOf(nbttagcompound5.func_74770_j(s1)));
             }
 
-            return protochunk1;
+            return new net.minecraft.world.chunk.storage.ChunkSerializer.InProgressChunkHolder(protochunk1, tasksToExecuteOnMain); // Paper - Async chunk loading
+        }
+    }
+
+    // Paper start - async chunk save for unload
+    public static final class AsyncSaveData {
+        public final NibbleArray[] blockLight; // null or size of 17 (for indices -1 through 15)
+        public final NibbleArray[] skyLight;
+
+        public final ListNBT blockTickList; // non-null if we had to go to the server's tick list
+        public final ListNBT fluidTickList; // non-null if we had to go to the server's tick list
+
+        public final long worldTime;
+
+        public AsyncSaveData(NibbleArray[] blockLight, NibbleArray[] skyLight, ListNBT blockTickList, ListNBT fluidTickList,
+                             long worldTime) {
+            this.blockLight = blockLight;
+            this.skyLight = skyLight;
+            this.blockTickList = blockTickList;
+            this.fluidTickList = fluidTickList;
+            this.worldTime = worldTime;
         }
     }
 
+    // must be called sync
+    public static net.minecraft.world.chunk.storage.ChunkSerializer.AsyncSaveData getAsyncSaveData(ServerWorld world, IChunk chunk) {
+        org.spigotmc.AsyncCatcher.catchOp("preparation of chunk data for async save");
+        ChunkPos chunkPos = chunk.func_76632_l();
+
+        ServerWorldLightManager lightenginethreaded = world.func_72863_F().func_212863_j_();
+
+        NibbleArray[] blockLight = new NibbleArray[17 - (-1)];
+        NibbleArray[] skyLight = new NibbleArray[17 - (-1)];
+
+        for (int i = -1; i < 17; ++i) {
+            NibbleArray blockArray = lightenginethreaded.func_215569_a(LightType.BLOCK).func_215612_a(SectionPos.func_218156_a(chunkPos, i));
+            NibbleArray skyArray = lightenginethreaded.func_215569_a(LightType.SKY).func_215612_a(SectionPos.func_218156_a(chunkPos, i));
+
+            // copy data for safety
+            if (blockArray != null) {
+                blockArray = blockArray.copy();
+            }
+            if (skyArray != null) {
+                skyArray = skyArray.copy();
+            }
+
+            // apply offset of 1 for -1 starting index
+            blockLight[i + 1] = blockArray;
+            skyLight[i + 1] = skyArray;
+        }
+
+        ITickList<Block> blockTickList = chunk.func_205218_i_();
+
+        ListNBT blockTickListSerialized;
+        if (blockTickList instanceof ChunkPrimerTickList || blockTickList instanceof SerializableTickList) {
+            blockTickListSerialized = null;
+        } else {
+            blockTickListSerialized = world.func_205220_G_().func_219503_a(chunkPos);
+        }
+
+        ITickList<Fluid> fluidTickList = chunk.func_212247_j();
+
+        ListNBT fluidTickListSerialized;
+        if (fluidTickList instanceof ChunkPrimerTickList || fluidTickList instanceof SerializableTickList) {
+            fluidTickListSerialized = null;
+        } else {
+            fluidTickListSerialized = world.func_205219_F_().func_219503_a(chunkPos);
+        }
+
+        return new net.minecraft.world.chunk.storage.ChunkSerializer.AsyncSaveData(blockLight, skyLight, blockTickListSerialized, fluidTickListSerialized, world.func_82737_E());
+    }
+
     public static CompoundNBT func_222645_a(ServerWorld p_222645_0_, IChunk p_222645_1_) {
-        ChunkPos chunkcoordintpair = p_222645_1_.func_76632_l();
+        return saveChunk(p_222645_0_, p_222645_1_, null);
+    }
+    public static CompoundNBT saveChunk(ServerWorld worldserver, IChunk ichunkaccess, net.minecraft.world.chunk.storage.ChunkSerializer.AsyncSaveData asyncsavedata) {
+        // Paper end
+        ChunkPos chunkcoordintpair = ichunkaccess.func_76632_l();
         CompoundNBT nbttagcompound = new CompoundNBT();
         CompoundNBT nbttagcompound1 = new CompoundNBT();
 
@@ -280,30 +389,38 @@ public class ChunkSerializer {
         nbttagcompound.func_218657_a("Level", nbttagcompound1);
         nbttagcompound1.func_74768_a("xPos", chunkcoordintpair.field_77276_a);
         nbttagcompound1.func_74768_a("zPos", chunkcoordintpair.field_77275_b);
-        nbttagcompound1.func_74772_a("LastUpdate", p_222645_0_.func_82737_E());
-        nbttagcompound1.func_74772_a("InhabitedTime", p_222645_1_.func_177416_w());
-        nbttagcompound1.func_74778_a("Status", p_222645_1_.func_201589_g().func_222596_d());
-        UpgradeData chunkconverter = p_222645_1_.func_196966_y();
+        nbttagcompound1.func_74772_a("LastUpdate", asyncsavedata != null ? asyncsavedata.worldTime : worldserver.func_82737_E()); // Paper - async chunk unloading
+        nbttagcompound1.func_74772_a("InhabitedTime", ichunkaccess.func_177416_w());
+        nbttagcompound1.func_74778_a("Status", ichunkaccess.func_201589_g().func_222596_d());
+        UpgradeData chunkconverter = ichunkaccess.func_196966_y();
 
         if (!chunkconverter.func_196988_a()) {
             nbttagcompound1.func_218657_a("UpgradeData", chunkconverter.func_196992_b());
         }
 
-        ChunkSection[] achunksection = p_222645_1_.func_76587_i();
+        ChunkSection[] achunksection = ichunkaccess.func_76587_i();
         ListNBT nbttaglist = new ListNBT();
-        ServerWorldLightManager lightenginethreaded = p_222645_0_.func_72863_F().func_212863_j_();
-        boolean flag = p_222645_1_.func_217310_r();
+        ServerWorldLightManager lightenginethreaded = worldserver.func_72863_F().func_212863_j_();
+        boolean flag = ichunkaccess.func_217310_r();
 
         CompoundNBT nbttagcompound2;
 
-        for (int i = -1; i < 17; ++i) {
+        for (int i = -1; i < 17; ++i) { // Paper - conflict on loop parameter change
             int finalI = i; // CraftBukkit - decompile errors
             ChunkSection chunksection = (ChunkSection) Arrays.stream(achunksection).filter((chunksection1) -> {
                 return chunksection1 != null && chunksection1.func_222632_g() >> 4 == finalI; // CraftBukkit - decompile errors
             }).findFirst().orElse(Chunk.field_186036_a);
-            NibbleArray nibblearray = lightenginethreaded.func_215569_a(LightType.BLOCK).func_215612_a(SectionPos.func_218156_a(chunkcoordintpair, i));
-            NibbleArray nibblearray1 = lightenginethreaded.func_215569_a(LightType.SKY).func_215612_a(SectionPos.func_218156_a(chunkcoordintpair, i));
-
+            // Paper start - async chunk save for unload
+            NibbleArray nibblearray; // block light
+            NibbleArray nibblearray1; // sky light
+            if (asyncsavedata == null) {
+                nibblearray = lightenginethreaded.func_215569_a(LightType.BLOCK).func_215612_a(SectionPos.func_218156_a(chunkcoordintpair, i)); /// Paper - diff on method change (see getAsyncSaveData)
+                nibblearray1 = lightenginethreaded.func_215569_a(LightType.SKY).func_215612_a(SectionPos.func_218156_a(chunkcoordintpair, i)); // Paper - diff on method change (see getAsyncSaveData)
+            } else {
+                nibblearray = asyncsavedata.blockLight[i + 1]; // +1 to offset the -1 starting index
+                nibblearray1 = asyncsavedata.skyLight[i + 1]; // +1 to offset the -1 starting index
+            }
+            // Paper end
             if (chunksection != Chunk.field_186036_a || nibblearray != null || nibblearray1 != null) {
                 nbttagcompound2 = new CompoundNBT();
                 nbttagcompound2.func_74774_a("Y", (byte) (i & 255));
@@ -328,21 +445,21 @@ public class ChunkSerializer {
             nbttagcompound1.func_74757_a("isLightOn", true);
         }
 
-        BiomeContainer biomestorage = p_222645_1_.func_225549_i_();
+        BiomeContainer biomestorage = ichunkaccess.func_225549_i_();
 
         if (biomestorage != null) {
             nbttagcompound1.func_74783_a("Biomes", biomestorage.func_227055_a_());
         }
 
         ListNBT nbttaglist1 = new ListNBT();
-        Iterator iterator = p_222645_1_.func_203066_o().iterator();
+        Iterator iterator = ichunkaccess.func_203066_o().iterator();
 
         CompoundNBT nbttagcompound3;
 
         while (iterator.hasNext()) {
             BlockPos blockposition = (BlockPos) iterator.next();
 
-            nbttagcompound3 = p_222645_1_.func_223134_j(blockposition);
+            nbttagcompound3 = ichunkaccess.func_223134_j(blockposition);
             if (nbttagcompound3 != null) {
                 nbttaglist1.add(nbttagcompound3);
             }
@@ -352,8 +469,8 @@ public class ChunkSerializer {
         ListNBT nbttaglist2 = new ListNBT();
 
         java.util.List<Entity> toUpdate = new java.util.ArrayList<>(); // Paper
-        if (p_222645_1_.func_201589_g().func_202129_d() == ChunkStatus.Type.LEVELCHUNK) {
-            Chunk chunk = (Chunk) p_222645_1_;
+        if (ichunkaccess.func_201589_g().func_202129_d() == ChunkStatus.Type.LEVELCHUNK) {
+            Chunk chunk = (Chunk) ichunkaccess;
 
             // CraftBukkit start - store chunk persistent data in nbt
             if (!chunk.persistentDataContainer.isEmpty()) {
@@ -370,7 +487,7 @@ public class ChunkSerializer {
                     Entity entity = (Entity) iterator1.next();
                     CompoundNBT nbttagcompound4 = new CompoundNBT();
                     // Paper start
-                    if ((int) Math.floor(entity.func_226277_ct_()) >> 4 != chunk.func_76632_l().field_77276_a || (int) Math.floor(entity.func_226281_cx_()) >> 4 != chunk.func_76632_l().field_77275_b) {
+                    if (asyncsavedata == null && !entity.field_70128_L && (int) Math.floor(entity.func_226277_ct_()) >> 4 != chunk.func_76632_l().field_77276_a || (int) Math.floor(entity.func_226281_cx_()) >> 4 != chunk.func_76632_l().field_77275_b) {
                         toUpdate.add(entity);
                         continue;
                     }
@@ -387,12 +504,12 @@ public class ChunkSerializer {
 
             // Paper start - move entities to the correct chunk
             for (Entity entity : toUpdate) {
-                p_222645_0_.func_217464_b(entity);
+                worldserver.func_217464_b(entity);
             }
             // Paper end
 
         } else {
-            ChunkPrimer protochunk = (ChunkPrimer) p_222645_1_;
+            ChunkPrimer protochunk = (ChunkPrimer) ichunkaccess;
 
             nbttaglist2.addAll(protochunk.func_201652_l());
             nbttagcompound1.func_218657_a("Lights", func_222647_a(protochunk.func_201647_i()));
@@ -413,40 +530,48 @@ public class ChunkSerializer {
         }
 
         nbttagcompound1.func_218657_a("Entities", nbttaglist2);
-        ITickList<Block> ticklist = p_222645_1_.func_205218_i_();
+        ITickList<Block> ticklist = ichunkaccess.func_205218_i_(); // Paper - diff on method change (see getAsyncSaveData)
 
         if (ticklist instanceof ChunkPrimerTickList) {
             nbttagcompound1.func_218657_a("ToBeTicked", ((ChunkPrimerTickList) ticklist).func_205379_a());
         } else if (ticklist instanceof SerializableTickList) {
             nbttagcompound1.func_218657_a("TileTicks", ((SerializableTickList) ticklist).func_234857_b_());
+            // Paper start - async chunk save for unload
+        } else if (asyncsavedata != null) {
+            nbttagcompound1.func_218657_a("TileTicks", asyncsavedata.blockTickList);
+            // Paper end
         } else {
-            nbttagcompound1.func_218657_a("TileTicks", p_222645_0_.func_205220_G_().func_219503_a(chunkcoordintpair));
+            nbttagcompound1.func_218657_a("TileTicks", worldserver.func_205220_G_().func_219503_a(chunkcoordintpair)); // Paper - diff on method change (see getAsyncSaveData)
         }
 
-        ITickList<Fluid> ticklist1 = p_222645_1_.func_212247_j();
+        ITickList<Fluid> ticklist1 = ichunkaccess.func_212247_j(); // Paper - diff on method change (see getAsyncSaveData)
 
         if (ticklist1 instanceof ChunkPrimerTickList) {
             nbttagcompound1.func_218657_a("LiquidsToBeTicked", ((ChunkPrimerTickList) ticklist1).func_205379_a());
         } else if (ticklist1 instanceof SerializableTickList) {
             nbttagcompound1.func_218657_a("LiquidTicks", ((SerializableTickList) ticklist1).func_234857_b_());
+            // Paper start - async chunk save for unload
+        } else if (asyncsavedata != null) {
+            nbttagcompound1.func_218657_a("LiquidTicks", asyncsavedata.fluidTickList);
+            // Paper end
         } else {
-            nbttagcompound1.func_218657_a("LiquidTicks", p_222645_0_.func_205219_F_().func_219503_a(chunkcoordintpair));
+            nbttagcompound1.func_218657_a("LiquidTicks", worldserver.func_205219_F_().func_219503_a(chunkcoordintpair)); // Paper - diff on method change (see getAsyncSaveData)
         }
 
-        nbttagcompound1.func_218657_a("PostProcessing", func_222647_a(p_222645_1_.func_201614_D()));
+        nbttagcompound1.func_218657_a("PostProcessing", func_222647_a(ichunkaccess.func_201614_D()));
         nbttagcompound2 = new CompoundNBT();
-        Iterator iterator2 = p_222645_1_.func_217311_f().iterator();
+        Iterator iterator2 = ichunkaccess.func_217311_f().iterator();
 
         while (iterator2.hasNext()) {
             Entry<Heightmap.Type, Heightmap> entry = (Entry) iterator2.next();
 
-            if (p_222645_1_.func_201589_g().func_222595_h().contains(entry.getKey())) {
+            if (ichunkaccess.func_201589_g().func_222595_h().contains(entry.getKey())) {
                 nbttagcompound2.func_218657_a(((Heightmap.Type) entry.getKey()).func_203500_b(), new LongArrayNBT(((Heightmap) entry.getValue()).func_202269_a()));
             }
         }
 
         nbttagcompound1.func_218657_a("Heightmaps", nbttagcompound2);
-        nbttagcompound1.func_218657_a("Structures", func_222649_a(chunkcoordintpair, p_222645_1_.func_201609_c(), p_222645_1_.func_201604_d()));
+        nbttagcompound1.func_218657_a("Structures", func_222649_a(chunkcoordintpair, ichunkaccess.func_201609_c(), ichunkaccess.func_201604_d()));
         return nbttagcompound;
     }
     // Paper start - this is saved with the player
diff --git a/src/main/java/net/minecraft/world/chunk/storage/RegionFile.java b/src/main/java/net/minecraft/world/chunk/storage/RegionFile.java
index 95557b6066728bd5b3880137651ef1c5bf0b1a5d..da3dc1bb45a7f757bfb77dc002fdc3e826eb00db 100644
--- a/src/main/java/net/minecraft/world/chunk/storage/RegionFile.java
+++ b/src/main/java/net/minecraft/world/chunk/storage/RegionFile.java
@@ -43,6 +43,8 @@ public class RegionFile implements AutoCloseable {
     protected final RegionBitmap field_227128_i_;
     public final File file; // Paper
 
+    public final java.util.concurrent.locks.ReentrantLock fileLock = new java.util.concurrent.locks.ReentrantLock(true); // Paper
+
     // Paper start - Cache chunk status
     private final ChunkStatus[] statuses = new ChunkStatus[32 * 32];
 
@@ -249,7 +251,7 @@ public class RegionFile implements AutoCloseable {
         return (p_227144_0_ + 4096 - 1) / 4096;
     }
 
-    public boolean func_222662_b(ChunkPos p_222662_1_) {
+    public synchronized boolean func_222662_b(ChunkPos p_222662_1_) { // Paper - synchronized
         int i = this.func_222660_e(p_222662_1_);
 
         if (i == 0) {
@@ -409,6 +411,11 @@ public class RegionFile implements AutoCloseable {
     }
 
     public void close() throws IOException {
+        // Paper start - Prevent regionfiles from being closed during use
+        this.fileLock.lock();
+        synchronized (this) {
+        try {
+        // Paper end
         this.closed = true; // Paper
         try {
             this.func_227143_c_();
@@ -419,6 +426,10 @@ public class RegionFile implements AutoCloseable {
                 this.field_76719_c.close();
             }
         }
+        } finally { // Paper start - Prevent regionfiles from being closed during use
+            this.fileLock.unlock();
+        }
+        } // Paper end
 
     }
 
diff --git a/src/main/java/net/minecraft/world/chunk/storage/RegionFileCache.java b/src/main/java/net/minecraft/world/chunk/storage/RegionFileCache.java
index 0c79c4b29c1eafd31fa7e28070b418abdba4db9f..bea2ecae05b7eb0f1234db5bcf7bee5192342831 100644
--- a/src/main/java/net/minecraft/world/chunk/storage/RegionFileCache.java
+++ b/src/main/java/net/minecraft/world/chunk/storage/RegionFileCache.java
@@ -16,7 +16,7 @@ import net.minecraft.nbt.ListNBT;
 import net.minecraft.server.MinecraftServer;
 import net.minecraft.util.math.ChunkPos;
 
-public final class RegionFileCache implements AutoCloseable {
+public class RegionFileCache implements AutoCloseable { // Paper - no final
 
     public final Long2ObjectLinkedOpenHashMap<RegionFile> field_219102_c = new Long2ObjectLinkedOpenHashMap();
     private final File field_219101_a;
@@ -29,16 +29,27 @@ public final class RegionFileCache implements AutoCloseable {
 
 
     // Paper start
-    public RegionFile getRegionFileIfLoaded(ChunkPos chunkcoordintpair) {
+    public synchronized RegionFile getRegionFileIfLoaded(ChunkPos chunkcoordintpair) { // Paper - synchronize for async io
         return this.field_219102_c.getAndMoveToFirst(ChunkPos.func_77272_a(chunkcoordintpair.func_222241_h(), chunkcoordintpair.func_222242_i()));
     }
 
     // Paper end
-    public RegionFile getFile(ChunkPos chunkcoordintpair, boolean existingOnly) throws IOException { // CraftBukkit // Paper - private >  public
+    public synchronized RegionFile getFile(ChunkPos chunkcoordintpair, boolean existingOnly) throws IOException { // CraftBukkit // Paper - private >  public, synchronize
+        // Paper start - add lock parameter
+        return this.getFile(chunkcoordintpair, existingOnly, false);
+    }
+    public synchronized RegionFile getFile(ChunkPos chunkcoordintpair, boolean existingOnly, boolean lock) throws IOException {
+        // Paper end
         long i = ChunkPos.func_77272_a(chunkcoordintpair.func_222241_h(), chunkcoordintpair.func_222242_i());
         RegionFile regionfile = (RegionFile) this.field_219102_c.getAndMoveToFirst(i);
 
         if (regionfile != null) {
+            // Paper start
+            if (lock) {
+                // must be in this synchronized block
+                regionfile.fileLock.lock();
+            }
+            // Paper end
             return regionfile;
         } else {
             if (this.field_219102_c.size() >= com.destroystokyo.paper.PaperConfig.regionFileCacheSize) { // Paper - configurable
@@ -54,6 +65,12 @@ public final class RegionFileCache implements AutoCloseable {
             RegionFile regionfile1 = new RegionFile(file, this.field_219101_a, this.field_235986_c_);
 
             this.field_219102_c.putAndMoveToFirst(i, regionfile1);
+            // Paper start
+            if (lock) {
+                // must be in this synchronized block
+                regionfile1.fileLock.lock();
+            }
+            // Paper end
             return regionfile1;
         }
     }
@@ -129,11 +146,12 @@ public final class RegionFileCache implements AutoCloseable {
     @Nullable
     public CompoundNBT func_219099_e(ChunkPos p_219099_1_) throws IOException {
         // CraftBukkit start - SPIGOT-5680: There's no good reason to preemptively create files on read, save that for writing
-        RegionFile regionfile = this.getFile(p_219099_1_, true);
+        RegionFile regionfile = this.getFile(p_219099_1_, true, true); // Paper
         if (regionfile == null) {
             return null;
         }
         // CraftBukkit end
+        try { // Paper
         DataInputStream datainputstream = regionfile.func_222666_a(p_219099_1_);
         // Paper start
         if (regionfile.isOversized(p_219099_1_.field_77276_a, p_219099_1_.field_77275_b)) {
@@ -171,10 +189,14 @@ public final class RegionFileCache implements AutoCloseable {
         }
 
         return nbttagcompound;
+        } finally { // Paper start
+            regionfile.fileLock.unlock();
+        } // Paper end
     }
 
     protected void func_219100_a(ChunkPos p_219100_1_, CompoundNBT p_219100_2_) throws IOException {
-        RegionFile regionfile = this.getFile(p_219100_1_, false); // CraftBukkit
+        RegionFile regionfile = this.getFile(p_219100_1_, false, true); // CraftBukkit // Paper
+        try { // Paper
         int attempts = 0; Exception laste = null; while (attempts++ < 5) { try { // Paper
         DataOutputStream dataoutputstream = regionfile.func_222661_c(p_219100_1_);
         Throwable throwable = null;
@@ -213,9 +235,12 @@ public final class RegionFileCache implements AutoCloseable {
             MinecraftServer.field_147145_h.error("Failed to save chunk", laste);
         }
         // Paper end
+        } finally { // Paper start
+            regionfile.fileLock.unlock();
+        } // Paper end
     }
 
-    public void close() throws IOException {
+    public synchronized void close() throws IOException { // Paper -> synchronized
         SuppressedExceptions<IOException> exceptionsuppressor = new SuppressedExceptions<>();
         ObjectIterator objectiterator = this.field_219102_c.values().iterator();
 
@@ -242,4 +267,12 @@ public final class RegionFileCache implements AutoCloseable {
         }
 
     }
+
+    // CraftBukkit start
+    public synchronized boolean chunkExists(ChunkPos pos) throws IOException { // Paper - synchronize
+        RegionFile regionfile = getFile(pos, true);
+
+        return regionfile != null ? regionfile.func_222667_d(pos) : false;
+    }
+    // CraftBukkit end
 }
diff --git a/src/main/java/net/minecraft/world/chunk/storage/RegionSectionCache.java b/src/main/java/net/minecraft/world/chunk/storage/RegionSectionCache.java
index 0dccb7647d1a6d0a8bed6919ffdbe259eb2a1821..246f82f1cfba78413fc965e5cd426cf1de8d3bd8 100644
--- a/src/main/java/net/minecraft/world/chunk/storage/RegionSectionCache.java
+++ b/src/main/java/net/minecraft/world/chunk/storage/RegionSectionCache.java
@@ -30,28 +30,29 @@ import net.minecraft.world.World;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
-public class RegionSectionCache<R> implements AutoCloseable {
+public class RegionSectionCache<R> extends RegionFileCache implements AutoCloseable { // Paper - nuke IOWorker
 
     private static final Logger field_219120_a = LogManager.getLogger();
-    private final IOWorker field_227173_b_;
+    // Paper - nuke IOWorker
     private final Long2ObjectMap<Optional<R>> field_219121_b = new Long2ObjectOpenHashMap();
-    private final LongLinkedOpenHashSet field_219122_d = new LongLinkedOpenHashSet();
+    protected final LongLinkedOpenHashSet field_219122_d = new LongLinkedOpenHashSet(); // Paper - private -> protected
     private final Function<Runnable, Codec<R>> field_235988_e_;
     private final Function<Runnable, R> field_219124_f;
     private final DataFixer field_219125_g;
     private final DefaultTypeReferences field_219126_h;
 
     public RegionSectionCache(File file, Function<Runnable, Codec<R>> function, Function<Runnable, R> function1, DataFixer datafixer, DefaultTypeReferences datafixtypes, boolean flag) {
+        super(file, flag); // Paper - nuke IOWorker
         this.field_235988_e_ = function;
         this.field_219124_f = function1;
         this.field_219125_g = datafixer;
         this.field_219126_h = datafixtypes;
-        this.field_227173_b_ = new IOWorker(file, flag, file.getName());
+        //this.b = new IOWorker(file, flag, file.getName()); // Paper - nuke IOWorker
     }
 
     protected void func_219115_a(BooleanSupplier p_219115_1_) {
         while (!this.field_219122_d.isEmpty() && p_219115_1_.getAsBoolean()) {
-            ChunkPos chunkcoordintpair = SectionPos.func_218170_a(this.field_219122_d.firstLong()).func_218155_u();
+            ChunkPos chunkcoordintpair = SectionPos.func_218170_a(this.field_219122_d.firstLong()).func_218155_u(); // Paper - conflict here to avoid obfhelpers
 
             this.func_219117_c(chunkcoordintpair);
         }
@@ -105,13 +106,18 @@ public class RegionSectionCache<R> implements AutoCloseable {
     }
 
     private void func_219107_b(ChunkPos p_219107_1_) {
-        this.func_235992_a_(p_219107_1_, NBTDynamicOps.field_210820_a, this.func_223138_c(p_219107_1_));
+        // Paper start - load data in function
+        this.loadInData(p_219107_1_, this.func_223138_c(p_219107_1_));
+    }
+    public void loadInData(ChunkPos chunkPos, CompoundNBT compound) {
+        this.func_235992_a_(chunkPos, NBTDynamicOps.field_210820_a, compound);
+        // Paper end
     }
 
     @Nullable
     private CompoundNBT func_223138_c(ChunkPos p_223138_1_) {
         try {
-            return this.field_227173_b_.func_227090_a_(p_223138_1_);
+            return this.func_219099_e(p_223138_1_); // Paper - nuke IOWorker
         } catch (IOException ioexception) {
             RegionSectionCache.field_219120_a.error("Error reading chunk {} data from disk", p_223138_1_, ioexception);
             return null;
@@ -157,17 +163,31 @@ public class RegionSectionCache<R> implements AutoCloseable {
     }
 
     private void func_219117_c(ChunkPos p_219117_1_) {
-        Dynamic<INBT> dynamic = this.func_235991_a_(p_219117_1_, NBTDynamicOps.field_210820_a);
+        Dynamic<INBT> dynamic = this.func_235991_a_(p_219117_1_, NBTDynamicOps.field_210820_a); // Paper - conflict here to avoid adding obfhelpers :)
         INBT nbtbase = (INBT) dynamic.getValue();
 
         if (nbtbase instanceof CompoundNBT) {
-            this.field_227173_b_.func_227093_a_(p_219117_1_, (CompoundNBT) nbtbase);
+            try { this.func_219100_a(p_219117_1_, (CompoundNBT) nbtbase); } catch (IOException ioexception) { RegionSectionCache.field_219120_a.error("Error writing data to disk", ioexception); } // Paper - nuke IOWorker // TODO make this write async
         } else {
             RegionSectionCache.field_219120_a.error("Expected compound tag, got {}", nbtbase);
         }
 
     }
 
+    // Paper start - internal get data function, copied from above
+    private CompoundNBT getDataInternal(ChunkPos chunkcoordintpair) {
+        Dynamic<INBT> dynamic = this.func_235991_a_(chunkcoordintpair, NBTDynamicOps.field_210820_a);
+        INBT nbtbase = (INBT) dynamic.getValue();
+
+        if (nbtbase instanceof CompoundNBT) {
+            return (CompoundNBT)nbtbase;
+        } else {
+            RegionSectionCache.field_219120_a.error("Expected compound tag, got {}", nbtbase);
+        }
+        return null;
+    }
+    // Paper end
+
     private <T> Dynamic<T> func_235991_a_(ChunkPos p_235991_1_, DynamicOps<T> p_235991_2_) {
         Map<T, T> map = Maps.newHashMap();
 
@@ -213,9 +233,9 @@ public class RegionSectionCache<R> implements AutoCloseable {
     public void func_219112_a(ChunkPos p_219112_1_) {
         if (!this.field_219122_d.isEmpty()) {
             for (int i = 0; i < 16; ++i) {
-                long j = SectionPos.func_218156_a(p_219112_1_, i).func_218146_v();
+                long j = SectionPos.func_218156_a(p_219112_1_, i).func_218146_v();  // Paper - conflict here to avoid obfhelpers
 
-                if (this.field_219122_d.contains(j)) {
+                if (this.field_219122_d.contains(j)) { // Paper - conflict here to avoid obfhelpers
                     this.func_219117_c(p_219112_1_);
                     return;
                 }
@@ -224,7 +244,26 @@ public class RegionSectionCache<R> implements AutoCloseable {
 
     }
 
-    public void close() throws IOException {
-        this.field_227173_b_.close();
+//    Paper start - nuke IOWorker
+//    public void close() throws IOException {
+//        this.b.close();
+//    }
+//    Paper end
+
+    // Paper start - get data function
+    public CompoundNBT getData(ChunkPos chunkcoordintpair) {
+        // Note: Copied from above
+        // This is checking if the data exists, then it builds it later in getDataInternal(ChunkCoordIntPair)
+        if (!this.field_219122_d.isEmpty()) {
+            for (int i = 0; i < 16; ++i) {
+                long j = SectionPos.func_218156_a(chunkcoordintpair, i).func_218146_v();
+
+                if (this.field_219122_d.contains(j)) {
+                    return this.getDataInternal(chunkcoordintpair);
+                }
+            }
+        }
+        return null;
     }
+    // Paper end
 }
diff --git a/src/main/java/net/minecraft/world/server/ChunkHolder.java b/src/main/java/net/minecraft/world/server/ChunkHolder.java
index 7174cd4045d1533a87928b34ccd2bad795fb8cab..e53ea8ca75e392808f49832ade42c3eb866c3e3f 100644
--- a/src/main/java/net/minecraft/world/server/ChunkHolder.java
+++ b/src/main/java/net/minecraft/world/server/ChunkHolder.java
@@ -152,6 +152,18 @@ public class ChunkHolder {
         }
         return null;
     }
+
+    public ChunkStatus getChunkHolderStatus() {
+        for (ChunkStatus curr = ChunkStatus.field_222617_m, next = curr.getPreviousStatus(); curr != next; curr = next, next = next.getPreviousStatus()) {
+            CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> future = this.func_219301_a(curr);
+            Either<IChunk, ChunkHolder.IChunkLoadingError> either = future.getNow(null);
+            if (either == null || !either.left().isPresent()) {
+                continue;
+            }
+            return curr;
+        }
+        return null;
+    }
     // Paper end
 
     public CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> func_219301_a(ChunkStatus p_219301_1_) {
@@ -370,7 +382,7 @@ public class ChunkHolder {
         ChunkStatus chunkstatus = func_219278_b(this.field_219316_k);
         ChunkStatus chunkstatus1 = func_219278_b(this.field_219317_l);
         boolean flag = this.field_219316_k <= ChunkManager.field_219249_a;
-        boolean flag1 = this.field_219317_l <= ChunkManager.field_219249_a;
+        boolean flag1 = this.field_219317_l <= ChunkManager.field_219249_a; // Paper - diff on change: (flag1 = new ticket level is in loadable range)
         ChunkHolder.LocationType playerchunk_state = func_219286_c(this.field_219316_k);
         ChunkHolder.LocationType playerchunk_state1 = func_219286_c(this.field_219317_l);
         // CraftBukkit start
@@ -406,6 +418,12 @@ public class ChunkHolder {
                 }
             });
 
+            // Paper start
+            if (!flag1) {
+                p_219291_1_.field_219255_i.asyncChunkTaskManager.cancelChunkLoad(this.field_219319_n.field_77276_a, this.field_219319_n.field_77275_b);
+            }
+            // Paper end
+
             for (int i = flag1 ? chunkstatus1.func_222584_c() + 1 : 0; i <= chunkstatus.func_222584_c(); ++i) {
                 completablefuture = (CompletableFuture) this.field_219312_g.get(i);
                 if (completablefuture != null) {
diff --git a/src/main/java/net/minecraft/world/server/ChunkManager.java b/src/main/java/net/minecraft/world/server/ChunkManager.java
index e976cbb9178ce363772749a1a65614c2d2f803f5..a4bffbdd59bb920908848f8e5decb267701d31f0 100644
--- a/src/main/java/net/minecraft/world/server/ChunkManager.java
+++ b/src/main/java/net/minecraft/world/server/ChunkManager.java
@@ -117,7 +117,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
     private final ServerWorldLightManager field_219256_j;
     private final ThreadTaskExecutor<Runnable> field_219257_k;
     public final ChunkGenerator field_219258_l;
-    private final Supplier<DimensionSavedDataManager> field_219259_m;
+    private final Supplier<DimensionSavedDataManager> field_219259_m; public final Supplier<DimensionSavedDataManager> getWorldPersistentDataSupplier() { return this.field_219259_m; } // Paper - OBFHELPER
     private final PointOfInterestManager field_219260_n;
     public final LongSet field_219261_o;
     private boolean field_219262_p;
@@ -127,7 +127,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
     public final IChunkStatusListener field_219266_t;
     public final ChunkManager.ProxyTicketManager field_219267_u;
     private final AtomicInteger field_219268_v;
-    private final TemplateManager field_219269_w;
+    public final TemplateManager field_219269_w; // Paper - private -> public
     private final File field_219270_x;
     private final PlayerGenerationTracker field_219271_y;
     public final Int2ObjectMap<ChunkManager.EntityTracker> field_219272_z;
@@ -210,7 +210,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
         this.field_219256_j = new ServerWorldLightManager(ilightaccess, this, this.field_219255_i.func_230315_m_().func_218272_d(), threadedmailbox1, this.field_219263_q.func_219087_a(threadedmailbox1, false));
         this.field_219267_u = new ChunkManager.ProxyTicketManager(executor, iasynctaskhandler);
         this.field_219259_m = supplier;
-        this.field_219260_n = new PointOfInterestManager(new File(this.field_219270_x, "poi"), datafixer, flag);
+        this.field_219260_n = new PointOfInterestManager(new File(this.field_219270_x, "poi"), datafixer, flag, this.field_219255_i); // Paper
         this.func_219175_a(i);
     }
 
@@ -252,12 +252,12 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
     }
 
     @Nullable
-    protected ChunkHolder func_219220_a(long p_219220_1_) {
+    public ChunkHolder func_219220_a(long p_219220_1_) { // Paper
         return (ChunkHolder) this.field_219251_e.get(p_219220_1_);
     }
 
     @Nullable
-    protected ChunkHolder func_219219_b(long p_219219_1_) {
+    public ChunkHolder func_219219_b(long p_219219_1_) { // Paper - protected -> public
         return (ChunkHolder) this.field_219252_f.get(p_219219_1_);
     }
 
@@ -379,6 +379,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
     public void close() throws IOException {
         try {
             this.field_219263_q.close();
+            this.field_219255_i.asyncChunkTaskManager.close(true); // Paper - Required since we're closing regionfiles in the next line
             this.field_219260_n.close();
         } finally {
             super.close();
@@ -470,7 +471,8 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
             this.func_223155_b(() -> {
                 return true;
             });
-            this.func_227079_i_();
+            this.field_219255_i.asyncChunkTaskManager.flush(); // Paper - flush to preserve behavior compat with pre-async behaviour
+//            this.i(); // Paper - nuke IOWorker
             ChunkManager.field_219250_d.info("ThreadedAnvilChunkStorage ({}): All chunks are saved", this.field_219270_x.getName());
         } else {
             this.field_219252_f.values().stream().filter(ChunkHolder::func_219289_k).forEach((playerchunk) -> {
@@ -486,16 +488,20 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
 
     }
 
-    private static final double UNLOAD_QUEUE_RESIZE_FACTOR = 0.96; // Spigot
+    private static final double UNLOAD_QUEUE_RESIZE_FACTOR = 0.90; // Spigot // Paper - unload more
 
     protected void func_219204_a(BooleanSupplier p_219204_1_) {
         IProfiler gameprofilerfiller = this.field_219255_i.func_217381_Z();
 
+        try (Timing ignored = this.field_219255_i.timings.poiUnload.startTiming()) { // Paper
         gameprofilerfiller.func_76320_a("poi");
         this.field_219260_n.func_219115_a(p_219204_1_);
+        } // Paper
         gameprofilerfiller.func_219895_b("chunk_unload");
         if (!this.field_219255_i.func_217402_u()) {
+            try (Timing ignored = this.field_219255_i.timings.chunkUnload.startTiming()) { // Paper
             this.func_223155_b(p_219204_1_);
+            }// Paper
         }
 
         gameprofilerfiller.func_76319_b();
@@ -516,12 +522,13 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
             if (playerchunk != null) {
                 this.field_219253_g.put(j, playerchunk);
                 this.field_219262_p = true;
+                this.func_219212_a(j, playerchunk); // Paper - Move up - don't leak chunks
                 // Spigot start
                 if (!p_223155_1_.getAsBoolean() && this.field_219261_o.size() <= targetSize && activityAccountant.activityTimeIsExhausted()) {
                     break;
                 }
                 // Spigot end
-                this.func_219212_a(j, playerchunk);
+                //this.a(j, playerchunk); // Paper - move up because spigot did a dumb
             }
         }
         activityAccountant.endActivity(); // Spigot
@@ -535,6 +542,60 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
 
     }
 
+    // Paper start - async chunk save for unload
+    // Note: This is very unsafe to call if the chunk is still in use.
+    // This is also modeled after PlayerChunkMap#saveChunk(IChunkAccess, boolean), with the intentional difference being
+    // serializing the chunk is left to a worker thread.
+    private void asyncSave(IChunk chunk) {
+        ChunkPos chunkPos = chunk.func_76632_l();
+        CompoundNBT poiData;
+        try (Timing ignored = this.field_219255_i.timings.chunkUnloadPOISerialization.startTiming()) {
+            poiData = this.getVillagePlace().getData(chunk.func_76632_l());
+        }
+
+        com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE.scheduleSave(this.field_219255_i, chunkPos.field_77276_a, chunkPos.field_77275_b,
+            poiData, null, com.destroystokyo.paper.io.PrioritizedTaskQueue.LOW_PRIORITY);
+
+        if (!chunk.func_201593_f()) {
+            return;
+        }
+
+        ChunkStatus chunkstatus = chunk.func_201589_g();
+
+        // Copied from PlayerChunkMap#saveChunk(IChunkAccess, boolean)
+        if (chunkstatus.func_202129_d() != ChunkStatus.Type.LEVELCHUNK) {
+            try (co.aikar.timings.Timing ignored1 = this.field_219255_i.timings.chunkSaveOverwriteCheck.startTiming()) { // Paper
+                // Paper start - Optimize save by using status cache
+                try {
+                    ChunkStatus statusOnDisk = this.getChunkStatusOnDisk(chunkPos);
+                    if (statusOnDisk != null && statusOnDisk.func_202129_d() == ChunkStatus.Type.LEVELCHUNK) {
+                        // Paper end
+                        return;
+                    }
+
+                    if (chunkstatus == ChunkStatus.field_223226_a_ && chunk.func_201609_c().values().stream().noneMatch(StructureStart::func_75069_d)) {
+                        return;
+                    }
+                } catch (IOException ex) {
+                    ex.printStackTrace();
+                    return;
+                }
+            }
+        }
+
+        ChunkSerializer.AsyncSaveData asyncSaveData;
+        try (Timing ignored = this.field_219255_i.timings.chunkUnloadPrepareSave.startTiming()) {
+            asyncSaveData = ChunkSerializer.getAsyncSaveData(this.field_219255_i, chunk);
+        }
+
+        this.field_219255_i.asyncChunkTaskManager.scheduleChunkSave(chunkPos.field_77276_a, chunkPos.field_77275_b, com.destroystokyo.paper.io.PrioritizedTaskQueue.LOW_PRIORITY,
+            asyncSaveData, chunk);
+
+        chunk.func_177432_b(this.field_219255_i.func_82737_E());
+        chunk.func_177427_f(false);
+    }
+    // Paper end
+
     private void func_219212_a(long p_219212_1_, ChunkHolder p_219212_2_) {
         CompletableFuture<IChunk> completablefuture = p_219212_2_.func_219302_f();
         Consumer<IChunk> consumer = (ichunkaccess) -> { // CraftBukkit - decompile error
@@ -548,7 +609,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
                         ((Chunk) ichunkaccess).func_177417_c(false);
                     }
 
-                    this.func_219229_a(ichunkaccess);
+                    //this.saveChunk(ichunkaccess);// Paper - delay
                     if (this.field_219254_h.remove(p_219212_1_) && ichunkaccess instanceof Chunk) {
                         Chunk chunk = (Chunk) ichunkaccess;
 
@@ -556,6 +617,13 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
                     }
                     this.autoSaveQueue.remove(p_219212_2_); // Paper
 
+                    try {
+                        this.asyncSave(ichunkaccess); // Paper - async chunk saving
+                    } catch (Throwable ex) {
+                        field_219250_d.fatal("Failed to prepare async save, attempting synchronous save", ex);
+                        this.func_219229_a(ichunkaccess);
+                    }
+
                     this.field_219256_j.func_215581_a(ichunkaccess.func_76632_l());
                     this.field_219256_j.func_215588_z_();
                     this.field_219266_t.func_219508_a(ichunkaccess.func_76632_l(), (ChunkStatus) null);
@@ -626,19 +694,23 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
     }
 
     private CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> func_223172_f(ChunkPos p_223172_1_) {
-        return CompletableFuture.supplyAsync(() -> {
+        // Paper start - Async chunk io
+        final java.util.function.BiFunction<ChunkSerializer.InProgressChunkHolder, Throwable, Either<IChunk, ChunkHolder.IChunkLoadingError>> syncLoadComplete = (chunkHolder, ioThrowable) -> {
             try (Timing ignored = this.field_219255_i.timings.chunkLoad.startTimingIfSync()) { // Paper
                 this.field_219255_i.func_217381_Z().func_230035_c_("chunkLoad");
-                CompoundNBT nbttagcompound; // Paper
-                try (Timing ignored2 = this.field_219255_i.timings.chunkIO.startTimingIfSync()) { // Paper start - timings
-                    nbttagcompound = this.func_219178_f(p_223172_1_);
-                } // Paper end
+                // Paper start
+                if (ioThrowable != null) {
+                    com.destroystokyo.paper.util.SneakyThrow.sneaky(ioThrowable);
+                }
 
-                if (nbttagcompound != null) {try (Timing ignored2 = this.field_219255_i.timings.chunkLoadLevelTimer.startTimingIfSync()) { // Paper start - timings
-                    boolean flag = nbttagcompound.func_150297_b("Level", 10) && nbttagcompound.func_74775_l("Level").func_150297_b("Status", 8);
+                this.getVillagePlace().loadInData(p_223172_1_, chunkHolder.poiData);
+                chunkHolder.tasks.forEach(Runnable::run);
+                // Paper end
 
-                    if (flag) {
-                        ChunkPrimer protochunk = ChunkSerializer.func_222656_a(this.field_219255_i, this.field_219269_w, this.field_219260_n, p_223172_1_, nbttagcompound);
+                if (chunkHolder.protoChunk != null) {try (Timing ignored2 = this.field_219255_i.timings.chunkLoadLevelTimer.startTimingIfSync()) { // Paper start - timings // Paper - chunk is created async
+
+                    if (true) {
+                        ChunkPrimer protochunk = chunkHolder.protoChunk;
 
                         protochunk.func_177432_b(this.field_219255_i.func_82737_E());
                         this.func_241088_a_(p_223172_1_, protochunk.func_201589_g().func_202129_d());
@@ -662,7 +734,32 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
 
             this.func_241089_g_(p_223172_1_);
             return Either.left(new ChunkPrimer(p_223172_1_, UpgradeData.field_196994_a, this.field_219255_i)); // Paper - Anti-Xray - Add parameter
-        }, this.field_219257_k);
+            // Paper start - Async chunk io
+        };
+        CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> ret = new CompletableFuture<>();
+
+        Consumer<ChunkSerializer.InProgressChunkHolder> chunkHolderConsumer = (ChunkSerializer.InProgressChunkHolder holder) -> {
+            // Go into the chunk load queue and not server task queue so we can be popped out even faster.
+            com.destroystokyo.paper.io.chunk.ChunkTaskManager.queueChunkWaitTask(() -> {
+                try {
+                    ret.complete(syncLoadComplete.apply(holder, null));
+                } catch (Exception e) {
+                    ret.completeExceptionally(e);
+                }
+            });
+        };
+
+        CompletableFuture<CompoundNBT> chunkSaveFuture = this.field_219255_i.asyncChunkTaskManager.getChunkSaveFuture(p_223172_1_.field_77276_a, p_223172_1_.field_77275_b);
+        if (chunkSaveFuture != null) {
+            this.field_219255_i.asyncChunkTaskManager.scheduleChunkLoad(p_223172_1_.field_77276_a, p_223172_1_.field_77275_b,
+                com.destroystokyo.paper.io.PrioritizedTaskQueue.HIGH_PRIORITY, chunkHolderConsumer, false, chunkSaveFuture);
+            this.field_219255_i.asyncChunkTaskManager.raisePriority(p_223172_1_.field_77276_a, p_223172_1_.field_77275_b, com.destroystokyo.paper.io.PrioritizedTaskQueue.HIGH_PRIORITY);
+        } else {
+            this.field_219255_i.asyncChunkTaskManager.scheduleChunkLoad(p_223172_1_.field_77276_a, p_223172_1_.field_77275_b,
+                com.destroystokyo.paper.io.PrioritizedTaskQueue.NORMAL_PRIORITY, chunkHolderConsumer, false);
+        }
+        return ret;
+        // Paper end
     }
 
     private void func_241089_g_(ChunkPos p_241089_1_) {
@@ -889,6 +986,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
     }
 
     public boolean func_219229_a(IChunk p_219229_1_) {
+        try (co.aikar.timings.Timing ignored = this.field_219255_i.timings.chunkSave.startTiming()) { // Paper
         this.field_219260_n.func_219112_a(p_219229_1_.func_76632_l());
         if (!p_219229_1_.func_201593_f()) {
             return false;
@@ -901,6 +999,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
                 ChunkStatus chunkstatus = p_219229_1_.func_201589_g();
 
                 if (chunkstatus.func_202129_d() != ChunkStatus.Type.LEVELCHUNK) {
+                    try (co.aikar.timings.Timing ignored1 = this.field_219255_i.timings.chunkSaveOverwriteCheck.startTiming()) { // Paper
                     if (this.func_241090_h_(chunkcoordintpair)) {
                         return false;
                     }
@@ -908,12 +1007,20 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
                     if (chunkstatus == ChunkStatus.field_223226_a_ && p_219229_1_.func_201609_c().values().stream().noneMatch(StructureStart::func_75069_d)) {
                         return false;
                     }
+                    } // Paper
                 }
 
                 this.field_219255_i.func_217381_Z().func_230035_c_("chunkSave");
-                CompoundNBT nbttagcompound = ChunkSerializer.func_222645_a(this.field_219255_i, p_219229_1_);
+                CompoundNBT nbttagcompound;
+                try (co.aikar.timings.Timing ignored1 = this.field_219255_i.timings.chunkSaveDataSerialization.startTiming()) { // Paper
+                    nbttagcompound = ChunkSerializer.func_222645_a(this.field_219255_i, p_219229_1_);
+                } // Paper
+
 
-                this.func_219100_a(chunkcoordintpair, nbttagcompound);
+                // Paper start - async chunk io
+                com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE.scheduleSave(this.field_219255_i, chunkcoordintpair.field_77276_a, chunkcoordintpair.field_77275_b,
+                    null, nbttagcompound, com.destroystokyo.paper.io.PrioritizedTaskQueue.NORMAL_PRIORITY);
+                // Paper end - async chunk io
                 this.func_241088_a_(chunkcoordintpair, chunkstatus.func_202129_d());
                 return true;
             } catch (Exception exception) {
@@ -922,6 +1029,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
                 return false;
             }
         }
+        } // Paper
     }
 
     private boolean func_241090_h_(ChunkPos p_241090_1_) {
@@ -1051,6 +1159,35 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
         }
     }
 
+    // Paper start - Asynchronous chunk io
+    @Nullable
+    @Override
+    public CompoundNBT func_227078_e_(ChunkPos p_227078_1_) throws IOException {
+        if (Thread.currentThread() != com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE) {
+            CompoundNBT ret = com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE
+                .loadChunkDataAsyncFuture(this.field_219255_i, p_227078_1_.field_77276_a, p_227078_1_.field_77275_b, com.destroystokyo.paper.io.IOUtil.getPriorityForCurrentThread(),
+                    false, true, true).join().chunkData;
+
+            if (ret == com.destroystokyo.paper.io.PaperFileIOThread.FAILURE_VALUE) {
+                throw new IOException("See logs for further detail");
+            }
+            return ret;
+        }
+        return super.func_227078_e_(p_227078_1_);
+    }
+
+    @Override
+    public void write(ChunkPos chunkcoordintpair, CompoundNBT nbttagcompound) throws IOException {
+        if (Thread.currentThread() != com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE) {
+            com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE.scheduleSave(
+                this.field_219255_i, chunkcoordintpair.field_77276_a, chunkcoordintpair.field_77275_b, null, nbttagcompound,
+                com.destroystokyo.paper.io.IOUtil.getPriorityForCurrentThread());
+            return;
+        }
+        super.write(chunkcoordintpair, nbttagcompound);
+    }
+    // Paper end
+
     @Nullable
     public CompoundNBT func_219178_f(ChunkPos p_219178_1_) throws IOException { // Paper - private -> public
         CompoundNBT nbttagcompound = this.func_227078_e_(p_219178_1_);
@@ -1072,33 +1209,55 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
 
     // Paper start - chunk status cache "api"
     public ChunkStatus getChunkStatusOnDiskIfCached(ChunkPos chunkPos) {
-        RegionFile regionFile = this.getIOWorker().getRegionFileCache().getRegionFileIfLoaded(chunkPos);
+        synchronized (this) { // Paper
+        RegionFile regionFile = this.regionFileCache.getRegionFileIfLoaded(chunkPos);
 
         return regionFile == null ? null : regionFile.getStatusIfCached(chunkPos.field_77276_a, chunkPos.field_77275_b);
+        } // Paper
     }
 
     public ChunkStatus getChunkStatusOnDisk(ChunkPos chunkPos) throws IOException {
-        RegionFile regionFile = this.getIOWorker().getRegionFileCache().getFile(chunkPos, true);
+        // Paper start - async chunk save for unload
+        IChunk unloadingChunk = this.field_219255_i.asyncChunkTaskManager.getChunkInSaveProgress(chunkPos.field_77276_a, chunkPos.field_77275_b);
+        if (unloadingChunk != null) {
+            return unloadingChunk.func_201589_g();
+        }
+        // Paper end
+        // Paper start - async io
+        CompoundNBT inProgressWrite = com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE
+                                             .getPendingWrite(this.field_219255_i, chunkPos.field_77276_a, chunkPos.field_77275_b, false);
 
-        if (regionFile == null || !regionFile.func_222667_d(chunkPos)) {
-            return null;
+        if (inProgressWrite != null) {
+            return ChunkSerializer.getStatus(inProgressWrite);
         }
+        // Paper end
+        synchronized (this) { // Paper - async io
+            RegionFile regionFile = this.regionFileCache.getFile(chunkPos, true);
+
+            if (regionFile == null || !regionFile.func_222667_d(chunkPos)) {
+                return null;
+            }
 
-        ChunkStatus status = regionFile.getStatusIfCached(chunkPos.field_77276_a, chunkPos.field_77275_b);
+            ChunkStatus status = regionFile.getStatusIfCached(chunkPos.field_77276_a, chunkPos.field_77275_b);
 
-        if (status != null) {
-            return status;
+            if (status != null) {
+                return status;
+            }
+            // Paper start - async io
         }
 
-        this.func_219178_f(chunkPos);
+        CompoundNBT compound = this.func_219178_f(chunkPos);
 
-        return regionFile.getStatusIfCached(chunkPos.field_77276_a, chunkPos.field_77275_b);
+        return ChunkSerializer.getStatus(compound);
+        // Paper end
     }
 
     public void updateChunkStatusOnDisk(ChunkPos chunkPos, @Nullable CompoundNBT compound) throws IOException {
-        RegionFile regionFile = this.getIOWorker().getRegionFileCache().getFile(chunkPos, false);
+        synchronized (this) {
+            RegionFile regionFile = this.regionFileCache.getFile(chunkPos, false);
 
-        regionFile.setStatus(chunkPos.field_77276_a, chunkPos.field_77275_b, ChunkSerializer.getStatus(compound));
+            regionFile.setStatus(chunkPos.field_77276_a, chunkPos.field_77275_b, ChunkSerializer.getStatus(compound));
+        }
     }
 
     public IChunk getUnloadingChunk(int chunkX, int chunkZ) {
@@ -1107,6 +1266,39 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
     }
     // Paper end
 
+
+    // Paper start - async io
+    // this function will not load chunk data off disk to check for status
+    // ret null for unknown, empty for empty status on disk or absent from disk
+    public ChunkStatus getStatusOnDiskNoLoad(int x, int z) {
+        // Paper start - async chunk save for unload
+        IChunk unloadingChunk = this.field_219255_i.asyncChunkTaskManager.getChunkInSaveProgress(x, z);
+        if (unloadingChunk != null) {
+            return unloadingChunk.func_201589_g();
+        }
+        // Paper end
+        // Paper start - async io
+        net.minecraft.nbt.CompoundNBT inProgressWrite = com.destroystokyo.paper.io.PaperFileIOThread.Holder.INSTANCE
+            .getPendingWrite(this.field_219255_i, x, z, false);
+
+        if (inProgressWrite != null) {
+            return net.minecraft.world.chunk.storage.ChunkSerializer.getStatus(inProgressWrite);
+        }
+        // Paper end
+        // variant of PlayerChunkMap#getChunkStatusOnDisk that does not load data off disk, but loads the region file
+        ChunkPos chunkPos = new ChunkPos(x, z);
+        synchronized (field_219255_i.func_72863_F().field_217237_a) {
+            net.minecraft.world.chunk.storage.RegionFile file;
+            try {
+                file = field_219255_i.func_72863_F().field_217237_a.regionFileCache.getFile(chunkPos, false);
+            } catch (IOException ex) {
+                throw new RuntimeException(ex);
+            }
+
+            return !file.func_222667_d(chunkPos) ? ChunkStatus.field_223226_a_ : file.getStatusIfCached(x, z);
+        }
+    }
+
     boolean func_219243_d(ChunkPos p_219243_1_) {
         // Spigot start
         return isOutsideOfRange(p_219243_1_, false);
@@ -1452,6 +1644,7 @@ public class ChunkManager extends ChunkLoader implements ChunkHolder.IPlayerProv
 
     }
 
+    public PointOfInterestManager getVillagePlace() { return this.func_219189_h(); } // Paper - OBFHELPER
     protected PointOfInterestManager func_219189_h() {
         return this.field_219260_n;
     }
diff --git a/src/main/java/net/minecraft/world/server/ServerChunkProvider.java b/src/main/java/net/minecraft/world/server/ServerChunkProvider.java
index 01b7ab898ae025aab47708cfa8e7ce44c5d7e19b..3933f1d4220e77a2903a79279cf565f5d7fb2f69 100644
--- a/src/main/java/net/minecraft/world/server/ServerChunkProvider.java
+++ b/src/main/java/net/minecraft/world/server/ServerChunkProvider.java
@@ -36,6 +36,7 @@ import net.minecraft.world.LightType;
 import net.minecraft.world.World;
 import net.minecraft.world.chunk.AbstractChunkProvider;
 import net.minecraft.world.chunk.Chunk;
+import net.minecraft.world.chunk.ChunkPrimerWrapper;
 import net.minecraft.world.chunk.ChunkStatus;
 import net.minecraft.world.chunk.IChunk;
 import net.minecraft.world.chunk.listener.IChunkStatusListener;
@@ -339,11 +340,138 @@ public class ServerChunkProvider extends AbstractChunkProvider {
         return playerChunk.getAvailableChunkNow();
 
     }
+
+    private long asyncLoadSeqCounter;
+
+    public CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> getChunkAtAsynchronously(int x, int z, boolean gen, boolean isUrgent) {
+        if (Thread.currentThread() != this.field_217241_g) {
+            CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> future = new CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>>();
+            this.field_217243_i.execute(() -> {
+                this.getChunkAtAsynchronously(x, z, gen, isUrgent).whenComplete((chunk, ex) -> {
+                    if (ex != null) {
+                        future.completeExceptionally(ex);
+                    } else {
+                        future.complete(chunk);
+                    }
+                });
+            });
+            return future;
+        }
+
+        if (!com.destroystokyo.paper.PaperConfig.asyncChunks) {
+            field_73251_h.getWorld().loadChunk(x, z, gen);
+            Chunk chunk = getChunkAtIfLoadedMainThread(x, z);
+            return CompletableFuture.completedFuture(chunk != null ? Either.left(chunk) : ChunkHolder.field_219306_a);
+        }
+
+        long k = ChunkPos.func_77272_a(x, z);
+        ChunkPos chunkPos = new ChunkPos(x, z);
+
+        IChunk ichunkaccess;
+
+        // try cache
+        for (int l = 0; l < 4; ++l) {
+            if (k == this.field_222875_n[l] && ChunkStatus.field_222617_m == this.field_222876_o[l]) {
+                ichunkaccess = this.field_222877_p[l];
+                if (ichunkaccess != null) { // CraftBukkit - the chunk can become accessible in the meantime TODO for non-null chunks it might also make sense to check that the chunk's state hasn't changed in the meantime
+
+                    // move to first in cache
+
+                    for (int i1 = 3; i1 > 0; --i1) {
+                        this.field_222875_n[i1] = this.field_222875_n[i1 - 1];
+                        this.field_222876_o[i1] = this.field_222876_o[i1 - 1];
+                        this.field_222877_p[i1] = this.field_222877_p[i1 - 1];
+                    }
+
+                    this.field_222875_n[0] = k;
+                    this.field_222876_o[0] = ChunkStatus.field_222617_m;
+                    this.field_222877_p[0] = ichunkaccess;
+
+                    return CompletableFuture.completedFuture(Either.left(ichunkaccess));
+                }
+            }
+        }
+
+        if (gen) {
+            return this.bringToFullStatusAsync(x, z, chunkPos, isUrgent);
+        }
+
+        IChunk current = this.getChunkAtImmediately(x, z); // we want to bypass ticket restrictions
+        if (current != null) {
+            if (!(current instanceof ChunkPrimerWrapper) && !(current instanceof net.minecraft.world.chunk.Chunk)) {
+                return CompletableFuture.completedFuture(ChunkHolder.field_219306_a);
+            }
+            // we know the chunk is at full status here (either in read-only mode or the real thing)
+            return this.bringToFullStatusAsync(x, z, chunkPos, isUrgent);
+        }
+
+        ChunkStatus status = field_73251_h.func_72863_F().field_217237_a.getStatusOnDiskNoLoad(x, z);
+
+        if (status != null && status != ChunkStatus.field_222617_m) {
+            // does not exist on disk
+            return CompletableFuture.completedFuture(ChunkHolder.field_219306_a);
+        }
+
+        if (status == ChunkStatus.field_222617_m) {
+            return this.bringToFullStatusAsync(x, z, chunkPos, isUrgent);
+        }
+
+        // status is null here
+
+        // here we don't know what status it is and we're not supposed to generate
+        // so we asynchronously load empty status
+        return this.bringToStatusAsync(x, z, chunkPos, ChunkStatus.field_223226_a_, isUrgent).thenCompose((either) -> {
+            IChunk chunk = either.left().orElse(null);
+            if (!(chunk instanceof ChunkPrimerWrapper) && !(chunk instanceof Chunk)) {
+                // the chunk on disk was not a full status chunk
+                return CompletableFuture.completedFuture(ChunkHolder.field_219306_a);
+            }
+            ; // bring to full status if required
+            return this.bringToFullStatusAsync(x, z, chunkPos, isUrgent);
+        });
+    }
+
+    private CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> bringToFullStatusAsync(int x, int z, ChunkPos chunkPos, boolean isUrgent) {
+        return this.bringToStatusAsync(x, z, chunkPos, ChunkStatus.field_222617_m, isUrgent);
+    }
+
+    private CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> bringToStatusAsync(int x, int z, ChunkPos chunkPos, ChunkStatus status, boolean isUrgent) {
+        CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> future = this.getChunkFutureMainThread(x, z, status, true, isUrgent);
+        Long identifier = Long.valueOf(this.asyncLoadSeqCounter++);
+        int ticketLevel = MCUtil.getTicketLevelFor(status);
+        this.addTicketAtLevel(TicketType.ASYNC_LOAD, chunkPos, ticketLevel, identifier);
+
+        return future.thenComposeAsync((Either<IChunk, ChunkHolder.IChunkLoadingError> either) -> {
+            // either left -> success
+            // either right -> failure
+
+            this.removeTicketAtLevel(TicketType.ASYNC_LOAD, chunkPos, ticketLevel, identifier);
+            this.addTicketAtLevel(TicketType.field_219494_g, chunkPos, ticketLevel, chunkPos); // allow unloading
+
+            Optional<ChunkHolder.IChunkLoadingError> failure = either.right();
+
+            if (failure.isPresent()) {
+                // failure
+                throw new IllegalStateException("Chunk failed to load: " + failure.get().toString());
+            }
+
+            return CompletableFuture.completedFuture(either);
+        }, this.field_217243_i);
+    }
+
+    public <T> void addTicketAtLevel(TicketType<T> ticketType, ChunkPos chunkPos, int ticketLevel, T identifier) {
+        this.field_217240_d.addTicketAtLevel(ticketType, chunkPos, ticketLevel, identifier);
+    }
+
+    public <T> void removeTicketAtLevel(TicketType<T> ticketType, ChunkPos chunkPos, int ticketLevel, T identifier) {
+        this.field_217240_d.removeTicketAtLevel(ticketType, chunkPos, ticketLevel, identifier);
+    }
     // Paper end
 
     @Nullable
     @Override
     public IChunk func_212849_a_(int p_212849_1_, int p_212849_2_, ChunkStatus p_212849_3_, boolean p_212849_4_) {
+        final int x = p_212849_1_; final int z = p_212849_2_; // Paper - conflict on variable change
         if (Thread.currentThread() != this.field_217241_g) {
             return (IChunk) CompletableFuture.supplyAsync(() -> {
                 return this.func_212849_a_(p_212849_1_, p_212849_2_, p_212849_3_, p_212849_4_);
@@ -366,11 +494,16 @@ public class ServerChunkProvider extends AbstractChunkProvider {
             }
 
             gameprofilerfiller.func_230035_c_("getChunkCacheMiss");
-            CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> completablefuture = this.func_217233_c(p_212849_1_, p_212849_2_, p_212849_3_, p_212849_4_);
+            CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> completablefuture = this.getChunkFutureMainThread(p_212849_1_, p_212849_2_, p_212849_3_, p_212849_4_, true); // Paper
 
             if (!completablefuture.isDone()) { // Paper
+                // Paper start - async chunk io/loading
+                this.field_73251_h.asyncChunkTaskManager.raisePriority(x, z, com.destroystokyo.paper.io.PrioritizedTaskQueue.HIGHEST_PRIORITY);
+                com.destroystokyo.paper.io.chunk.ChunkTaskManager.pushChunkWait(this.field_73251_h, x, z);
+                // Paper end
                 this.field_73251_h.timings.syncChunkLoad.startTiming(); // Paper
             this.field_217243_i.func_213161_c(completablefuture::isDone);
+                com.destroystokyo.paper.io.chunk.ChunkTaskManager.popChunkWait(); // Paper - async chunk debug
                 this.field_73251_h.timings.syncChunkLoad.stopTiming(); // Paper
             } // Paper
             ichunkaccess = (IChunk) ((Either) completablefuture.join()).map((ichunkaccess1) -> {
@@ -436,9 +569,14 @@ public class ServerChunkProvider extends AbstractChunkProvider {
     }
 
     private CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> func_217233_c(int p_217233_1_, int p_217233_2_, ChunkStatus p_217233_3_, boolean p_217233_4_) {
-        ChunkPos chunkcoordintpair = new ChunkPos(p_217233_1_, p_217233_2_);
+        // Paper start - add isUrgent - old sig left in place for dirty nms plugins
+        return getChunkFutureMainThread(p_217233_1_, p_217233_2_, p_217233_3_, p_217233_4_, false);
+    }
+    private CompletableFuture<Either<IChunk, ChunkHolder.IChunkLoadingError>> getChunkFutureMainThread(int i, int j, ChunkStatus chunkstatus, boolean flag, boolean isUrgent) {
+        // Paper end
+        ChunkPos chunkcoordintpair = new ChunkPos(i, j);
         long k = chunkcoordintpair.func_201841_a();
-        int l = 33 + ChunkStatus.func_222599_a(p_217233_3_);
+        int l = 33 + ChunkStatus.func_222599_a(chunkstatus);
         ChunkHolder playerchunk = this.func_217213_a(k);
 
         // CraftBukkit start - don't add new ticket for currently unloading chunk
@@ -448,7 +586,7 @@ public class ServerChunkProvider extends AbstractChunkProvider {
             ChunkHolder.LocationType currentChunkState = ChunkHolder.func_219286_c(playerchunk.func_219299_i());
             currentlyUnloading = (oldChunkState.func_219065_a(ChunkHolder.LocationType.BORDER) && !currentChunkState.func_219065_a(ChunkHolder.LocationType.BORDER));
         }
-        if (p_217233_4_ && !currentlyUnloading) {
+        if (flag && !currentlyUnloading) {
             // CraftBukkit end
             this.field_217240_d.func_219356_a(TicketType.field_219494_g, chunkcoordintpair, l, chunkcoordintpair);
             if (this.func_217224_a(playerchunk, l)) {
@@ -464,7 +602,7 @@ public class ServerChunkProvider extends AbstractChunkProvider {
             }
         }
 
-        return this.func_217224_a(playerchunk, l) ? ChunkHolder.field_219307_b : playerchunk.func_219276_a(p_217233_3_, this.field_217237_a);
+        return this.func_217224_a(playerchunk, l) ? ChunkHolder.field_219307_b : playerchunk.func_219276_a(chunkstatus, this.field_217237_a);
     }
 
     private boolean func_217224_a(@Nullable ChunkHolder p_217224_1_, int p_217224_2_) {
@@ -835,11 +973,12 @@ public class ServerChunkProvider extends AbstractChunkProvider {
         protected boolean func_213168_p() {
         // CraftBukkit start - process pending Chunk loadCallback() and unloadCallback() after each run task
         try {
+            boolean execChunkTask = com.destroystokyo.paper.io.chunk.ChunkTaskManager.pollChunkWaitQueue() || ServerChunkProvider.this.field_73251_h.asyncChunkTaskManager.pollNextChunkTask(); // Paper
             if (ServerChunkProvider.this.func_217235_l()) {
                 return true;
             } else {
                 ServerChunkProvider.this.field_217242_h.func_215588_z_();
-                return super.func_213168_p();
+                return super.func_213168_p() || execChunkTask; // Paper
             }
         } finally {
             field_217237_a.callbackExecutor.run();
diff --git a/src/main/java/net/minecraft/world/server/ServerWorld.java b/src/main/java/net/minecraft/world/server/ServerWorld.java
index 749a535f8572d755fa435071f383d5bfb4360dd5..505bec05bd8c8f3273481fb175a8fd898a0749a5 100644
--- a/src/main/java/net/minecraft/world/server/ServerWorld.java
+++ b/src/main/java/net/minecraft/world/server/ServerWorld.java
@@ -67,6 +67,7 @@ import net.minecraft.fluid.FluidState;
 import net.minecraft.fluid.Fluids;
 import net.minecraft.inventory.IInventory;
 import net.minecraft.item.crafting.RecipeManager;
+import net.minecraft.nbt.CompoundNBT;
 import net.minecraft.network.DebugPacketSender;
 import net.minecraft.network.IPacket;
 import net.minecraft.network.play.server.SAnimateBlockBreakPacket;
@@ -128,6 +129,7 @@ import net.minecraft.world.chunk.ChunkSection;
 import net.minecraft.world.chunk.ChunkStatus;
 import net.minecraft.world.chunk.IChunk;
 import net.minecraft.world.chunk.listener.IChunkStatusListener;
+import net.minecraft.world.chunk.storage.RegionFile;
 import net.minecraft.world.end.DragonFightManager;
 import net.minecraft.world.gen.ChunkGenerator;
 import net.minecraft.world.gen.Heightmap;
@@ -203,6 +205,79 @@ public class ServerWorld extends World implements ISeedReader {
         return this.field_241102_C_.func_217205_a(x, z, false);
     }
 
+    // Paper start - Asynchronous IO
+    public final com.destroystokyo.paper.io.PaperFileIOThread.ChunkDataController poiDataController = new com.destroystokyo.paper.io.PaperFileIOThread.ChunkDataController() {
+        @Override
+        public void writeData(int x, int z, CompoundNBT compound) throws java.io.IOException {
+            ServerWorld.this.func_72863_F().field_217237_a.getVillagePlace().func_219100_a(new ChunkPos(x, z), compound);
+        }
+
+        @Override
+        public CompoundNBT readData(int x, int z) throws java.io.IOException {
+            return ServerWorld.this.func_72863_F().field_217237_a.getVillagePlace().func_219099_e(new ChunkPos(x, z));
+        }
+
+        @Override
+        public <T> T computeForRegionFile(int chunkX, int chunkZ, java.util.function.Function<RegionFile, T> function) {
+            synchronized (ServerWorld.this.func_72863_F().field_217237_a.getVillagePlace()) {
+                RegionFile file;
+
+                try {
+                    file = ServerWorld.this.func_72863_F().field_217237_a.getVillagePlace().getFile(new ChunkPos(chunkX, chunkZ), false);
+                } catch (java.io.IOException ex) {
+                    throw new RuntimeException(ex);
+                }
+
+                return function.apply(file);
+            }
+        }
+
+        @Override
+        public <T> T computeForRegionFileIfLoaded(int chunkX, int chunkZ, java.util.function.Function<RegionFile, T> function) {
+            synchronized (ServerWorld.this.func_72863_F().field_217237_a.getVillagePlace()) {
+                RegionFile file = ServerWorld.this.func_72863_F().field_217237_a.getVillagePlace().getRegionFileIfLoaded(new ChunkPos(chunkX, chunkZ));
+                return function.apply(file);
+            }
+        }
+    };
+
+    public final com.destroystokyo.paper.io.PaperFileIOThread.ChunkDataController chunkDataController = new com.destroystokyo.paper.io.PaperFileIOThread.ChunkDataController() {
+        @Override
+        public void writeData(int x, int z, CompoundNBT compound) throws java.io.IOException {
+            ServerWorld.this.func_72863_F().field_217237_a.write(new ChunkPos(x, z), compound);
+        }
+
+        @Override
+        public CompoundNBT readData(int x, int z) throws java.io.IOException {
+            return ServerWorld.this.func_72863_F().field_217237_a.func_227078_e_(new ChunkPos(x, z));
+        }
+
+        @Override
+        public <T> T computeForRegionFile(int chunkX, int chunkZ, java.util.function.Function<RegionFile, T> function) {
+            synchronized (ServerWorld.this.func_72863_F().field_217237_a) {
+                RegionFile file;
+
+                try {
+                    file = ServerWorld.this.func_72863_F().field_217237_a.regionFileCache.getFile(new ChunkPos(chunkX, chunkZ), false);
+                } catch (java.io.IOException ex) {
+                    throw new RuntimeException(ex);
+                }
+
+                return function.apply(file);
+            }
+        }
+
+        @Override
+        public <T> T computeForRegionFileIfLoaded(int chunkX, int chunkZ, java.util.function.Function<RegionFile, T> function) {
+            synchronized (ServerWorld.this.func_72863_F().field_217237_a) {
+                RegionFile file = ServerWorld.this.func_72863_F().field_217237_a.regionFileCache.getRegionFileIfLoaded(new ChunkPos(chunkX, chunkZ));
+                return function.apply(file);
+            }
+        }
+    };
+    public final com.destroystokyo.paper.io.chunk.ChunkTaskManager asyncChunkTaskManager;
+    // Paper end
+
     // Add env and gen to constructor, WorldData -> WorldDataServer
     public ServerWorld(MinecraftServer minecraftserver, Executor executor, SaveFormat.LevelSave convertable_conversionsession, IServerWorldInfo iworlddataserver, RegistryKey<World> resourcekey, DimensionType dimensionmanager, IChunkStatusListener worldloadlistener, ChunkGenerator chunkgenerator, boolean flag, long i, List<ISpecialSpawner> list, boolean flag1, org.bukkit.World.Environment env, org.bukkit.generator.ChunkGenerator gen) {
         super(iworlddataserver, resourcekey, dimensionmanager, minecraftserver::func_213185_aS, false, flag, i, gen, env, executor); // Paper pass executor
@@ -250,6 +325,8 @@ public class ServerWorld extends World implements ISeedReader {
             this.field_241105_O_ = null;
         }
         this.getServer().addWorld(this.getWorld()); // CraftBukkit
+
+        this.asyncChunkTaskManager = new com.destroystokyo.paper.io.chunk.ChunkTaskManager(this); // Paper
     }
 
     // CraftBukkit start
@@ -1724,7 +1801,10 @@ public class ServerWorld extends World implements ISeedReader {
         }
 
         MCUtil.getSpiralOutChunks(spawn, radiusInBlocks >> 4).forEach(pair -> {
-            func_72863_F().getChunkAtMainThread(pair.field_77276_a, pair.field_77275_b);
+            func_72863_F().getChunkAtAsynchronously(pair.field_77276_a, pair.field_77275_b, true, false).exceptionally((ex) -> {
+                ex.printStackTrace();
+                return null;
+            });
         });
     }
     public void removeTicketsForSpawn(int radiusInBlocks, BlockPos spawn) {
diff --git a/src/main/java/net/minecraft/world/server/TicketType.java b/src/main/java/net/minecraft/world/server/TicketType.java
index 04114c39a533fe7b3dce27d3a7bcc33973444b31..779d6f5a3500445c372a9b5c6cd00ccf27ae5ae5 100644
--- a/src/main/java/net/minecraft/world/server/TicketType.java
+++ b/src/main/java/net/minecraft/world/server/TicketType.java
@@ -26,6 +26,7 @@ public class TicketType<T> {
     public static final TicketType<Unit> PLUGIN = func_219484_a("plugin", (a, b) -> 0); // CraftBukkit
     public static final TicketType<org.bukkit.plugin.Plugin> PLUGIN_TICKET = func_219484_a("plugin_ticket", (plugin1, plugin2) -> plugin1.getClass().getName().compareTo(plugin2.getClass().getName())); // CraftBukkit
     public static final TicketType<Long> FUTURE_AWAIT = func_219484_a("future_await", Long::compareTo); // Paper
+    public static final TicketType<Long> ASYNC_LOAD = func_219484_a("async_load", Long::compareTo); // Paper
 
     public static <T> TicketType<T> func_219484_a(String p_219484_0_, Comparator<T> p_219484_1_) {
         return new TicketType<>(p_219484_0_, p_219484_1_, 0L);
diff --git a/src/main/java/org/bukkit/craftbukkit/CraftWorld.java b/src/main/java/org/bukkit/craftbukkit/CraftWorld.java
index e3544afd53a951e5ba02988374347a2a4e88bf00..2bb0b537aae13a87421f8f08e60da26b613a4ff1 100644
--- a/src/main/java/org/bukkit/craftbukkit/CraftWorld.java
+++ b/src/main/java/org/bukkit/craftbukkit/CraftWorld.java
@@ -60,6 +60,7 @@ import net.minecraft.entity.projectile.SnowballEntity;
 import net.minecraft.network.play.server.SPlaySoundEventPacket;
 import net.minecraft.network.play.server.SPlaySoundPacket;
 import net.minecraft.network.play.server.SUpdateTimePacket;
+import net.minecraft.server.MinecraftServer;
 import net.minecraft.util.Direction;
 import net.minecraft.util.ResourceLocation;
 import net.minecraft.util.SortedArraySet;
@@ -557,22 +558,23 @@ public class CraftWorld implements World {
                 return true;
             }
 
-            net.minecraft.world.chunk.storage.RegionFile file;
-            try {
-                file = world.func_72863_F().field_217237_a.getIOWorker().getRegionFileCache().getFile(chunkPos, false);
-            } catch (IOException ex) {
-                throw new RuntimeException(ex);
-            }
+            ChunkStatus status = world.func_72863_F().field_217237_a.getStatusOnDiskNoLoad(x, z); // Paper - async io - move to own method
 
-            ChunkStatus status = file.getStatusIfCached(x, z);
-            if (!file.func_222667_d(chunkPos) || (status != null && status != ChunkStatus.field_222617_m)) {
+            // Paper start - async io
+            if (status == ChunkStatus.field_223226_a_) {
+                // does not exist on disk
                 return false;
             }
 
+            if (status == null) { // at this stage we don't know what it is on disk
             IChunk chunk = world.func_72863_F().func_212849_a_(x, z, ChunkStatus.field_223226_a_, true);
             if (!(chunk instanceof ChunkPrimerWrapper) && !(chunk instanceof net.minecraft.world.chunk.Chunk)) {
                 return false;
             }
+            } else if (status != ChunkStatus.field_222617_m) {
+                return false; // not full status on disk
+            }
+            // Paper end
 
             // fall through to load
             // we do this so we do not re-read the chunk data on disk
@@ -2461,6 +2463,34 @@ public class CraftWorld implements World {
     public DragonBattle getEnderDragonBattle() {
         return (getHandle().func_241110_C_() == null) ? null : new CraftDragonBattle(getHandle().func_241110_C_());
     }
+    // Paper start
+    @Override
+    public CompletableFuture<Chunk> getChunkAtAsync(int x, int z, boolean gen, boolean urgent) {
+        if (Bukkit.isPrimaryThread()) {
+            net.minecraft.world.chunk.Chunk immediate = this.world.func_72863_F().getChunkAtIfLoadedImmediately(x, z);
+            if (immediate != null) {
+                return CompletableFuture.completedFuture(immediate.getBukkitChunk());
+            }
+        } else {
+            CompletableFuture<Chunk> future = new CompletableFuture<Chunk>();
+            world.func_73046_m().execute(() -> {
+                getChunkAtAsync(x, z, gen, urgent).whenComplete((chunk, err) -> {
+                    if (err != null) {
+                        future.completeExceptionally(err);
+                    } else {
+                        future.complete(chunk);
+                    }
+                });
+            });
+            return future;
+        }
+
+        return this.world.func_72863_F().getChunkAtAsynchronously(x, z, gen, urgent).thenComposeAsync((either) -> {
+            net.minecraft.world.chunk.Chunk chunk = (net.minecraft.world.chunk.Chunk) either.left().orElse(null);
+            return CompletableFuture.completedFuture(chunk == null ? null : chunk.getBukkitChunk());
+        }, MinecraftServer.getServer());
+    }
+    // Paper end
 
     // Spigot start
     @Override
diff --git a/src/main/java/org/bukkit/craftbukkit/entity/CraftEntity.java b/src/main/java/org/bukkit/craftbukkit/entity/CraftEntity.java
index ca1ec7481395ba43a212be1a59aee682bd3a893a..affcc92a459b2cfb98905e8dd6598e9d3d528e07 100644
--- a/src/main/java/org/bukkit/craftbukkit/entity/CraftEntity.java
+++ b/src/main/java/org/bukkit/craftbukkit/entity/CraftEntity.java
@@ -503,6 +503,28 @@ public abstract class CraftEntity implements org.bukkit.entity.Entity {
         entity.func_70034_d(yaw);
     }
 
+    @Override// Paper start
+    public java.util.concurrent.CompletableFuture<Boolean> teleportAsync(Location loc, @javax.annotation.Nonnull org.bukkit.event.player.PlayerTeleportEvent.TeleportCause cause) {
+        net.minecraft.world.server.ChunkManager playerChunkMap = ((CraftWorld) loc.getWorld()).getHandle().func_72863_F().field_217237_a;
+        java.util.concurrent.CompletableFuture<Boolean> future = new java.util.concurrent.CompletableFuture<>();
+
+        loc.getWorld().getChunkAtAsyncUrgently(loc).thenCompose(chunk -> {
+            net.minecraft.server.ChunkCoordIntPair pair = new net.minecraft.server.ChunkCoordIntPair(chunk.getX(), chunk.getZ());
+            ((CraftWorld) loc.getWorld()).getHandle().getChunkProvider().addTicketAtLevel(net.minecraft.server.TicketType.POST_TELEPORT, pair, 31, 0);
+            net.minecraft.server.PlayerChunk updatingChunk = playerChunkMap.getUpdatingChunk(pair.pair());
+            if (updatingChunk != null) {
+                return updatingChunk.getEntityTickingFuture();
+            } else {
+                return java.util.concurrent.CompletableFuture.completedFuture(com.mojang.datafixers.util.Either.left(((org.bukkit.craftbukkit.CraftChunk)chunk).getHandle()));
+            }
+        }).thenAccept((chunk) -> future.complete(teleport(loc, cause))).exceptionally(ex -> {
+            future.completeExceptionally(ex);
+            return null;
+        });
+        return future;
+    }
+    // Paper end
+
     @Override
     public boolean teleport(Location location) {
         return teleport(location, TeleportCause.PLUGIN);
diff --git a/src/main/java/org/spigotmc/WatchdogThread.java b/src/main/java/org/spigotmc/WatchdogThread.java
index 4ac96acdad6cf268bf3949e70741e05e252ea2df..93c8701c4da2c96284f8d22e2be69c13bc7c0b43 100644
--- a/src/main/java/org/spigotmc/WatchdogThread.java
+++ b/src/main/java/org/spigotmc/WatchdogThread.java
@@ -6,6 +6,7 @@ import java.lang.management.ThreadInfo;
 import java.util.logging.Level;
 import java.util.logging.Logger;
 import com.destroystokyo.paper.PaperConfig;
+import com.destroystokyo.paper.io.chunk.ChunkTaskManager; // Paper
 import net.minecraft.server.MinecraftServer;
 import org.bukkit.Bukkit;
 
@@ -112,6 +113,7 @@ public class WatchdogThread extends Thread
                 // Paper end - Different message for short timeout
                 log.log( Level.SEVERE, "------------------------------" );
                 log.log( Level.SEVERE, "Server thread dump (Look for plugins here before reporting to Paper!):" ); // Paper
+                ChunkTaskManager.dumpAllChunkLoadInfo(); // Paper
                 dumpThread( ManagementFactory.getThreadMXBean().getThreadInfo( MinecraftServer.getServer().field_175590_aa.getId(), Integer.MAX_VALUE ), log );
                 log.log( Level.SEVERE, "------------------------------" );
                 //
